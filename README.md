# C-implementation-of-RNN

## Introduction
This is the first step to implement RNN on FPGAs. All modules are heavily commented. We will use High-Level Synthesis to turn these code into Hardware Description Languages (HDL).

## Run Program
We prepared everything for you, simply run 'make' in command line, then './main' to see the result generated by 1000 samples.

If you don't want to run the program by yourself, there are some sample results.
log_double.out: 27.8125%
log_float.out: 26.8750%
These results are the inference accuracy of the next words. Each word is predicted by input the sequences of previous 50 words to RNN. We used 'double' and 'float' in C to test the results, which are float64 and float32. However, these results are slightly less accurate than Keras, which has an accuracy of 28.1250%.

## Module Description

### RNN computations
fc.c: Fully-connected Layers 
rnn.c: RNN Layers

### Activation functions
activation.c: relu & tanh
softmax.c: softmax

### run program
main.c: float32 inference
main_double.c: float54 inference

### dataset & weights
./datasets: sequences composed of 50 words, the result we want to predict is the next single word
./h5: convert the original one HDF5 file which contains weights to several txt files
./model: all weights in txt version, with high precision (at least for float and double)


### other
constant.h: RNN dimensions, word dictionary size, etc.
load_data.c: load weights and datasets from txt files to C
params_init.c: initialize weights to zeros (usually used with malloc)



## H5dump

list all contents:
h5dump -n pre-trained-rnn.h5

open an attribute
h5dump -a "/model_weights/dense_1/weight_names" pre-trained-rnn.h5

view a dataset (show weights)
h5dump -d "/model_weights/dense_1/dense_1/bias:0" pre-trained-rnn.h5

h5 to txt:
h5dump -o dense_1_bias.txt -y -w 1000000000 dense_1_bias.h5
