{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Word Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('./data/word_dict.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    word_dict = {rows[0]:int(rows[1]) for rows in reader}\n",
    "    \n",
    "with open('./data/index_dict.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    index_dict = {int(rows[0]):rows[1] for rows in reader}\n",
    "    \n",
    "index_dict[0] = 'UNKNOWN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'a': 2,\n",
       " 'of': 3,\n",
       " '.': 4,\n",
       " ',': 5,\n",
       " 'and': 6,\n",
       " 'to': 7,\n",
       " 'network': 8,\n",
       " 'neural': 9,\n",
       " 'is': 10,\n",
       " 'for': 11,\n",
       " 'in': 12,\n",
       " 'The': 13,\n",
       " 'an': 14,\n",
       " 'data': 15,\n",
       " 'are': 16,\n",
       " 'by': 17,\n",
       " 'A': 18,\n",
       " 'input': 19,\n",
       " 'system': 20,\n",
       " 'with': 21,\n",
       " 'output': 22,\n",
       " 'or': 23,\n",
       " 'from': 24,\n",
       " 'which': 25,\n",
       " 'be': 26,\n",
       " 'as': 27,\n",
       " 'that': 28,\n",
       " 'on': 29,\n",
       " 'signal': 30,\n",
       " 'method': 31,\n",
       " 'each': 32,\n",
       " 'one': 33,\n",
       " 'image': 34,\n",
       " 'at': 35,\n",
       " 'using': 36,\n",
       " 'plurality': 37,\n",
       " 'first': 38,\n",
       " 'layer': 39,\n",
       " 'can': 40,\n",
       " 'includes': 41,\n",
       " 'set': 42,\n",
       " 'training': 43,\n",
       " 'control': 44,\n",
       " 'may': 45,\n",
       " 'processing': 46,\n",
       " 'based': 47,\n",
       " 'values': 48,\n",
       " 'second': 49,\n",
       " 'information': 50,\n",
       " 'signals': 51,\n",
       " 'model': 52,\n",
       " 'value': 53,\n",
       " 'used': 54,\n",
       " 'process': 55,\n",
       " 'learning': 56,\n",
       " 'neuron': 57,\n",
       " 'least': 58,\n",
       " 'pattern': 59,\n",
       " 'such': 60,\n",
       " 'device': 61,\n",
       " 'between': 62,\n",
       " 'time': 63,\n",
       " 'In': 64,\n",
       " 'circuit': 65,\n",
       " 'vector': 66,\n",
       " 'unit': 67,\n",
       " 'having': 68,\n",
       " 'into': 69,\n",
       " 'neurons': 70,\n",
       " 'apparatus': 71,\n",
       " 'function': 72,\n",
       " 'trained': 73,\n",
       " 'more': 74,\n",
       " 'invention': 75,\n",
       " 'An': 76,\n",
       " 'parameters': 77,\n",
       " 'provided': 78,\n",
       " 'corresponding': 79,\n",
       " 'feature': 80,\n",
       " 'recognition': 81,\n",
       " 'artificial': 82,\n",
       " 'networks': 83,\n",
       " 'has': 84,\n",
       " 'also': 85,\n",
       " 'weight': 86,\n",
       " 'number': 87,\n",
       " 'then': 88,\n",
       " 'state': 89,\n",
       " 'inputs': 90,\n",
       " 'present': 91,\n",
       " 'object': 92,\n",
       " 'memory': 93,\n",
       " 'speech': 94,\n",
       " 'including': 95,\n",
       " 'associated': 96,\n",
       " 'computer': 97,\n",
       " 'comprises': 98,\n",
       " 'other': 99,\n",
       " 'through': 100,\n",
       " 'images': 101,\n",
       " 'sensor': 102,\n",
       " 'outputs': 103,\n",
       " 'within': 104,\n",
       " 'parameter': 105,\n",
       " 'vectors': 106,\n",
       " 'error': 107,\n",
       " 'use': 108,\n",
       " 'generate': 109,\n",
       " 'operation': 110,\n",
       " 'determined': 111,\n",
       " 'nodes': 112,\n",
       " 'current': 113,\n",
       " 'controller': 114,\n",
       " 'Each': 115,\n",
       " 'elements': 116,\n",
       " 'user': 117,\n",
       " 'node': 118,\n",
       " 'connected': 119,\n",
       " 'predetermined': 120,\n",
       " 'weights': 121,\n",
       " 'response': 122,\n",
       " 'processor': 123,\n",
       " 'systems': 124,\n",
       " 'provides': 125,\n",
       " 'features': 126,\n",
       " 'determine': 127,\n",
       " 'determining': 128,\n",
       " 'analysis': 129,\n",
       " 'patterns': 130,\n",
       " 'digital': 131,\n",
       " 'target': 132,\n",
       " 'disclosed': 133,\n",
       " 'selected': 134,\n",
       " 'different': 135,\n",
       " 'stored': 136,\n",
       " 'means': 137,\n",
       " 'algorithm': 138,\n",
       " 'being': 139,\n",
       " 'generated': 140,\n",
       " 'provide': 141,\n",
       " 'include': 142,\n",
       " 'generating': 143,\n",
       " 'array': 144,\n",
       " 'and/or': 145,\n",
       " 'multiple': 146,\n",
       " 'module': 147,\n",
       " 'structure': 148,\n",
       " 'This': 149,\n",
       " 'methods': 150,\n",
       " 'so': 151,\n",
       " 'respective': 152,\n",
       " 'applied': 153,\n",
       " 'when': 154,\n",
       " 'obtained': 155,\n",
       " 'classification': 156,\n",
       " 'two': 157,\n",
       " 'said': 158,\n",
       " '.sub': 159,\n",
       " 'element': 160,\n",
       " 'during': 161,\n",
       " 'wherein': 162,\n",
       " 'variables': 163,\n",
       " 'further': 164,\n",
       " 'form': 165,\n",
       " 'embodiment': 166,\n",
       " 'vehicle': 167,\n",
       " 'comprising': 168,\n",
       " 'desired': 169,\n",
       " 'color': 170,\n",
       " 'matrix': 171,\n",
       " 'sequence': 172,\n",
       " 'this': 173,\n",
       " 'detection': 174,\n",
       " 'according': 175,\n",
       " 'synapse': 176,\n",
       " 'fuzzy': 177,\n",
       " 'result': 178,\n",
       " 'receiving': 179,\n",
       " 'providing': 180,\n",
       " 'it': 181,\n",
       " 'not': 182,\n",
       " 'results': 183,\n",
       " 'representing': 184,\n",
       " 'hidden': 185,\n",
       " 'sets': 186,\n",
       " 'connection': 187,\n",
       " 'all': 188,\n",
       " 'characteristics': 189,\n",
       " 'layers': 190,\n",
       " 'its': 191,\n",
       " 'uses': 192,\n",
       " 'predicted': 193,\n",
       " 'operating': 194,\n",
       " 'component': 195,\n",
       " 'configured': 196,\n",
       " 'units': 197,\n",
       " 'example': 198,\n",
       " 'frequency': 199,\n",
       " 'processed': 200,\n",
       " 'engine': 201,\n",
       " 'new': 202,\n",
       " 'generates': 203,\n",
       " 'light': 204,\n",
       " 'adaptive': 205,\n",
       " 'characteristic': 206,\n",
       " 'particular': 207,\n",
       " 'performance': 208,\n",
       " 'receives': 209,\n",
       " 'than': 210,\n",
       " 'position': 211,\n",
       " 'condition': 212,\n",
       " 'functions': 213,\n",
       " 'have': 214,\n",
       " 'produce': 215,\n",
       " 'order': 216,\n",
       " 'conditions': 217,\n",
       " 'detected': 218,\n",
       " 'performed': 219,\n",
       " 'part': 220,\n",
       " 'optical': 221,\n",
       " 'type': 222,\n",
       " 'models': 223,\n",
       " 'reference': 224,\n",
       " 'level': 225,\n",
       " 'logic': 226,\n",
       " 'components': 227,\n",
       " 'known': 228,\n",
       " 'received': 229,\n",
       " 'variable': 230,\n",
       " 'measured': 231,\n",
       " 'sample': 232,\n",
       " 'voltage': 233,\n",
       " 'given': 234,\n",
       " 'performing': 235,\n",
       " 'any': 236,\n",
       " 'analog': 237,\n",
       " 'difference': 238,\n",
       " 'threshold': 239,\n",
       " 'upon': 240,\n",
       " 'high': 241,\n",
       " 'detecting': 242,\n",
       " 'extracted': 243,\n",
       " 'group': 244,\n",
       " 'another': 245,\n",
       " 'storage': 246,\n",
       " 'whether': 247,\n",
       " 'described': 248,\n",
       " 'section': 249,\n",
       " 'objects': 250,\n",
       " 'where': 251,\n",
       " 'rate': 252,\n",
       " 'portion': 253,\n",
       " 'accordance': 254,\n",
       " 'devices': 255,\n",
       " 'temperature': 256,\n",
       " 'been': 257,\n",
       " 'basis': 258,\n",
       " 'application': 259,\n",
       " 'computing': 260,\n",
       " 'controlling': 261,\n",
       " 'location': 262,\n",
       " 'power': 263,\n",
       " 'via': 264,\n",
       " 'synaptic': 265,\n",
       " 'acoustic': 266,\n",
       " 'controlled': 267,\n",
       " 'area': 268,\n",
       " 'electronic': 269,\n",
       " 'feedback': 270,\n",
       " 'character': 271,\n",
       " 'space': 272,\n",
       " 'nonlinear': 273,\n",
       " 'out': 274,\n",
       " 'circuits': 275,\n",
       " 'techniques': 276,\n",
       " 'samples': 277,\n",
       " 'classifier': 278,\n",
       " 'cell': 279,\n",
       " 'sensors': 280,\n",
       " 'representation': 281,\n",
       " 'same': 282,\n",
       " 'these': 283,\n",
       " 'coupled': 284,\n",
       " 'energy': 285,\n",
       " 'point': 286,\n",
       " 'single': 287,\n",
       " 'database': 288,\n",
       " 'various': 289,\n",
       " 'both': 290,\n",
       " 'points': 291,\n",
       " 'region': 292,\n",
       " 'calculated': 293,\n",
       " 'field': 294,\n",
       " 'steps': 295,\n",
       " 'representative': 296,\n",
       " 'combination': 297,\n",
       " 'linear': 298,\n",
       " 'audio': 299,\n",
       " 'thereby': 300,\n",
       " 'architecture': 301,\n",
       " 'train': 302,\n",
       " 'program': 303,\n",
       " 'over': 304,\n",
       " 'weighted': 305,\n",
       " 'cells': 306,\n",
       " 'weighting': 307,\n",
       " 'formed': 308,\n",
       " 'prediction': 309,\n",
       " 'source': 310,\n",
       " 'block': 311,\n",
       " 'change': 312,\n",
       " 'event': 313,\n",
       " 'video': 314,\n",
       " 'class': 315,\n",
       " 'if': 316,\n",
       " '.g': 317,\n",
       " 'convolutional': 318,\n",
       " 'implemented': 319,\n",
       " 'only': 320,\n",
       " 'noise': 321,\n",
       " 'internal': 322,\n",
       " 'intermediate': 323,\n",
       " 'coefficients': 324,\n",
       " 'test': 325,\n",
       " 'product': 326,\n",
       " 'dynamic': 327,\n",
       " 'obtain': 328,\n",
       " 'decision': 329,\n",
       " 'indicative': 330,\n",
       " 'patient': 331,\n",
       " 'content': 332,\n",
       " 'machine': 333,\n",
       " 'monitoring': 334,\n",
       " 'well': 335,\n",
       " 'storing': 336,\n",
       " 'distance': 337,\n",
       " 'determines': 338,\n",
       " 'actual': 339,\n",
       " 'integrated': 340,\n",
       " 'local': 341,\n",
       " 'parallel': 342,\n",
       " 'measurements': 343,\n",
       " 'series': 344,\n",
       " 'made': 345,\n",
       " 'connections': 346,\n",
       " 'automatically': 347,\n",
       " 'derived': 348,\n",
       " 'physical': 349,\n",
       " 'step': 350,\n",
       " 'initial': 351,\n",
       " 'plant': 352,\n",
       " 'phase': 353,\n",
       " 'extraction': 354,\n",
       " 'filter': 355,\n",
       " 'combined': 356,\n",
       " 'mode': 357,\n",
       " 'specific': 358,\n",
       " 'pressure': 359,\n",
       " 'identify': 360,\n",
       " 'subject': 361,\n",
       " 'related': 362,\n",
       " 'line': 363,\n",
       " 'regions': 364,\n",
       " 'map': 365,\n",
       " 'while': 366,\n",
       " 'back': 367,\n",
       " 'search': 368,\n",
       " 'pixel': 369,\n",
       " 'rules': 370,\n",
       " 'estimated': 371,\n",
       " 'either': 372,\n",
       " 'receive': 373,\n",
       " 'detector': 374,\n",
       " 'about': 375,\n",
       " 'third': 376,\n",
       " 'processes': 377,\n",
       " 'rule': 378,\n",
       " 'domain': 379,\n",
       " 'range': 380,\n",
       " 'identifying': 381,\n",
       " 'measurement': 382,\n",
       " 'distribution': 383,\n",
       " 'learned': 384,\n",
       " 'capable': 385,\n",
       " 'calculating': 386,\n",
       " 'quality': 387,\n",
       " 'measuring': 388,\n",
       " 'individual': 389,\n",
       " 'perform': 390,\n",
       " 'flow': 391,\n",
       " 'real': 392,\n",
       " 'without': 393,\n",
       " 'optimal': 394,\n",
       " 'correction': 395,\n",
       " 'communication': 396,\n",
       " 'after': 397,\n",
       " 'text': 398,\n",
       " 'unknown': 399,\n",
       " 'defined': 400,\n",
       " 'channel': 401,\n",
       " 'speed': 402,\n",
       " 'base': 403,\n",
       " 'interface': 404,\n",
       " 'operations': 405,\n",
       " 'words': 406,\n",
       " 'binary': 407,\n",
       " 'evaluation': 408,\n",
       " 'N': 409,\n",
       " 'environment': 410,\n",
       " 'candidate': 411,\n",
       " 'real-time': 412,\n",
       " 'their': 413,\n",
       " 'surface': 414,\n",
       " 'amount': 415,\n",
       " 'technique': 416,\n",
       " 'synapses': 417,\n",
       " 'visual': 418,\n",
       " 'probability': 419,\n",
       " 'adapted': 420,\n",
       " 'recurrent': 421,\n",
       " 'identified': 422,\n",
       " 'preferably': 423,\n",
       " 'electrical': 424,\n",
       " 'utilizing': 425,\n",
       " 'Neural': 426,\n",
       " 'activation': 427,\n",
       " 'characters': 428,\n",
       " 'presented': 429,\n",
       " 'predicting': 430,\n",
       " 'predict': 431,\n",
       " 'applying': 432,\n",
       " 'changes': 433,\n",
       " 'factors': 434,\n",
       " 'query': 435,\n",
       " 'levels': 436,\n",
       " 'potential': 437,\n",
       " 'motor': 438,\n",
       " 'ANN': 439,\n",
       " 'transform': 440,\n",
       " 'category': 441,\n",
       " 'three': 442,\n",
       " 'lines': 443,\n",
       " 'identification': 444,\n",
       " 'One': 445,\n",
       " 'estimate': 446,\n",
       " 'inference': 447,\n",
       " 'pixels': 448,\n",
       " 'interconnected': 449,\n",
       " 'produced': 450,\n",
       " 'degree': 451,\n",
       " 'display': 452,\n",
       " 'some': 453,\n",
       " 'obtaining': 454,\n",
       " 'those': 455,\n",
       " 'automatic': 456,\n",
       " 'deep': 457,\n",
       " 'ratio': 458,\n",
       " 'document': 459,\n",
       " 'among': 460,\n",
       " 'calculation': 461,\n",
       " 'detect': 462,\n",
       " 'arrangement': 463,\n",
       " 'knowledge': 464,\n",
       " 'For': 465,\n",
       " 'code': 466,\n",
       " 'These': 467,\n",
       " 'along': 468,\n",
       " 'accuracy': 469,\n",
       " 'adjusted': 470,\n",
       " 'language': 471,\n",
       " 'pair': 472,\n",
       " 'spatial': 473,\n",
       " '(e': 474,\n",
       " 'will': 475,\n",
       " 'estimation': 476,\n",
       " 'compared': 477,\n",
       " 'media': 478,\n",
       " 'analyzing': 479,\n",
       " 'inputted': 480,\n",
       " 'transmission': 481,\n",
       " 'thereof': 482,\n",
       " 'original': 483,\n",
       " 'sum': 484,\n",
       " 'relationship': 485,\n",
       " 'possible': 486,\n",
       " 'coupling': 487,\n",
       " 'If': 488,\n",
       " 'respect': 489,\n",
       " 'normal': 490,\n",
       " 'recognize': 491,\n",
       " 'relative': 492,\n",
       " 'interest': 493,\n",
       " 'extracting': 494,\n",
       " 'problem': 495,\n",
       " 'allows': 496,\n",
       " 'containing': 497,\n",
       " 'optimization': 498,\n",
       " 'states': 499,\n",
       " 'context': 500,\n",
       " 'activity': 501,\n",
       " 'employed': 502,\n",
       " 'pulse': 503,\n",
       " 'relates': 504,\n",
       " 'selection': 505,\n",
       " 'final': 506,\n",
       " 'stage': 507,\n",
       " 'selecting': 508,\n",
       " 'thus': 509,\n",
       " 'size': 510,\n",
       " 'mapping': 511,\n",
       " 'similar': 512,\n",
       " 'utilized': 513,\n",
       " 'embodiments': 514,\n",
       " 'Methods': 515,\n",
       " 'non-linear': 516,\n",
       " 'large': 517,\n",
       " 'locations': 518,\n",
       " 'supplied': 519,\n",
       " 'waveform': 520,\n",
       " 'modeling': 521,\n",
       " 'cost': 522,\n",
       " 'indicating': 523,\n",
       " 'produces': 524,\n",
       " 'behavior': 525,\n",
       " 'terms': 526,\n",
       " 'manner': 527,\n",
       " 'human': 528,\n",
       " 'external': 529,\n",
       " 'under': 530,\n",
       " 'estimating': 531,\n",
       " 'frames': 532,\n",
       " 'frame': 533,\n",
       " 'constructed': 534,\n",
       " 'determination': 535,\n",
       " 'station': 536,\n",
       " 'computed': 537,\n",
       " 'outputting': 538,\n",
       " 'classes': 539,\n",
       " 'gas': 540,\n",
       " 'complex': 541,\n",
       " 'performs': 542,\n",
       " 'bit': 543,\n",
       " 'strength': 544,\n",
       " 'face': 545,\n",
       " 'arranged': 546,\n",
       " 'addition': 547,\n",
       " 'programs': 548,\n",
       " 'traffic': 549,\n",
       " 'improved': 550,\n",
       " 'modified': 551,\n",
       " 'charge': 552,\n",
       " 'comparing': 553,\n",
       " 'transformed': 554,\n",
       " 'represents': 555,\n",
       " 'word': 556,\n",
       " 'driving': 557,\n",
       " 'resulting': 558,\n",
       " 'gate': 559,\n",
       " 'recognizing': 560,\n",
       " 'clusters': 561,\n",
       " 'fault': 562,\n",
       " 'design': 563,\n",
       " 'associative': 564,\n",
       " 'body': 565,\n",
       " 'classifying': 566,\n",
       " 'events': 567,\n",
       " 'template': 568,\n",
       " 'matching': 569,\n",
       " 'utilizes': 570,\n",
       " 'spectral': 571,\n",
       " 'times': 572,\n",
       " 'low': 573,\n",
       " 'score': 574,\n",
       " 'material': 575,\n",
       " 'previously': 576,\n",
       " 'appropriate': 577,\n",
       " 'represented': 578,\n",
       " 'learn': 579,\n",
       " 'voice': 580,\n",
       " 'but': 581,\n",
       " 'attributes': 582,\n",
       " 'reduced': 583,\n",
       " 'brain': 584,\n",
       " 'expert': 585,\n",
       " 'normalized': 586,\n",
       " 'automated': 587,\n",
       " 'monitored': 588,\n",
       " 'action': 589,\n",
       " 'encoded': 590,\n",
       " 'inputting': 591,\n",
       " 'optimum': 592,\n",
       " 'algorithms': 593,\n",
       " 'comparison': 594,\n",
       " 'respectively': 595,\n",
       " 'forming': 596,\n",
       " 'producing': 597,\n",
       " 'implementation': 598,\n",
       " 'predictive': 599,\n",
       " 'window': 600,\n",
       " 'processors': 601,\n",
       " 'configuration': 602,\n",
       " 'propagation': 603,\n",
       " 'classified': 604,\n",
       " 'additional': 605,\n",
       " 'quantity': 606,\n",
       " 'required': 607,\n",
       " 'software': 608,\n",
       " 'preferred': 609,\n",
       " 'At': 610,\n",
       " 'statistical': 611,\n",
       " 'represent': 612,\n",
       " 'correlation': 613,\n",
       " 'recognized': 614,\n",
       " 'subset': 615,\n",
       " 'segment': 616,\n",
       " 'collected': 617,\n",
       " 'spectrum': 618,\n",
       " 'most': 619,\n",
       " 'responsive': 620,\n",
       " 'hardware': 621,\n",
       " 'properties': 622,\n",
       " 'electrode': 623,\n",
       " 'measure': 624,\n",
       " 'relating': 625,\n",
       " 'global': 626,\n",
       " 'differential': 627,\n",
       " 'presence': 628,\n",
       " 'operates': 629,\n",
       " 'shape': 630,\n",
       " 'minimum': 631,\n",
       " 'located': 632,\n",
       " 'path': 633,\n",
       " 'optimized': 634,\n",
       " 'until': 635,\n",
       " 'direction': 636,\n",
       " 'sensing': 637,\n",
       " 'up': 638,\n",
       " 'tissue': 639,\n",
       " 'transformation': 640,\n",
       " 'applications': 641,\n",
       " 'future': 642,\n",
       " 'groups': 643,\n",
       " 'mechanism': 644,\n",
       " 'standard': 645,\n",
       " 'When': 646,\n",
       " 'assigned': 647,\n",
       " 'conventional': 648,\n",
       " 'movement': 649,\n",
       " 'case': 650,\n",
       " 'mobile': 651,\n",
       " 'distributed': 652,\n",
       " 'types': 653,\n",
       " 'select': 654,\n",
       " 'fed': 655,\n",
       " 'stream': 656,\n",
       " 'electric': 657,\n",
       " 'corresponds': 658,\n",
       " 'analyzed': 659,\n",
       " 'fixed': 660,\n",
       " 'transfer': 661,\n",
       " 'combustion': 662,\n",
       " 'available': 663,\n",
       " 'together': 664,\n",
       " 'phoneme': 665,\n",
       " 'common': 666,\n",
       " 'whose': 667,\n",
       " 'signature': 668,\n",
       " 'directly': 669,\n",
       " 'air': 670,\n",
       " 'coefficient': 671,\n",
       " 'cluster': 672,\n",
       " 'maximum': 673,\n",
       " 'core': 674,\n",
       " 'contains': 675,\n",
       " 'approach': 676,\n",
       " 'index': 677,\n",
       " 'several': 678,\n",
       " 'load': 679,\n",
       " 'included': 680,\n",
       " 'pairs': 681,\n",
       " 'collection': 682,\n",
       " 'Network': 683,\n",
       " 'computation': 684,\n",
       " 'create': 685,\n",
       " 'medium': 686,\n",
       " 'access': 687,\n",
       " 'match': 688,\n",
       " 'herein': 689,\n",
       " 'generator': 690,\n",
       " 'average': 691,\n",
       " 'improve': 692,\n",
       " 'prior': 693,\n",
       " 'period': 694,\n",
       " 'converting': 695,\n",
       " 'person': 696,\n",
       " 'production': 697,\n",
       " 'density': 698,\n",
       " 'calculates': 699,\n",
       " 'amplifier': 700,\n",
       " 'general': 701,\n",
       " 'necessary': 702,\n",
       " 'semiconductor': 703,\n",
       " 'medical': 704,\n",
       " 'following': 705,\n",
       " 'formation': 706,\n",
       " 'background': 707,\n",
       " 'analyzer': 708,\n",
       " 'subsequent': 709,\n",
       " 'classify': 710,\n",
       " 'converted': 711,\n",
       " 'column': 712,\n",
       " 'wavelet': 713,\n",
       " 'radiation': 714,\n",
       " 'previous': 715,\n",
       " 'After': 716,\n",
       " 'physiological': 717,\n",
       " 'genetic': 718,\n",
       " 'stores': 719,\n",
       " 'correspond': 720,\n",
       " 'likelihood': 721,\n",
       " 'evaluating': 722,\n",
       " 'estimates': 723,\n",
       " 'camera': 724,\n",
       " 'angle': 725,\n",
       " 'useful': 726,\n",
       " 'center': 727,\n",
       " 'generation': 728,\n",
       " 'controls': 729,\n",
       " 'operational': 730,\n",
       " 'lower': 731,\n",
       " 'spike': 732,\n",
       " 'breathing': 733,\n",
       " 'diagnostic': 734,\n",
       " 'reduce': 735,\n",
       " 'electrodes': 736,\n",
       " 'During': 737,\n",
       " 'created': 738,\n",
       " 'cycle': 739,\n",
       " 'forward': 740,\n",
       " 'effect': 741,\n",
       " 'volume': 742,\n",
       " 'Fourier': 743,\n",
       " 'intelligent': 744,\n",
       " 'vibration': 745,\n",
       " 'drive': 746,\n",
       " 'communications': 747,\n",
       " 'efficiency': 748,\n",
       " 'measures': 749,\n",
       " 'table': 750,\n",
       " 'technology': 751,\n",
       " 'partial': 752,\n",
       " 'transmitted': 753,\n",
       " 'achieved': 754,\n",
       " 'service': 755,\n",
       " 'conversion': 756,\n",
       " 'floating': 757,\n",
       " 'representations': 758,\n",
       " 'suitable': 759,\n",
       " 'relationships': 760,\n",
       " 'updated': 761,\n",
       " 'dimension': 762,\n",
       " 'heart': 763,\n",
       " 'packet': 764,\n",
       " 'monitor': 765,\n",
       " 'analyzes': 766,\n",
       " 'smaller': 767,\n",
       " 'imaging': 768,\n",
       " 'categories': 769,\n",
       " 'It': 770,\n",
       " 'operate': 771,\n",
       " 'delay': 772,\n",
       " 'characterized': 773,\n",
       " 'interconnection': 774,\n",
       " 'tool': 775,\n",
       " 'moving': 776,\n",
       " 'confidence': 777,\n",
       " 'main': 778,\n",
       " 'total': 779,\n",
       " 'positions': 780,\n",
       " 'read': 781,\n",
       " 'solution': 782,\n",
       " 'adjusting': 783,\n",
       " 'speaker': 784,\n",
       " 'loop': 785,\n",
       " 'historical': 786,\n",
       " 'setting': 787,\n",
       " 'abnormal': 788,\n",
       " 'n': 789,\n",
       " 'etc': 790,\n",
       " 'fluid': 791,\n",
       " 'scores': 792,\n",
       " 'implementing': 793,\n",
       " 'sampling': 794,\n",
       " 'membership': 795,\n",
       " 'health': 796,\n",
       " 'By': 797,\n",
       " 'discrete': 798,\n",
       " 'store': 799,\n",
       " 'key': 800,\n",
       " 'row': 801,\n",
       " '(ANN)': 802,\n",
       " 'comprise': 803,\n",
       " 'cardiac': 804,\n",
       " 'structures': 805,\n",
       " 'operator': 806,\n",
       " 'similarity': 807,\n",
       " 'problems': 808,\n",
       " 'primary': 809,\n",
       " 'higher': 810,\n",
       " 'battery': 811,\n",
       " 'errors': 812,\n",
       " 'modules': 813,\n",
       " 'particularly': 814,\n",
       " 'temporal': 815,\n",
       " 'objective': 816,\n",
       " 'variety': 817,\n",
       " 'dimensional': 818,\n",
       " 'multiplier': 819,\n",
       " 'three-dimensional': 820,\n",
       " 'aspect': 821,\n",
       " 'e': 822,\n",
       " 'correct': 823,\n",
       " 'indicates': 824,\n",
       " 'basic': 825,\n",
       " 'calculate': 826,\n",
       " 'testing': 827,\n",
       " 'efficient': 828,\n",
       " 'spiking': 829,\n",
       " 'documents': 830,\n",
       " 'accurate': 831,\n",
       " 'active': 832,\n",
       " 'portions': 833,\n",
       " 'accurately': 834,\n",
       " 'making': 835,\n",
       " 'employs': 836,\n",
       " 'unsupervised': 837,\n",
       " 'semantic': 838,\n",
       " 'hybrid': 839,\n",
       " 'onto': 840,\n",
       " 'supervised': 841,\n",
       " 'examples': 842,\n",
       " 'certain': 843,\n",
       " 'filtering': 844,\n",
       " 'factor': 845,\n",
       " 'resistance': 846,\n",
       " 'products': 847,\n",
       " 'independent': 848,\n",
       " 'bus': 849,\n",
       " 'small': 850,\n",
       " 'joint': 851,\n",
       " 'converter': 852,\n",
       " 'scheme': 853,\n",
       " 'sequences': 854,\n",
       " 'DNN': 855,\n",
       " 'length': 856,\n",
       " 'dependent': 857,\n",
       " 'water': 858,\n",
       " 'neuronal': 859,\n",
       " 'thermal': 860,\n",
       " 'sound': 861,\n",
       " 'highly': 862,\n",
       " 'substantially': 863,\n",
       " 'Once': 864,\n",
       " 'capability': 865,\n",
       " 'magnetic': 866,\n",
       " 'carried': 867,\n",
       " 'plural': 868,\n",
       " 'scale': 869,\n",
       " 'motion': 870,\n",
       " 'computational': 871,\n",
       " 'address': 872,\n",
       " 'intelligence': 873,\n",
       " 'relevant': 874,\n",
       " 'tensor': 875,\n",
       " 'employing': 876,\n",
       " 'simultaneously': 877,\n",
       " 'updating': 878,\n",
       " 'Systems': 879,\n",
       " 'feedforward': 880,\n",
       " 'creating': 881,\n",
       " 'actions': 882,\n",
       " 'utterance': 883,\n",
       " 'To': 884,\n",
       " 'Thus': 885,\n",
       " 'As': 886,\n",
       " 'overall': 887,\n",
       " 'infrared': 888,\n",
       " 'quantities': 889,\n",
       " 'beam': 890,\n",
       " 'back-propagation': 891,\n",
       " 'directed': 892,\n",
       " 'digitized': 893,\n",
       " 'selects': 894,\n",
       " 'Also': 895,\n",
       " 'fuel': 896,\n",
       " 'before': 897,\n",
       " 'gradient': 898,\n",
       " 'positive': 899,\n",
       " 'concentration': 900,\n",
       " 'functional': 901,\n",
       " 'probabilities': 902,\n",
       " 'adjust': 903,\n",
       " 'Then': 904,\n",
       " 'displayed': 905,\n",
       " 'existing': 906,\n",
       " 'switch': 907,\n",
       " 'many': 908,\n",
       " 'transmitting': 909,\n",
       " 'extract': 910,\n",
       " 'adjustment': 911,\n",
       " 'no': 912,\n",
       " 'random': 913,\n",
       " 'inverse': 914,\n",
       " 'term': 915,\n",
       " 'detects': 916,\n",
       " 'taken': 917,\n",
       " 'net': 918,\n",
       " 'depending': 919,\n",
       " 'maps': 920,\n",
       " 'risk': 921,\n",
       " 'status': 922,\n",
       " 'molecular': 923,\n",
       " 'regression': 924,\n",
       " 'history': 925,\n",
       " 'chip': 926,\n",
       " 'selectively': 927,\n",
       " 'cause': 928,\n",
       " 'programmed': 929,\n",
       " 'changed': 930,\n",
       " 'manufacturing': 931,\n",
       " 'was': 932,\n",
       " 'operable': 933,\n",
       " 'seismic': 934,\n",
       " 'sources': 935,\n",
       " 'transistor': 936,\n",
       " 'simple': 937,\n",
       " 'sequentially': 938,\n",
       " 'depth': 939,\n",
       " 'equal': 940,\n",
       " 'segmented': 941,\n",
       " 'item': 942,\n",
       " 'drilling': 943,\n",
       " 'axon': 944,\n",
       " 'dynamically': 945,\n",
       " 'tasks': 946,\n",
       " 'evaluated': 947,\n",
       " 'segmentation': 948,\n",
       " 'resolution': 949,\n",
       " 'Embodiments': 950,\n",
       " 'wireless': 951,\n",
       " \"user's\": 952,\n",
       " 'property': 953,\n",
       " 'circuitry': 954,\n",
       " 'programmable': 955,\n",
       " 'Additionally': 956,\n",
       " 'switching': 957,\n",
       " 'thereto': 958,\n",
       " 'contained': 959,\n",
       " 'way': 960,\n",
       " 'blocks': 961,\n",
       " 'list': 962,\n",
       " 'less': 963,\n",
       " 'paths': 964,\n",
       " 'novel': 965,\n",
       " 'procedure': 966,\n",
       " 'differences': 967,\n",
       " 'generally': 968,\n",
       " 'combining': 969,\n",
       " 'does': 970,\n",
       " 'run': 971,\n",
       " 'changing': 972,\n",
       " 'natural': 973,\n",
       " 'continuous': 974,\n",
       " 'format': 975,\n",
       " 'Such': 976,\n",
       " 'there': 977,\n",
       " 'users': 978,\n",
       " 'items': 979,\n",
       " 'reduction': 980,\n",
       " 'picture': 981,\n",
       " 'amplitude': 982,\n",
       " 'quantization': 983,\n",
       " 'channels': 984,\n",
       " 'Further': 985,\n",
       " 'developed': 986,\n",
       " 'tracking': 987,\n",
       " 'filters': 988,\n",
       " 'records': 989,\n",
       " 'separate': 990,\n",
       " 'enable': 991,\n",
       " 'significant': 992,\n",
       " 'involves': 993,\n",
       " 'expected': 994,\n",
       " 'mathematical': 995,\n",
       " 'enables': 996,\n",
       " 'teaching': 997,\n",
       " 'intensity': 998,\n",
       " 'support': 999,\n",
       " 'areas': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'the',\n",
       " 2: 'a',\n",
       " 3: 'of',\n",
       " 4: '.',\n",
       " 5: ',',\n",
       " 6: 'and',\n",
       " 7: 'to',\n",
       " 8: 'network',\n",
       " 9: 'neural',\n",
       " 10: 'is',\n",
       " 11: 'for',\n",
       " 12: 'in',\n",
       " 13: 'The',\n",
       " 14: 'an',\n",
       " 15: 'data',\n",
       " 16: 'are',\n",
       " 17: 'by',\n",
       " 18: 'A',\n",
       " 19: 'input',\n",
       " 20: 'system',\n",
       " 21: 'with',\n",
       " 22: 'output',\n",
       " 23: 'or',\n",
       " 24: 'from',\n",
       " 25: 'which',\n",
       " 26: 'be',\n",
       " 27: 'as',\n",
       " 28: 'that',\n",
       " 29: 'on',\n",
       " 30: 'signal',\n",
       " 31: 'method',\n",
       " 32: 'each',\n",
       " 33: 'one',\n",
       " 34: 'image',\n",
       " 35: 'at',\n",
       " 36: 'using',\n",
       " 37: 'plurality',\n",
       " 38: 'first',\n",
       " 39: 'layer',\n",
       " 40: 'can',\n",
       " 41: 'includes',\n",
       " 42: 'set',\n",
       " 43: 'training',\n",
       " 44: 'control',\n",
       " 45: 'may',\n",
       " 46: 'processing',\n",
       " 47: 'based',\n",
       " 48: 'values',\n",
       " 49: 'second',\n",
       " 50: 'information',\n",
       " 51: 'signals',\n",
       " 52: 'model',\n",
       " 53: 'value',\n",
       " 54: 'used',\n",
       " 55: 'process',\n",
       " 56: 'learning',\n",
       " 57: 'neuron',\n",
       " 58: 'least',\n",
       " 59: 'pattern',\n",
       " 60: 'such',\n",
       " 61: 'device',\n",
       " 62: 'between',\n",
       " 63: 'time',\n",
       " 64: 'In',\n",
       " 65: 'circuit',\n",
       " 66: 'vector',\n",
       " 67: 'unit',\n",
       " 68: 'having',\n",
       " 69: 'into',\n",
       " 70: 'neurons',\n",
       " 71: 'apparatus',\n",
       " 72: 'function',\n",
       " 73: 'trained',\n",
       " 74: 'more',\n",
       " 75: 'invention',\n",
       " 76: 'An',\n",
       " 77: 'parameters',\n",
       " 78: 'provided',\n",
       " 79: 'corresponding',\n",
       " 80: 'feature',\n",
       " 81: 'recognition',\n",
       " 82: 'artificial',\n",
       " 83: 'networks',\n",
       " 84: 'has',\n",
       " 85: 'also',\n",
       " 86: 'weight',\n",
       " 87: 'number',\n",
       " 88: 'then',\n",
       " 89: 'state',\n",
       " 90: 'inputs',\n",
       " 91: 'present',\n",
       " 92: 'object',\n",
       " 93: 'memory',\n",
       " 94: 'speech',\n",
       " 95: 'including',\n",
       " 96: 'associated',\n",
       " 97: 'computer',\n",
       " 98: 'comprises',\n",
       " 99: 'other',\n",
       " 100: 'through',\n",
       " 101: 'images',\n",
       " 102: 'sensor',\n",
       " 103: 'outputs',\n",
       " 104: 'within',\n",
       " 105: 'parameter',\n",
       " 106: 'vectors',\n",
       " 107: 'error',\n",
       " 108: 'use',\n",
       " 109: 'generate',\n",
       " 110: 'operation',\n",
       " 111: 'determined',\n",
       " 112: 'nodes',\n",
       " 113: 'current',\n",
       " 114: 'controller',\n",
       " 115: 'Each',\n",
       " 116: 'elements',\n",
       " 117: 'user',\n",
       " 118: 'node',\n",
       " 119: 'connected',\n",
       " 120: 'predetermined',\n",
       " 121: 'weights',\n",
       " 122: 'response',\n",
       " 123: 'processor',\n",
       " 124: 'systems',\n",
       " 125: 'provides',\n",
       " 126: 'features',\n",
       " 127: 'determine',\n",
       " 128: 'determining',\n",
       " 129: 'analysis',\n",
       " 130: 'patterns',\n",
       " 131: 'digital',\n",
       " 132: 'target',\n",
       " 133: 'disclosed',\n",
       " 134: 'selected',\n",
       " 135: 'different',\n",
       " 136: 'stored',\n",
       " 137: 'means',\n",
       " 138: 'algorithm',\n",
       " 139: 'being',\n",
       " 140: 'generated',\n",
       " 141: 'provide',\n",
       " 142: 'include',\n",
       " 143: 'generating',\n",
       " 144: 'array',\n",
       " 145: 'and/or',\n",
       " 146: 'multiple',\n",
       " 147: 'module',\n",
       " 148: 'structure',\n",
       " 149: 'This',\n",
       " 150: 'methods',\n",
       " 151: 'so',\n",
       " 152: 'respective',\n",
       " 153: 'applied',\n",
       " 154: 'when',\n",
       " 155: 'obtained',\n",
       " 156: 'classification',\n",
       " 157: 'two',\n",
       " 158: 'said',\n",
       " 159: '.sub',\n",
       " 160: 'element',\n",
       " 161: 'during',\n",
       " 162: 'wherein',\n",
       " 163: 'variables',\n",
       " 164: 'further',\n",
       " 165: 'form',\n",
       " 166: 'embodiment',\n",
       " 167: 'vehicle',\n",
       " 168: 'comprising',\n",
       " 169: 'desired',\n",
       " 170: 'color',\n",
       " 171: 'matrix',\n",
       " 172: 'sequence',\n",
       " 173: 'this',\n",
       " 174: 'detection',\n",
       " 175: 'according',\n",
       " 176: 'synapse',\n",
       " 177: 'fuzzy',\n",
       " 178: 'result',\n",
       " 179: 'receiving',\n",
       " 180: 'providing',\n",
       " 181: 'it',\n",
       " 182: 'not',\n",
       " 183: 'results',\n",
       " 184: 'representing',\n",
       " 185: 'hidden',\n",
       " 186: 'sets',\n",
       " 187: 'connection',\n",
       " 188: 'all',\n",
       " 189: 'characteristics',\n",
       " 190: 'layers',\n",
       " 191: 'its',\n",
       " 192: 'uses',\n",
       " 193: 'predicted',\n",
       " 194: 'operating',\n",
       " 195: 'component',\n",
       " 196: 'configured',\n",
       " 197: 'units',\n",
       " 198: 'example',\n",
       " 199: 'frequency',\n",
       " 200: 'processed',\n",
       " 201: 'engine',\n",
       " 202: 'new',\n",
       " 203: 'generates',\n",
       " 204: 'light',\n",
       " 205: 'adaptive',\n",
       " 206: 'characteristic',\n",
       " 207: 'particular',\n",
       " 208: 'performance',\n",
       " 209: 'receives',\n",
       " 210: 'than',\n",
       " 211: 'position',\n",
       " 212: 'condition',\n",
       " 213: 'functions',\n",
       " 214: 'have',\n",
       " 215: 'produce',\n",
       " 216: 'order',\n",
       " 217: 'conditions',\n",
       " 218: 'detected',\n",
       " 219: 'performed',\n",
       " 220: 'part',\n",
       " 221: 'optical',\n",
       " 222: 'type',\n",
       " 223: 'models',\n",
       " 224: 'reference',\n",
       " 225: 'level',\n",
       " 226: 'logic',\n",
       " 227: 'components',\n",
       " 228: 'known',\n",
       " 229: 'received',\n",
       " 230: 'variable',\n",
       " 231: 'measured',\n",
       " 232: 'sample',\n",
       " 233: 'voltage',\n",
       " 234: 'given',\n",
       " 235: 'performing',\n",
       " 236: 'any',\n",
       " 237: 'analog',\n",
       " 238: 'difference',\n",
       " 239: 'threshold',\n",
       " 240: 'upon',\n",
       " 241: 'high',\n",
       " 242: 'detecting',\n",
       " 243: 'extracted',\n",
       " 244: 'group',\n",
       " 245: 'another',\n",
       " 246: 'storage',\n",
       " 247: 'whether',\n",
       " 248: 'described',\n",
       " 249: 'section',\n",
       " 250: 'objects',\n",
       " 251: 'where',\n",
       " 252: 'rate',\n",
       " 253: 'portion',\n",
       " 254: 'accordance',\n",
       " 255: 'devices',\n",
       " 256: 'temperature',\n",
       " 257: 'been',\n",
       " 258: 'basis',\n",
       " 259: 'application',\n",
       " 260: 'computing',\n",
       " 261: 'controlling',\n",
       " 262: 'location',\n",
       " 263: 'power',\n",
       " 264: 'via',\n",
       " 265: 'synaptic',\n",
       " 266: 'acoustic',\n",
       " 267: 'controlled',\n",
       " 268: 'area',\n",
       " 269: 'electronic',\n",
       " 270: 'feedback',\n",
       " 271: 'character',\n",
       " 272: 'space',\n",
       " 273: 'nonlinear',\n",
       " 274: 'out',\n",
       " 275: 'circuits',\n",
       " 276: 'techniques',\n",
       " 277: 'samples',\n",
       " 278: 'classifier',\n",
       " 279: 'cell',\n",
       " 280: 'sensors',\n",
       " 281: 'representation',\n",
       " 282: 'same',\n",
       " 283: 'these',\n",
       " 284: 'coupled',\n",
       " 285: 'energy',\n",
       " 286: 'point',\n",
       " 287: 'single',\n",
       " 288: 'database',\n",
       " 289: 'various',\n",
       " 290: 'both',\n",
       " 291: 'points',\n",
       " 292: 'region',\n",
       " 293: 'calculated',\n",
       " 294: 'field',\n",
       " 295: 'steps',\n",
       " 296: 'representative',\n",
       " 297: 'combination',\n",
       " 298: 'linear',\n",
       " 299: 'audio',\n",
       " 300: 'thereby',\n",
       " 301: 'architecture',\n",
       " 302: 'train',\n",
       " 303: 'program',\n",
       " 304: 'over',\n",
       " 305: 'weighted',\n",
       " 306: 'cells',\n",
       " 307: 'weighting',\n",
       " 308: 'formed',\n",
       " 309: 'prediction',\n",
       " 310: 'source',\n",
       " 311: 'block',\n",
       " 312: 'change',\n",
       " 313: 'event',\n",
       " 314: 'video',\n",
       " 315: 'class',\n",
       " 316: 'if',\n",
       " 317: '.g',\n",
       " 318: 'convolutional',\n",
       " 319: 'implemented',\n",
       " 320: 'only',\n",
       " 321: 'noise',\n",
       " 322: 'internal',\n",
       " 323: 'intermediate',\n",
       " 324: 'coefficients',\n",
       " 325: 'test',\n",
       " 326: 'product',\n",
       " 327: 'dynamic',\n",
       " 328: 'obtain',\n",
       " 329: 'decision',\n",
       " 330: 'indicative',\n",
       " 331: 'patient',\n",
       " 332: 'content',\n",
       " 333: 'machine',\n",
       " 334: 'monitoring',\n",
       " 335: 'well',\n",
       " 336: 'storing',\n",
       " 337: 'distance',\n",
       " 338: 'determines',\n",
       " 339: 'actual',\n",
       " 340: 'integrated',\n",
       " 341: 'local',\n",
       " 342: 'parallel',\n",
       " 343: 'measurements',\n",
       " 344: 'series',\n",
       " 345: 'made',\n",
       " 346: 'connections',\n",
       " 347: 'automatically',\n",
       " 348: 'derived',\n",
       " 349: 'physical',\n",
       " 350: 'step',\n",
       " 351: 'initial',\n",
       " 352: 'plant',\n",
       " 353: 'phase',\n",
       " 354: 'extraction',\n",
       " 355: 'filter',\n",
       " 356: 'combined',\n",
       " 357: 'mode',\n",
       " 358: 'specific',\n",
       " 359: 'pressure',\n",
       " 360: 'identify',\n",
       " 361: 'subject',\n",
       " 362: 'related',\n",
       " 363: 'line',\n",
       " 364: 'regions',\n",
       " 365: 'map',\n",
       " 366: 'while',\n",
       " 367: 'back',\n",
       " 368: 'search',\n",
       " 369: 'pixel',\n",
       " 370: 'rules',\n",
       " 371: 'estimated',\n",
       " 372: 'either',\n",
       " 373: 'receive',\n",
       " 374: 'detector',\n",
       " 375: 'about',\n",
       " 376: 'third',\n",
       " 377: 'processes',\n",
       " 378: 'rule',\n",
       " 379: 'domain',\n",
       " 380: 'range',\n",
       " 381: 'identifying',\n",
       " 382: 'measurement',\n",
       " 383: 'distribution',\n",
       " 384: 'learned',\n",
       " 385: 'capable',\n",
       " 386: 'calculating',\n",
       " 387: 'quality',\n",
       " 388: 'measuring',\n",
       " 389: 'individual',\n",
       " 390: 'perform',\n",
       " 391: 'flow',\n",
       " 392: 'real',\n",
       " 393: 'without',\n",
       " 394: 'optimal',\n",
       " 395: 'correction',\n",
       " 396: 'communication',\n",
       " 397: 'after',\n",
       " 398: 'text',\n",
       " 399: 'unknown',\n",
       " 400: 'defined',\n",
       " 401: 'channel',\n",
       " 402: 'speed',\n",
       " 403: 'base',\n",
       " 404: 'interface',\n",
       " 405: 'operations',\n",
       " 406: 'words',\n",
       " 407: 'binary',\n",
       " 408: 'evaluation',\n",
       " 409: 'N',\n",
       " 410: 'environment',\n",
       " 411: 'candidate',\n",
       " 412: 'real-time',\n",
       " 413: 'their',\n",
       " 414: 'surface',\n",
       " 415: 'amount',\n",
       " 416: 'technique',\n",
       " 417: 'synapses',\n",
       " 418: 'visual',\n",
       " 419: 'probability',\n",
       " 420: 'adapted',\n",
       " 421: 'recurrent',\n",
       " 422: 'identified',\n",
       " 423: 'preferably',\n",
       " 424: 'electrical',\n",
       " 425: 'utilizing',\n",
       " 426: 'Neural',\n",
       " 427: 'activation',\n",
       " 428: 'characters',\n",
       " 429: 'presented',\n",
       " 430: 'predicting',\n",
       " 431: 'predict',\n",
       " 432: 'applying',\n",
       " 433: 'changes',\n",
       " 434: 'factors',\n",
       " 435: 'query',\n",
       " 436: 'levels',\n",
       " 437: 'potential',\n",
       " 438: 'motor',\n",
       " 439: 'ANN',\n",
       " 440: 'transform',\n",
       " 441: 'category',\n",
       " 442: 'three',\n",
       " 443: 'lines',\n",
       " 444: 'identification',\n",
       " 445: 'One',\n",
       " 446: 'estimate',\n",
       " 447: 'inference',\n",
       " 448: 'pixels',\n",
       " 449: 'interconnected',\n",
       " 450: 'produced',\n",
       " 451: 'degree',\n",
       " 452: 'display',\n",
       " 453: 'some',\n",
       " 454: 'obtaining',\n",
       " 455: 'those',\n",
       " 456: 'automatic',\n",
       " 457: 'deep',\n",
       " 458: 'ratio',\n",
       " 459: 'document',\n",
       " 460: 'among',\n",
       " 461: 'calculation',\n",
       " 462: 'detect',\n",
       " 463: 'arrangement',\n",
       " 464: 'knowledge',\n",
       " 465: 'For',\n",
       " 466: 'code',\n",
       " 467: 'These',\n",
       " 468: 'along',\n",
       " 469: 'accuracy',\n",
       " 470: 'adjusted',\n",
       " 471: 'language',\n",
       " 472: 'pair',\n",
       " 473: 'spatial',\n",
       " 474: '(e',\n",
       " 475: 'will',\n",
       " 476: 'estimation',\n",
       " 477: 'compared',\n",
       " 478: 'media',\n",
       " 479: 'analyzing',\n",
       " 480: 'inputted',\n",
       " 481: 'transmission',\n",
       " 482: 'thereof',\n",
       " 483: 'original',\n",
       " 484: 'sum',\n",
       " 485: 'relationship',\n",
       " 486: 'possible',\n",
       " 487: 'coupling',\n",
       " 488: 'If',\n",
       " 489: 'respect',\n",
       " 490: 'normal',\n",
       " 491: 'recognize',\n",
       " 492: 'relative',\n",
       " 493: 'interest',\n",
       " 494: 'extracting',\n",
       " 495: 'problem',\n",
       " 496: 'allows',\n",
       " 497: 'containing',\n",
       " 498: 'optimization',\n",
       " 499: 'states',\n",
       " 500: 'context',\n",
       " 501: 'activity',\n",
       " 502: 'employed',\n",
       " 503: 'pulse',\n",
       " 504: 'relates',\n",
       " 505: 'selection',\n",
       " 506: 'final',\n",
       " 507: 'stage',\n",
       " 508: 'selecting',\n",
       " 509: 'thus',\n",
       " 510: 'size',\n",
       " 511: 'mapping',\n",
       " 512: 'similar',\n",
       " 513: 'utilized',\n",
       " 514: 'embodiments',\n",
       " 515: 'Methods',\n",
       " 516: 'non-linear',\n",
       " 517: 'large',\n",
       " 518: 'locations',\n",
       " 519: 'supplied',\n",
       " 520: 'waveform',\n",
       " 521: 'modeling',\n",
       " 522: 'cost',\n",
       " 523: 'indicating',\n",
       " 524: 'produces',\n",
       " 525: 'behavior',\n",
       " 526: 'terms',\n",
       " 527: 'manner',\n",
       " 528: 'human',\n",
       " 529: 'external',\n",
       " 530: 'under',\n",
       " 531: 'estimating',\n",
       " 532: 'frames',\n",
       " 533: 'frame',\n",
       " 534: 'constructed',\n",
       " 535: 'determination',\n",
       " 536: 'station',\n",
       " 537: 'computed',\n",
       " 538: 'outputting',\n",
       " 539: 'classes',\n",
       " 540: 'gas',\n",
       " 541: 'complex',\n",
       " 542: 'performs',\n",
       " 543: 'bit',\n",
       " 544: 'strength',\n",
       " 545: 'face',\n",
       " 546: 'arranged',\n",
       " 547: 'addition',\n",
       " 548: 'programs',\n",
       " 549: 'traffic',\n",
       " 550: 'improved',\n",
       " 551: 'modified',\n",
       " 552: 'charge',\n",
       " 553: 'comparing',\n",
       " 554: 'transformed',\n",
       " 555: 'represents',\n",
       " 556: 'word',\n",
       " 557: 'driving',\n",
       " 558: 'resulting',\n",
       " 559: 'gate',\n",
       " 560: 'recognizing',\n",
       " 561: 'clusters',\n",
       " 562: 'fault',\n",
       " 563: 'design',\n",
       " 564: 'associative',\n",
       " 565: 'body',\n",
       " 566: 'classifying',\n",
       " 567: 'events',\n",
       " 568: 'template',\n",
       " 569: 'matching',\n",
       " 570: 'utilizes',\n",
       " 571: 'spectral',\n",
       " 572: 'times',\n",
       " 573: 'low',\n",
       " 574: 'score',\n",
       " 575: 'material',\n",
       " 576: 'previously',\n",
       " 577: 'appropriate',\n",
       " 578: 'represented',\n",
       " 579: 'learn',\n",
       " 580: 'voice',\n",
       " 581: 'but',\n",
       " 582: 'attributes',\n",
       " 583: 'reduced',\n",
       " 584: 'brain',\n",
       " 585: 'expert',\n",
       " 586: 'normalized',\n",
       " 587: 'automated',\n",
       " 588: 'monitored',\n",
       " 589: 'action',\n",
       " 590: 'encoded',\n",
       " 591: 'inputting',\n",
       " 592: 'optimum',\n",
       " 593: 'algorithms',\n",
       " 594: 'comparison',\n",
       " 595: 'respectively',\n",
       " 596: 'forming',\n",
       " 597: 'producing',\n",
       " 598: 'implementation',\n",
       " 599: 'predictive',\n",
       " 600: 'window',\n",
       " 601: 'processors',\n",
       " 602: 'configuration',\n",
       " 603: 'propagation',\n",
       " 604: 'classified',\n",
       " 605: 'additional',\n",
       " 606: 'quantity',\n",
       " 607: 'required',\n",
       " 608: 'software',\n",
       " 609: 'preferred',\n",
       " 610: 'At',\n",
       " 611: 'statistical',\n",
       " 612: 'represent',\n",
       " 613: 'correlation',\n",
       " 614: 'recognized',\n",
       " 615: 'subset',\n",
       " 616: 'segment',\n",
       " 617: 'collected',\n",
       " 618: 'spectrum',\n",
       " 619: 'most',\n",
       " 620: 'responsive',\n",
       " 621: 'hardware',\n",
       " 622: 'properties',\n",
       " 623: 'electrode',\n",
       " 624: 'measure',\n",
       " 625: 'relating',\n",
       " 626: 'global',\n",
       " 627: 'differential',\n",
       " 628: 'presence',\n",
       " 629: 'operates',\n",
       " 630: 'shape',\n",
       " 631: 'minimum',\n",
       " 632: 'located',\n",
       " 633: 'path',\n",
       " 634: 'optimized',\n",
       " 635: 'until',\n",
       " 636: 'direction',\n",
       " 637: 'sensing',\n",
       " 638: 'up',\n",
       " 639: 'tissue',\n",
       " 640: 'transformation',\n",
       " 641: 'applications',\n",
       " 642: 'future',\n",
       " 643: 'groups',\n",
       " 644: 'mechanism',\n",
       " 645: 'standard',\n",
       " 646: 'When',\n",
       " 647: 'assigned',\n",
       " 648: 'conventional',\n",
       " 649: 'movement',\n",
       " 650: 'case',\n",
       " 651: 'mobile',\n",
       " 652: 'distributed',\n",
       " 653: 'types',\n",
       " 654: 'select',\n",
       " 655: 'fed',\n",
       " 656: 'stream',\n",
       " 657: 'electric',\n",
       " 658: 'corresponds',\n",
       " 659: 'analyzed',\n",
       " 660: 'fixed',\n",
       " 661: 'transfer',\n",
       " 662: 'combustion',\n",
       " 663: 'available',\n",
       " 664: 'together',\n",
       " 665: 'phoneme',\n",
       " 666: 'common',\n",
       " 667: 'whose',\n",
       " 668: 'signature',\n",
       " 669: 'directly',\n",
       " 670: 'air',\n",
       " 671: 'coefficient',\n",
       " 672: 'cluster',\n",
       " 673: 'maximum',\n",
       " 674: 'core',\n",
       " 675: 'contains',\n",
       " 676: 'approach',\n",
       " 677: 'index',\n",
       " 678: 'several',\n",
       " 679: 'load',\n",
       " 680: 'included',\n",
       " 681: 'pairs',\n",
       " 682: 'collection',\n",
       " 683: 'Network',\n",
       " 684: 'computation',\n",
       " 685: 'create',\n",
       " 686: 'medium',\n",
       " 687: 'access',\n",
       " 688: 'match',\n",
       " 689: 'herein',\n",
       " 690: 'generator',\n",
       " 691: 'average',\n",
       " 692: 'improve',\n",
       " 693: 'prior',\n",
       " 694: 'period',\n",
       " 695: 'converting',\n",
       " 696: 'person',\n",
       " 697: 'production',\n",
       " 698: 'density',\n",
       " 699: 'calculates',\n",
       " 700: 'amplifier',\n",
       " 701: 'general',\n",
       " 702: 'necessary',\n",
       " 703: 'semiconductor',\n",
       " 704: 'medical',\n",
       " 705: 'following',\n",
       " 706: 'formation',\n",
       " 707: 'background',\n",
       " 708: 'analyzer',\n",
       " 709: 'subsequent',\n",
       " 710: 'classify',\n",
       " 711: 'converted',\n",
       " 712: 'column',\n",
       " 713: 'wavelet',\n",
       " 714: 'radiation',\n",
       " 715: 'previous',\n",
       " 716: 'After',\n",
       " 717: 'physiological',\n",
       " 718: 'genetic',\n",
       " 719: 'stores',\n",
       " 720: 'correspond',\n",
       " 721: 'likelihood',\n",
       " 722: 'evaluating',\n",
       " 723: 'estimates',\n",
       " 724: 'camera',\n",
       " 725: 'angle',\n",
       " 726: 'useful',\n",
       " 727: 'center',\n",
       " 728: 'generation',\n",
       " 729: 'controls',\n",
       " 730: 'operational',\n",
       " 731: 'lower',\n",
       " 732: 'spike',\n",
       " 733: 'breathing',\n",
       " 734: 'diagnostic',\n",
       " 735: 'reduce',\n",
       " 736: 'electrodes',\n",
       " 737: 'During',\n",
       " 738: 'created',\n",
       " 739: 'cycle',\n",
       " 740: 'forward',\n",
       " 741: 'effect',\n",
       " 742: 'volume',\n",
       " 743: 'Fourier',\n",
       " 744: 'intelligent',\n",
       " 745: 'vibration',\n",
       " 746: 'drive',\n",
       " 747: 'communications',\n",
       " 748: 'efficiency',\n",
       " 749: 'measures',\n",
       " 750: 'table',\n",
       " 751: 'technology',\n",
       " 752: 'partial',\n",
       " 753: 'transmitted',\n",
       " 754: 'achieved',\n",
       " 755: 'service',\n",
       " 756: 'conversion',\n",
       " 757: 'floating',\n",
       " 758: 'representations',\n",
       " 759: 'suitable',\n",
       " 760: 'relationships',\n",
       " 761: 'updated',\n",
       " 762: 'dimension',\n",
       " 763: 'heart',\n",
       " 764: 'packet',\n",
       " 765: 'monitor',\n",
       " 766: 'analyzes',\n",
       " 767: 'smaller',\n",
       " 768: 'imaging',\n",
       " 769: 'categories',\n",
       " 770: 'It',\n",
       " 771: 'operate',\n",
       " 772: 'delay',\n",
       " 773: 'characterized',\n",
       " 774: 'interconnection',\n",
       " 775: 'tool',\n",
       " 776: 'moving',\n",
       " 777: 'confidence',\n",
       " 778: 'main',\n",
       " 779: 'total',\n",
       " 780: 'positions',\n",
       " 781: 'read',\n",
       " 782: 'solution',\n",
       " 783: 'adjusting',\n",
       " 784: 'speaker',\n",
       " 785: 'loop',\n",
       " 786: 'historical',\n",
       " 787: 'setting',\n",
       " 788: 'abnormal',\n",
       " 789: 'n',\n",
       " 790: 'etc',\n",
       " 791: 'fluid',\n",
       " 792: 'scores',\n",
       " 793: 'implementing',\n",
       " 794: 'sampling',\n",
       " 795: 'membership',\n",
       " 796: 'health',\n",
       " 797: 'By',\n",
       " 798: 'discrete',\n",
       " 799: 'store',\n",
       " 800: 'key',\n",
       " 801: 'row',\n",
       " 802: '(ANN)',\n",
       " 803: 'comprise',\n",
       " 804: 'cardiac',\n",
       " 805: 'structures',\n",
       " 806: 'operator',\n",
       " 807: 'similarity',\n",
       " 808: 'problems',\n",
       " 809: 'primary',\n",
       " 810: 'higher',\n",
       " 811: 'battery',\n",
       " 812: 'errors',\n",
       " 813: 'modules',\n",
       " 814: 'particularly',\n",
       " 815: 'temporal',\n",
       " 816: 'objective',\n",
       " 817: 'variety',\n",
       " 818: 'dimensional',\n",
       " 819: 'multiplier',\n",
       " 820: 'three-dimensional',\n",
       " 821: 'aspect',\n",
       " 822: 'e',\n",
       " 823: 'correct',\n",
       " 824: 'indicates',\n",
       " 825: 'basic',\n",
       " 826: 'calculate',\n",
       " 827: 'testing',\n",
       " 828: 'efficient',\n",
       " 829: 'spiking',\n",
       " 830: 'documents',\n",
       " 831: 'accurate',\n",
       " 832: 'active',\n",
       " 833: 'portions',\n",
       " 834: 'accurately',\n",
       " 835: 'making',\n",
       " 836: 'employs',\n",
       " 837: 'unsupervised',\n",
       " 838: 'semantic',\n",
       " 839: 'hybrid',\n",
       " 840: 'onto',\n",
       " 841: 'supervised',\n",
       " 842: 'examples',\n",
       " 843: 'certain',\n",
       " 844: 'filtering',\n",
       " 845: 'factor',\n",
       " 846: 'resistance',\n",
       " 847: 'products',\n",
       " 848: 'independent',\n",
       " 849: 'bus',\n",
       " 850: 'small',\n",
       " 851: 'joint',\n",
       " 852: 'converter',\n",
       " 853: 'scheme',\n",
       " 854: 'sequences',\n",
       " 855: 'DNN',\n",
       " 856: 'length',\n",
       " 857: 'dependent',\n",
       " 858: 'water',\n",
       " 859: 'neuronal',\n",
       " 860: 'thermal',\n",
       " 861: 'sound',\n",
       " 862: 'highly',\n",
       " 863: 'substantially',\n",
       " 864: 'Once',\n",
       " 865: 'capability',\n",
       " 866: 'magnetic',\n",
       " 867: 'carried',\n",
       " 868: 'plural',\n",
       " 869: 'scale',\n",
       " 870: 'motion',\n",
       " 871: 'computational',\n",
       " 872: 'address',\n",
       " 873: 'intelligence',\n",
       " 874: 'relevant',\n",
       " 875: 'tensor',\n",
       " 876: 'employing',\n",
       " 877: 'simultaneously',\n",
       " 878: 'updating',\n",
       " 879: 'Systems',\n",
       " 880: 'feedforward',\n",
       " 881: 'creating',\n",
       " 882: 'actions',\n",
       " 883: 'utterance',\n",
       " 884: 'To',\n",
       " 885: 'Thus',\n",
       " 886: 'As',\n",
       " 887: 'overall',\n",
       " 888: 'infrared',\n",
       " 889: 'quantities',\n",
       " 890: 'beam',\n",
       " 891: 'back-propagation',\n",
       " 892: 'directed',\n",
       " 893: 'digitized',\n",
       " 894: 'selects',\n",
       " 895: 'Also',\n",
       " 896: 'fuel',\n",
       " 897: 'before',\n",
       " 898: 'gradient',\n",
       " 899: 'positive',\n",
       " 900: 'concentration',\n",
       " 901: 'functional',\n",
       " 902: 'probabilities',\n",
       " 903: 'adjust',\n",
       " 904: 'Then',\n",
       " 905: 'displayed',\n",
       " 906: 'existing',\n",
       " 907: 'switch',\n",
       " 908: 'many',\n",
       " 909: 'transmitting',\n",
       " 910: 'extract',\n",
       " 911: 'adjustment',\n",
       " 912: 'no',\n",
       " 913: 'random',\n",
       " 914: 'inverse',\n",
       " 915: 'term',\n",
       " 916: 'detects',\n",
       " 917: 'taken',\n",
       " 918: 'net',\n",
       " 919: 'depending',\n",
       " 920: 'maps',\n",
       " 921: 'risk',\n",
       " 922: 'status',\n",
       " 923: 'molecular',\n",
       " 924: 'regression',\n",
       " 925: 'history',\n",
       " 926: 'chip',\n",
       " 927: 'selectively',\n",
       " 928: 'cause',\n",
       " 929: 'programmed',\n",
       " 930: 'changed',\n",
       " 931: 'manufacturing',\n",
       " 932: 'was',\n",
       " 933: 'operable',\n",
       " 934: 'seismic',\n",
       " 935: 'sources',\n",
       " 936: 'transistor',\n",
       " 937: 'simple',\n",
       " 938: 'sequentially',\n",
       " 939: 'depth',\n",
       " 940: 'equal',\n",
       " 941: 'segmented',\n",
       " 942: 'item',\n",
       " 943: 'drilling',\n",
       " 944: 'axon',\n",
       " 945: 'dynamically',\n",
       " 946: 'tasks',\n",
       " 947: 'evaluated',\n",
       " 948: 'segmentation',\n",
       " 949: 'resolution',\n",
       " 950: 'Embodiments',\n",
       " 951: 'wireless',\n",
       " 952: \"user's\",\n",
       " 953: 'property',\n",
       " 954: 'circuitry',\n",
       " 955: 'programmable',\n",
       " 956: 'Additionally',\n",
       " 957: 'switching',\n",
       " 958: 'thereto',\n",
       " 959: 'contained',\n",
       " 960: 'way',\n",
       " 961: 'blocks',\n",
       " 962: 'list',\n",
       " 963: 'less',\n",
       " 964: 'paths',\n",
       " 965: 'novel',\n",
       " 966: 'procedure',\n",
       " 967: 'differences',\n",
       " 968: 'generally',\n",
       " 969: 'combining',\n",
       " 970: 'does',\n",
       " 971: 'run',\n",
       " 972: 'changing',\n",
       " 973: 'natural',\n",
       " 974: 'continuous',\n",
       " 975: 'format',\n",
       " 976: 'Such',\n",
       " 977: 'there',\n",
       " 978: 'users',\n",
       " 979: 'items',\n",
       " 980: 'reduction',\n",
       " 981: 'picture',\n",
       " 982: 'amplitude',\n",
       " 983: 'quantization',\n",
       " 984: 'channels',\n",
       " 985: 'Further',\n",
       " 986: 'developed',\n",
       " 987: 'tracking',\n",
       " 988: 'filters',\n",
       " 989: 'records',\n",
       " 990: 'separate',\n",
       " 991: 'enable',\n",
       " 992: 'significant',\n",
       " 993: 'involves',\n",
       " 994: 'expected',\n",
       " 995: 'mathematical',\n",
       " 996: 'enables',\n",
       " 997: 'teaching',\n",
       " 998: 'intensity',\n",
       " 999: 'support',\n",
       " 1000: 'areas',\n",
       " ...}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwq/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import get_model, find_closest, create_train_valid,  generate_output, guess_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\" A \"\"Barometer\"\" Neuron enhances stability in a Neural Network System that, when used as a track-while-scan system, assigns sensor plots to predicted track positions in a plot/track association situation. The \"\"Barometer\"\" Neuron functions as a bench-mark or reference system node that equates a superimposed plot and track to a zero distance as a \"\"perfect\"\" pairing of plot and track which has a measured/desired level of inhibition. The \"\"Barometer\"\" Neuron responds to the System inputs, compares these inputs against the level of inhibition of the \"\"perfect\"\" pair, and generates a supplied excitation or inhibition output signal to the System which adjusts the System to a desired value at or near 1.0; this the reference level of inhibition of the \"\"perfect\"\" pair. \"',\n",
       " '\" This invention is a novel high-speed neural network based processor for solving the \"\"traveling salesman\"\" and other global optimization problems. It comprises a novel hybrid architecture employing a binary synaptic array whose embodiment incorporates the fixed rules of the problem, such as the number of cities to be visited. The array is prompted by analog voltages representing variables such as distances. The processor incorporates two interconnected feedback networks, each of which solves part of the problem independently and simultaneously, yet which exchange information dynamically. \"',\n",
       " 'An optical information processor for use as a matrix vector multiplier comprises a vector input spatial light modulator (1) and an optically addressed weight matrix spatial light modulator (3). A read beam (10) passes through the input modulator (1) and the weight modulator and onto a combined output transducer and error spatial light modulator (5). The error modulator (5) is then controlled in accordance with the difference between a target output vector and the output vector from the transducer (5), and modulates an update beam (11) which then passes through the input modulator (1) and onto the weight modulator (3). The weight modulator (3) represents a two-dimensional array of optical attenuation values which are updated in accordance with the optical radiation incident thereon during updating.',\n",
       " 'A method and system for intelligent control of external devices using a mammalian brain-like structure having three parts. The method and system include a computer-implemented neural network system which is an extension of the model-based adaptive critic design and is applicable to real-time control (e.g., robotic control) and real-time distributed control. Additional uses include data visualization, data mining, and other tasks requiring complex analysis of inter-relationships between data.',\n",
       " 'A method and system for intelligent control of external devices using a mammalian brain-like structure having three parts. The method and system include a computer-implemented neural network system which is an extension of the model-based adaptive critic design and is applicable to real-time control (e.g., robotic control) and real-time distributed control. Additional uses include data visualization, data mining, and other tasks requiring complex analysis of inter-relationships between data.',\n",
       " '\" An unknown object is non-destructively and quantitatively evaluated for three-dimensional spatial distribution of a set of material constitutive parameters of the unknown object, using a multi-element array-source transducer and a multi-element array-detector transducer located near the unknown object. The array-source transducer exposes the array-detector transducer to a set of source-field patterns pursuant to a set of electrical input signals. An unknown object located near these transducers will be the cause of scattering, thus presenting a scattered-field pattern to the array detector transducer, for each pattern of the set of source-field patterns. In a related computation, a set of training signals is determined by evaluating on a computer the scattered field from a set of computer simulated training objects. A computer, a signal processor and a neural network operate from detector response to the computer simulated and unknown object scattered-field patterns, in each of two modes. In an initial mode, the neural network is \"\"trained\"\" or configured to process a set of transfer functions involved in array-detector response to scattered-field patterns evaluated by computer simulations for the known computer simulated objects; in another mode, the neural network utilizes its \"\"trained\"\" configuration in application to a set of transfer functions involved in array-detector response to scattered-field patterns produced by an unknown object, to generate estimates of the three-dimensional spatial distribution of the material constitutive parameters of the unknown object. In another embodiment, a set of the Biot poro-elastic material parameters of an unknown object is estimated. \"',\n",
       " '\" An unknown object is non-destructively and quantitatively evaluated for three-dimensional spatial distribution of a set of material constitutive parameters, using a multi-element array-source transducer and a multi-element array-detector transducer in spaced, mutually facing relation. The array-source transducer exposes the array-detector transducer to a set of source-field patterns pursuant to a set of electrical input signals. Either a known object or an unknown object positioned between these transducers will be the cause of scattering, thus presenting a scattered-field pattern to the array detector transducer, for each pattern of the set of source-field patterns. A computer, a signal processor and a neural network operate from detector response to each set of scattered-field patterns, in each of two modes. In an initial mode, the neural network is \"\"trained\"\" or configured to process a set of transfer functions involved in array-detector response to scattered-field patterns produced by the known object; in another mode, the neural network utilizes its \"\"trained\"\" configuration in application to a set of transfer functions involved in array-detector response to scattered-field patterns produced by an unknown object, to generate estimates of the three-dimensional spatial distribution of the material constitutive parameters of the unknown object. \"',\n",
       " 'A security system comprised of a device for monitoring an area under surveillance. The monitoring device produces images of the area. The security system is also comprised of a device for processing the images to determine whether the area is in a desired state or an undesired state. The processing device is trainable to learn the difference between the desired state and the undesired state. In a preferred embodiment, the monitoring device includes a video camera which produces video images of the area and the processing device includes a computer simulating a neural network. A method for determining whether an area under surveillance is in a desired state or an undesired state. The method comprises the steps of collecting data in a computer about the area which defines when the area is in the desired state or the undesired state. Next, training the computer from the collected data to essentially correctly identify when the area is in the desired state or in the undesired state while the area is under surveillance. Next, performing surveillance of the area with a computer such that the computer determines whether the area is in a desired state or the undesired state.',\n",
       " 'A target recognition system and method wherein only target amplitude data, i.e., coherent A-scan data, is interrogated for target recognition. Target aspect angle is ignored within the angular segmentation of the feature library without degrading classification performance. Observed signature characteristics are collected at various aspect angles and through unknown and arbitrary roll, pitch and yaw motions of each anticipated target and provided to a neural network as training sets. The neural network forms feature vectors for each target class which are useful for valid classification comparisons in all sea states, especially in calm and littoral waters. These feature vectors are useful for valid classification comparisons over at least 30 degrees of target aspect angle.',\n",
       " 'A target recognition system and method wherein only target amplitude data, i.e., coherent A-scan data, is interrogated at each of a plurality of range resolution cells along the radar line of sight path for target recognition. Target aspect angle is ignored within the angular segmentation of the feature library without degrading classification performance. Observed signature characteristics are collected at various aspect angles and through unknown roll, pitch and yaw motions of each anticipated target and provided to a neural network as training sets. The neural network forms feature vectors for each target class which are useful for valid classification comparisons in all sea states, especially in calm and littoral waters. These feature vectors are useful for valid classification comparisons over at least 30 degrees of target aspect angle.',\n",
       " 'A supervised procedure for obtaining weight values for back-propagation neural networks is described. The method according to the invention performs a sequence of partial optimizations in order to determine values for the network connection weights. The partial optimization depends on a constrained representation of hidden weights derived from a singular value decomposition of the input space as well as an Iterative Least Squares optimization solution for the output weights.',\n",
       " 'A method of accelerating the training of an artificial neural network uses a computer configured as an artificial neural network with a network input and a network output, and having a plurality of interconnected units arranged in layers including an input layer and an output layer. Each unit has a multiplicity of unit inputs and a set of variables for operating upon the unit inputs to provide a unit output. A plurality of examples are serially provided to the network input and the network output is observed. The computer is programmed with a back propagation algorithm for adjusting each set of variables in response to feedback representing differences between the network output for each example and the desired output. The examples are iterated while those values which change are identified. The examples are reiterated and the algorithm is applied to only those values which changed in a previous iteration.',\n",
       " 'An apparatus is described herein. The apparatus comprises an accumulator, a controller, and a convolutional neural network. The accumulator is to accumulate a plurality of values within a predetermined bit width. The controller is to determine a parameter quantization and a data quantization. The convolutional neural network is adapted to the data quantization, wherein a quantization point is selected based on the parameter quantization, data quantization, and accumulator bit width.',\n",
       " 'Approaches for accurate neural network training for library-based critical dimension (CD) metrology are described. Approaches for fast neural network training for library-based CD metrology are also described. In an example, a method includes optimizing a threshold for a principal component analysis (PCA) of a spectrum data set to provide a principal component (PC) value, estimating a training target for one or more neural networks, training the one or more neural networks based both on the training target and on the PC value provided from optimizing the threshold for the PCA, and providing a spectral library based on the one or more trained neural networks.',\n",
       " 'Embodiments are generally directed to neural network training for library-based critical dimension metrology. An embodiment of a method includes optimizing a threshold for a principal component analysis of a spectrum data set to provide a principal component value, estimating a training target for one or more neural networks, training the one or more neural networks based both on the training target and on the principal component value provided from optimizing the threshold for the principal component analysis, and providing a spectral library based on the one or more trained neural networks.',\n",
       " 'Systems and methods using a neural network based portable absorption spectrometer system for real-time automatic evaluation of tissue injury are described. An apparatus includes an electromagnetic signal generator; an optical fiber connected to the electromagnetic signal generator; a fiber optic probe connected to the optical fiber; a broad band spectrometer connected to the fiber optic probe; and a hybrid neural network connected to the broad band spectrometer. The hybrid neural network includes a principle component analyzer of broad band spectral data obtained from said broad band spectrometer.',\n",
       " 'A system for real-time analysis of weld quality in an arc welding process. he system includes a transducer which receives acoustic signals generated during the welding process. The acoustic signals are then sampled and digitized. A signal processor calculates the root mean square and peak amplitudes of the digitized signals and transforms the digitized signal into a frequency domain signal. A data processor divides the frequency domain signal into a plurality of frequency bands and calculates the average power for each band. The average power values, in addition to the peak and root mean square amplitude values, are input to an artificial neural network for analysis of weld quality. Arc current and/or arc voltage signals may be input to the A/D converter alone or in combination with the acoustic signal data for subsequent signal processing and neural network analysis.',\n",
       " 'A method and apparatus for identifying running vehicles in an area to be monitored using acoustic signature recognition. The apparatus includes an input sensor for capturing an acoustic waveform produced by a vehicle source, and a processing system. The waveform is digitized and divided into frames. Each frame is filtered into a plurality of gammatone filtered signals. At least one spectral feature vector is computed for each frame. The vectors are integrated across a plurality of frames to create a spectro-temporal representation of the vehicle waveform. In a training mode, values from the spectro-temporal representation are used as inputs to a Nonlinear Hebbian learning function to extract acoustic signatures and synaptic weights. In an active mode, the synaptic weights and acoustic signatures are used as patterns in a supervised associative network to identify whether a vehicle is present in the area to be monitored. In response to a vehicle being present, the class of vehicle is identified. Results may be provided to a central computer.',\n",
       " 'Tasks such as object classification from image data can take advantage of a deep learning process using convolutional neural networks. These networks can include a convolutional layer followed by an activation layer, or activation unit, among other potential layers. Improved accuracy can be obtained by using a generalized linear unit (GLU) as an activation unit in such a network, where a GLU is linear for both positive and negative inputs, and is defined by a positive slope, a negative slope, and a bias. These parameters can be learned for each channel or a block of channels, and stacking those types of activation units can further improve accuracy.',\n",
       " 'Active vibration control (AVC) systems without online path modeling and controller adjustment are provided that are able to adapt to an uncertain operating environment. The controller (250, 280, 315, 252, 282, 317, 254, 319) of such an AVC system is an adaptive recursive neural network whose weights are determined in an offline training and are held fixed online during the operation of the system. AVC feedforward, feedback, and feedforward-feedback systems in accordance with the present invention are described. An AVC feedforward system has no error sensor and an AVC feedback system has no reference sensor. All sensor outputs of an AVC system are processed by the controller for generating control signals to drive at least one secondary source (240). While an error sensor (480, 481) must be a vibrational sensor, a reference sensor (230, 270, 295, 305, 330) may be either a vibrational or nonvibrational sensor. The provided AVC systems reduce or eliminate most of such shortcomings of the prior-art AVC systems as use of an error sensor, relatively slow convergence of a weight/waveform adjustment algorithm, frequent adjustment of a path model, use of a high-order adaptive linear transversal filter, instability of an adaptive linear recursive filter, failure to use a useful nonvibrational reference sensor, failure to deal with the nonlinear behavior of a primary or secondary path, weight adjustment using control predicted values, use of an identification neural network, and online adjustment of the weights of a neural network.',\n",
       " 'Disclosed are an active delay method and an improved wireless binaural hearing device. The binaural hearing device includes: a first hearing device including a first microphone, an amplifier and a wireless transmitter; and a second hearing device including a second microphone, an amplifier, a wireless transmitter, a wireless receiver which receives a signal from the wireless transmitter, an active delay circuit which synchronizes the received signal with a signal acquired by the second microphone, a neural network which synchronizes the delayed signal, and a speaker which converts the synchronized signal into a voice signal. With this configuration, it is possible to prevent incorrect detection of the position of the sound source or paralalia due to a time delay which is produced in the wireless binaural hearing device and reduce noises due to a time difference between both hearing devices, thereby providing a binaural hearing device with high quality.',\n",
       " 'The present invention is predicated upon the fact that an emission trace from a plasma glow used in fabricating integrated circuits contains information about phenoma which cause variations in the fabrication process such as age of the plasma reactor, densities of the wafers exposed to the plasma, chemistry of the plasma, and concentration of the remaining material. In accordance with the present invention, a method for using neural networks to determine plasma etch end-point times in an integrated circuit fabrication process is disclosed. The end-point time is based on in-situ monitoring of the optical emission trace. The back-propagation method is used to train the network. More generally, a neural network can be used to regulate control variables and materials in a manufacturing process to yield an output product with desired quality attributes. An identified process signature which reflects the relation between the quality attribute and the process may be used to train the neural network.',\n",
       " 'The present invention is predicated upon the fact that an emission trace from a plasma glow used in fabricating integrated circuits contains information about phenoma which cause variations in the fabrication process such as age of the plasma reactor, densities of the wafers exposed to the plasma, chemistry of the plasma, and concentration of the remaining material. In accordance with the present invention, a method for using neural networks to determine plasma etch end-point times in an integrated circuit fabrication process is disclosed. The end-point time is based on in-situ monitoring of the optical emission trace. The back-propagation method is used to train the network. More generally, a neural network can be used to regulate control variables and materials in a manufacturing process to yield an output product with desired quality attributes. An identified process signature which reflects the relation between the quality attribute and the process may be used to train the neural network.',\n",
       " 'The present invention is predicated upon the fact that a process signature from a plasma process used in fabricating integrated circuits contains information about phenomena which cause variations in the fabrication process such as age of the plasma reactor, densities of the wafers exposed to the plasma, chemistry of the plasma, and concentration of the remaining material. In accordance with the present invention, a method for using neural networks to determine plasma etch end-point times in an integrated circuit fabrication process is disclosed. The end-point time is based on in-situ monitoring of at least two parameters during the plasma etch process. After the neural network is trained to associate a certain condition or set of conditions with the endpoint of the process, the neural network is used to control the process.',\n",
       " 'Noise data from a noise source is provided for a neural network. An output signal from the neural network is provided for a node of a hidden layer H of the neural network. The weight of the neural network is updated by an update unit according to an error signal e.sub.j0 detected by a microphone, thereby outputting a deadening sound from a speaker.',\n",
       " 'An improved active vibration control system using feedback and pseudo-feedforward sensor inputs is provided for solving the problem of random and repetitive active vibration control and noise cancellation in a system. In a first embodiment of the invention, an artificial neural network is used for learning the dynamics of a structure and for providing output signals that follow the state variables of the structure. In one implementation of the neural network, a plurality of neurons obtain biasing inputs derived from sensor inputs, as well as inputs from the other neurons in the network. Further, each neuron obtains a feedback input from itself. Each input to a neuron is weighted using a weighting function derived on-line. The neural network supplies structure parameters and state variables to an optimal controller which derives and provides a control signal to the actuators so as to counteract vibrations and/or noise sensed in the system. In a second embodiment an optimal controller utilizing a modified generalized predictive control algorithm is used to to consider the limitations on the physical characteristics of the actuator(s), on-line, in terms of the output level and the rate of change of the output in the system. Additional embodiments wherein an optimized control signal is sent to the actuator(s) to minimize vibration incident to the structure are provided.',\n",
       " \"Various technologies and techniques are disclosed for improving handwriting recognition using a neural network by allowing a user to provide samples. A recognition operation is performed on the user's handwritten input, and the user is not satisfied with the recognition result. The user selects an option to train the neural network on one or more characters to improve the recognition results. The user is prompted to specify samples for the certain character, word, or phrase, and the neural network is adjusted for the certain character, word, or phrase. Handwritten input is later received from the user. A recognition operation is performed on the handwritten input using the neural network that was adjusted for the certain character or characters.\",\n",
       " 'The invention describes a method and apparatus for effectively communicating data along the acoustic channel of a subterranean well. The method comprises optimally driving an acoustic transmitter with an adaptive transmitter controller. A data signal is transmitted along the acoustic channel and detected as a distorted signal along the acoustic channel. The distorted signal is input to the adaptive transmitter controller which, based on the detected signal, modifies later transmissions to counteract the distorting effects of the transmitter and acoustic channel. The adaptive transmitter controller preferably comprises a neural network. Another receiver may be employed, at a point further from the transmitter, to receive the optimized signals.',\n",
       " 'An adaptive agent including an artificial neural network having a plurality of input nodes for receiving input signals and a plurality of output nodes generating responses. A situation value unit receives a plurality of the responses and generating a situation value signal. A change sensor coupled to receive the situation value signal generates an output signal representing a change of the situation value signal from a prior time to a current time. A connection coupling the change sensor output to one of the input nodes of the artificial neural network.',\n",
       " \"An adaptive anti-collision method for vehicles has steps of creating multiple driving patterns with each driving pattern corresponding to a vehicle speed, a safe distance and a braking distance parameter, such as longer safe distance configured for faster vehicle speed, and higher vehicle speed or shorter safe distance for different road condition, acquiring dynamic information, such as vehicle speed or acceleration, of the vehicle using sensors on the vehicle, combining the dynamic information and drivers' driving behavior to determine a driving pattern through a statistical analysis and a neural network, adjusting control parameters of the vehicle according to the driving pattern for an electronic control unit of the vehicle to issue an alert or activate a braking action according to the driving pattern. Accordingly, the anti-collision method can be adapted to different vehicle speed, road condition and drivers' driving habits for adjusting the safe distance and the braking system.\",\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for neural network adaptive beamforming for multichannel speech recognition are disclosed. In one aspect, a method includes the actions of receiving a first channel of audio data corresponding to an utterance and a second channel of audio data corresponding to the utterance. The actions further include generating a first set of filter parameters for a first filter based on the first channel of audio data and the second channel of audio data and a second set of filter parameters for a second filter based on the first channel of audio data and the second channel of audio data. The actions further include generating a single combined channel of audio data. The actions further include inputting the audio data to a neural network. The actions further include providing a transcription for the utterance.',\n",
       " 'A system including a learning module and an algorithmic module for learning a physiological aspect of a patient body and regulating the delivery of a physiological agent to the body. An embodiment of the invention is an adaptive CRT device performing biventricular pacing in which the AV delay and VV interval parameters are changed dynamically according to the information supplied by the IEGM, hemodynamic sensor and online processed data, in order to achieve optimal hemodynamic performance.A learning module, preferably using artificial neural network, performs the adaptive part of the algorithm supervised by an algorithmic deterministic module, internally or externally from the implanted pacemaker or defibrillator.',\n",
       " 'An adaptive feed-back controlled system for regulating a physiological function of a heart in which a hemodynamic sensor continuously monitors the physiological performance of the heart. Three implanted electrodes sense and pace the right atrial, right ventricle and left ventricle. A learning neural network module receives and processes information for the electrodes (18) and sensors (22), and is controlled by a deterministic module for limiting said learning module. A pulse generator (16), is also controlled by the deterministic module, and stimulates both the heart and the vagus (20).',\n",
       " 'A neural network including a plurality of sub-nets stored in a memory array and a method of operation. Each of the sub-nets includes a corresponding plurality of weights and is individually operable to classify an input vector. A computation unit, including a distance calculation unit and a math unit, is responsive to an input vector comprising input training features for determining a distance between the weights of each sub-net to each of the input features of the input vector and for determining whether the distance is within a particular region of influence. Also described is a parallel process for training the sub-nets.',\n",
       " 'An adaptive packet mechanism and method for optimizing data packet transmission through a network connection between a sending node and a receiving node. Current network conditions in the connection are periodically determined wherein the network conditions pertain to the latency and jitter of packet transmission between the sending node and receiving node. The measurements of latency and jitter are used to determine an optimum packet size and an optimum inter-packet interval for transmission of packet data between the sending node and the receiving node and are used in the transmission of data packets from the sending node to the receiving node. Network conditions may be determined by transmission of monitor or data packets and may be determined at either or both of the sending or receiving nodes and the optimum packet size and inter-packet interval are determined by a fuzzy logic analyzer, a neural network analyzer or a combined fuzzy logic/neural network analyzer.',\n",
       " 'This invention relates a control strategy for a hybrid electric vehicle having an electric motor, a battery and an internal combustion engine. The control strategy improves fuel economy and reduces emissions while providing sufficient acceleration over a varying set of driving conditions through an adaptive control unit with an artificial neural network. The artificial neural network is trained on a pre-processed training set based on the highest fuel economies of multiple control strategies and multiple driving profiles. Training the artificial neural network includes a training algorithm and a learning algorithm. The invention also includes a method of operating a hybrid electric vehicle with an adaptive control strategy using an artificial neural network.',\n",
       " 'An adaptive control system (ACS) uses direct output feedback to control a plant. The ACS uses direct adaptive output feedback control developed for highly uncertain nonlinear systems, that does not rely on state estimation. The approach is also applicable to systems of unknown, but bounded dimension, whose output has known, but otherwise arbitrary relative degree. This includes systems with both parameter uncertainty and unmodeled dynamics. The result is achieved by extending the universal function approximation property of linearly parameterized neural networks to model unknown system dynamics from input/output data. The network weight adaptation rule is derived from Lyapunov stability analysis, and guarantees that the adapted weight errors and the tracking error are bounded.',\n",
       " 'An adaptive control system (ACS) uses direct output feedback to control a plant. The ACS uses direct adaptive output feedback control developed for highly uncertain nonlinear systems, that does not rely on state estimation. The approach is also applicable to systems of unknown, but bounded dimension, whose output has known, but otherwise arbitrary relative degree. This includes systems with both parameter uncertainty and unmodeled dynamics. The result is achieved by extending the universal function approximation property of linearly parameterized neural networks to model unknown system dynamics from input/output data. The network weight adaptation rule is derived from Lyapunov stability analysis, and guarantees that the adapted weight errors and the tracking error are bounded.',\n",
       " 'A neural network demodulator is used within a receiver to provide Inter Symbol Interference (ISI) channel equalization and to correct for I/Q/phase imbalance. The neural network is trained with a single integrated training step to simultaneously handle the channel impairments of ISI equalization and I/Q phase imbalance as opposed to prior art methods of separately addressing each channel impairment in sequence.',\n",
       " 'A channel equalizer is formed using a self-learning neural network. During a training period, the neural network is taught the channel response function. The network is then used to equalize distortions introduced into signals by the channel. The neural network may be a Boltzmann Machine type of neural network comprising neurons arranged in an input layer, a hidden layer, and an output layer. The neurons are interconnected by bidirectional symmetric weighted synapses. Each neuron is preferably implemented by an analog integrated circuit. Direct communication between the input and output layers helps in faster channel acquisition. The scheme can very easily be extended to multilevel and multisymbol modulation schemes such as QAM and PSK.',\n",
       " 'An adaptive filtering neural network classifier for classifying input signals, includes a neural network and one or more adaptive filters for receiving input analog signals to be classified and generates inputs for the classifier. Each adaptive filter is characterized as having a predetermined number of operating parameters. An analog to digital converter converts each input signal into a digital signal before input to the neural network. The neural network processes each digital signal to generate therefrom a plurality of weighted output signals in accordance with the type of network implemented. One of the weighted output signals represents a class for the input signal, and an error signal representing a difference between the weighted output signals and a predetermined desired output is also generated by the network. A control device responsive to the error signal generates a further set of operating filter parameters for input to each of the adaptive filters to change the operating response thereof and minimize the error signal.',\n",
       " 'A job scheduler makes decisions concerning the order and frequency of access to a resource according to a substantially optimum delay cost function. The delay cost function is a single value function of one or more inputs, where at least one of the inputs is a delay time which increases as a job waits for service. The job scheduler is preferably used by a multi-user computer operating system to schedule jobs of different classes. The delay cost functions are preferably implemented by neural networks. The user specifies desired performance objectives for each job class. The computer system runs for a specified period of time, collecting data on system performance. The differences between the actual and desired performance objectives are computed, and used to adaptively train the neural network. The process repeats until the delay cost functions stabilize near optimum value. However, if the system configuration, workload, or desired performance objectives change, the neural network will again start to adapt.',\n",
       " 'A neural network module including an input layer having one or more input nodes arranged to receive input data, a rule base layer having one or more rule nodes, an output layer having one or more output nodes, and an adaptive component arranged to aggregate selected two or more rule nodes in the rule base layer based on the input data, an adaptive learning system having one or more of the neural network modules, related methods of implementing the neural network module and an adaptive learning system, and a neural network program.',\n",
       " 'A control system for controlling the output of at least one plant process output parameter is implemented by adaptive model predictive control using a neural network. An improved method and apparatus provides for sampling plant output and control input at a first sampling rate to provide control inputs at the fast rate. The MPC system is, however, provided with a network state vector that is constructed at a second, slower rate so that the input control values used by the MPC system are averaged over a gapped time period. Another improvement is a provision for on-line training that may include difference training, curvature training, and basis center adjustment to maintain the weights and basis centers of the neural in an updated state that can follow changes in the plant operation apart from initial off-line training data.',\n",
       " 'An adaptive, or neural, network and a method of operating the same is disclosed which is particularly adapted for performing first break analysis for seismic shot records. The adaptive network is first trained according to the generalized delta rule. The disclosed training method includes selection of the seismic trace with the highest error, where the backpropagation is performed according to the error of this worst trace. The learning and momentum factors in the generalized delta rule are adjusted according to the value of the worst error, so that the learning and momentum factors increase as the error decreases. The training method further includes detection of slow convergence regions, and methods for escaping such regions including restoration of previously trimmed dormant links, renormalization of the weighting factor values, and the addition of new layers to the network. The network, after the addition of a new layer, includes links between nodes which skip the hidden layer. The error value used in the backpropagation is reduced from that actually calculated, by adjusting the desired output value, in order to reduce the growth of the weighting factors. After the training of the network, data corresponding to an average of the graphical display of a portion of the shot record, including multiple traces over a period of time, is provided to the network. The time of interest of the data is incremented until such time as the network indicates that the time of interest equals the first break time. The analysis may be repeated for all of the traces in the shot record.',\n",
       " 'A method of operating an adaptive, or neural, network is disclosed for performing first break analysis for seismic shot records. The adaptive network is first trained according to the generalized delta rule. The disclosed training method includes selection of the seismic trace with the highest error, where the backpropagation is performed according to the error of this worst trace. The learning and momentum factors in the generalized delta rule are adjusted according to the value of the worst error, so that the learning and momentum factors increase as the error decreases. The training method further includes detection of slow convergence regions, and methods for escaping such regions including restoration of previously trimmed dormant links, renormalization of the weighting factor values, and the addition of new layers to the network. The network, after the addition of a new layer, includes links between nodes which skip the hidden layer. The error value used in the backpropagation is reduced from that actually calculated, by adjusting the desired output value, in order to reduce the growth of the weighting factors. After the training of the network, data corresponding to an average of the graphical display of a portion of the shot record, including multiple traces over a period of time, is provided to the network. The time of interest of the data is incremented until such time as the network indicates that the time of interest equals the first break time. The analysis may be repeated for all of the traces in the shot record.',\n",
       " 'An Adaptive Network For In-Band Signal Separation (26) and method for providing in-band separation of a composite signal (32) into its constituent signals (28), (30). The input to the network (26) is a series of sampled portions of the composite signal (32). The network (26) is trained with at least one of said composite signals (28) (30) using a neural network training paradigm by presenting one or more of the constituent signals (28) (30) to said network (28). The network (26) may be used to separate multiple speech signals from a composite signal from a single sensor such as a microphone.',\n",
       " 'A neural-simulating system for processing input stimuli includes a plurality of layers, each layer receives layer input signals and generates layer output signals, the layer input signals include signals from the input stimuli and ones of the layer output signals from only previous layers within the plurality of layers. Each of the plurality of layers includes a plurality of neurons operating in parallel on the layer input signals applied to the plurality of layers. Each of the neurons derives neuron output signals from a continuously differentiable transfer function for each of the neurons based upon a combination of sets of weights associated with the neurons and the layer input signals. An adaptive network is associated with each neuron for generating weight correction signals based upon gradient estimate signals and convergence factors signals of each neuron and for processing the weight correction signals to thereby modify the weights associated with each neuron. An error measuring circuit generates relative powered error signals for use in generating the gradient estimate signals and the convergence factors signals.',\n",
       " 'Neural networks may be used in certain automatic speech recognition systems. To improve performance of these neural networks, they may be updated/retrained during run time by training the neural network based on the output of a speech recognition system or based on the output of the neural networks themselves. The outputs may include weighted outputs, lattices, weighted N-best lists, or the like. The neural networks may be acoustic model neural networks or language model neural networks. The neural networks may be retrained after each pass through the network, after each utterance, or in varying time scales.',\n",
       " 'Methods and systems for modifying at least one synapse of a physicallelectromechanical neural network. A physical/electromechanical neural network implemented as an adaptive neural network can be provided, which includes one or more neurons and one or more synapses thereof, wherein the neurons and synapses are formed from a plurality of nanoparticles disposed within a dielectric solution in association with one or more pre-synaptic electrodes and one or more post-synaptic electrodes and an applied electric field. At least one pulse can be generated from one or more of the neurons to one or more of the pre-synaptic electrodes of a succeeding neuron and one or more post-synaptic electrodes of one or more of the neurons of the physical/electromechanical neural network, thereby strengthening at least one nanoparticle of a plurality of nanoparticles disposed within the dielectric solution and at least one synapse thereof.',\n",
       " 'A method and an apparatus for the rapid learning of nonlinear mappings and topological transformations using a dynamically reconfigurable artificial neural network is presented. This fully-recurrent Adaptive Neuron Model (ANM) network has been applied to the highly degenerative inverse kinematics problem in robotics, and its performance evaluation is bench-marked. Once trained, the resulting neuromorphic architecture was implemented in custom analog neural network hardware and the parameters capturing the functional transformation downloaded onto the system. This neuroprocessor, capable of 10.sup.9 ops/sec, was interfaced directly to a three degree of freedom Heathkit robotic manipulator. Calculation of the hardware feed-forward pass for this mapping was benchmarked at .apprxeq.10 .mu.sec.',\n",
       " 'An adaptive optical network is provided for the implementation of learning algorithms. The network comprises a double Mach-Zehnder interferometer in conjunction with a photorefractive crystal that functions as a holographic medium. Light from selectable sources on opposite sides of a beamsplitter is passed through the interferometer, at least one arm of which includes a spatial light modulator for imprinting a data pattern on the light. The light is directed into the holographic medium to develop a refractive index grating corresponding to the data pattern. Light from the hologram is sensed by a photodetector that provides a signal to a threshold device. The output of the threshold device is compared with a reference signal to produce an error signal that can be used to select the source of light directed through the network. The interconnections of the optical devices function to compute the inner product between the elements of the data pattern and their weight factors. Selecting the light source and changing the data pattern provide additive and subtractive weight change capability for implementing various learning algorithms.',\n",
       " 'The adaptive pitch control system for wind generators is utilized in variable speed doubly fed induction generator (DFIG) systems. An adaptive neural network generates optimized controller gains for pitch control. The pitch controller parameters are generated using intelligent differential evolution, a type of genetic algorithm. A back propagation neural network is trained using the generated pitch controller parameters, thereby tuning the weights of the network according to the system states in a variable wind speed environment.',\n",
       " 'An adaptive plasma characterization system and method characterize a semiconductor plasma process using fuzzy logic and neural networks. The method includes the step of collecting input and output training data, where the input training data is based on variables associated with electrical power used to control a plasma chamber and results from execution of the plasma process. The method further includes the step of generating fuzzy logic-based input and output membership functions based on the training data. The membership functions enable estimation of an output parameter value of the plasma process, such that the membership functions characterize the plasma process with regard to the output parameter. Modifying the membership functions based on a neural network learning algorithm and output data provides ability to learn. Thus, etching process parameters such as etch rate, end point detection, and chamber maintenance can all be characterized in a manner that allows the system to operate autonomously.',\n",
       " 'An adaptive predictive model includes a standard predictive model, such as a neural network or a natural model, constructed to produce an output that predicts a process parameter and a combiner network that combines the output of the predictive model with one or more measured values of the process parameter to produce an adjusted predicted process parameter during operation of a process. The adaptive predictive model reduces or corrects for non-linear as well as linear errors in the prediction of a process variable without having to reform the predictive model itself, while requiring only minor increases in processing power and time.',\n",
       " \"In a system comprising a plurality of resources for performing useful work, a resource allocation controller function, which is customized to the particular system's available resources and configuration, dynamically allocates resources and/or alters configuration to accommodate a changing workload. Preferably, the resource allocation controller is part of the computer's operating system which allocates resources of the computer system. The resource allocation controller uses a controller neural network for control, and a separate system model neural network for modelling the system and training the controller neural network. Performance data is collected by the system and used to train the system model neural network. A system administrator specifies computer system performance targets which indicate the desired performance of the system. Deviations in actual performance from desired performance are propagated back through the system model and ultimately to the controller neural network to create a closed loop system for resource allocation.\",\n",
       " \"In a system comprising a plurality of resources for performing useful work, a resource allocation controller function, which is customized to the particular system's available resources and configuration, dynamically allocates resources and/or alters configuration to accommodate a changing workload. Preferably, the resource allocation controller is part of the computer's operating system which allocates resources of the computer system. The resource allocation controller uses a controller neural network for control, and a separate system model neural network for modelling the system and training the controller neural network. Performance data is collected by the system and used to train the system model neural network. A system administrator specifies computer system performance targets which indicate the desired performance of the system. Deviations in actual performance from desired performance are propagated back through the system model and ultimately to the controller neural network to create a closed loop system for resource allocation.\",\n",
       " 'This invention unifies a set of statistical signal processing, neuromorphic systems, and microelectronic implementation techniques for blind separation and recovery of mixed signals. A set of architectures, frameworks, algorithms, and devices for separating, discriminating, and recovering original signal sources by processing a set of received mixtures and functions of said signals are described. The adaptation inherent in the referenced architectures, frameworks, algorithms, and devices is based on processing of the received, measured, recorded or otherwise stored signals or functions thereof. There are multiple criteria that can be used alone or in conjunction with other criteria for achieving the separation and recovery of the original signal content from the signal mixtures. The composition adopts both discrete-time and continuous-time formulations with a view towards implementations in the digital as well as the analog domains of microelectronic circuits. This invention focuses on the development and formulation of dynamic architectures with adaptive update laws for multi-source blind signal separation/recovery. The system of the invention seeks to permit the adaptive blind separation and recovery of several unknown signals mixed together in changing interference environments with very minimal assumption on the original signals. The system of this invention has practical applications to non-multiplexed media sharing, adaptive interferer rejection, acoustic sensors, acoustic diagnostics, medical diagnostics and instrumentation, speech, voice, language recognition and processing, wired and wireless modulated communication signal receivers, and cellular communications.This invention also introduces a set of update laws and links minimization of mutual information and the information maximization of the output entropy function of a nonlinear neural network, specifically in relation to techniques for blind separation, discrimination and recovery of mixed signals. The system of the invention seeks to permit the adaptive blind separation and recovery of several unknown signals mixed together in changing interference environments with very minimal assumption on the original signals.',\n",
       " 'A statistical classifier for pattern recognition, such as a neural network, produces a plurality of output signals corresponding to the probabilities that a given input pattern belongs in respective classes. The classifier is trained in a manner such that low probabilities which pertain to classes of interest are not suppressed too greatly. This is achieved by modifying the amount by which error signals, corresponding to classes which are incorrectly identified, are employed in the training process, relative to error signals corresponding to the correct class. As a result, output probabilities for incorrect classes are not forced to a low value as much as probabilities for correct classes are raised.',\n",
       " 'The adaptive superconductive magnetic energy storage (SMES) control method and system control a SMES device connected to a power generation system. A radial basis function neural network (RBFNN) connected to the controller adaptively adjusts gain constants of the controller. A processor executes an improved particle swarm optimization (IPSO) procedure to train the RBFNN from input-output training data created by the IPSO, and thereafter generate starting weights for the neural network. Tests carried out show that the proposed adaptive SMES controller maintains the DC capacitor voltage constant, thus improving the efficiency of wind energy transfer. The power output (reactive and real) of the SMES device improves the voltage profile following large voltage dips and provides added damping to the system.',\n",
       " \"The present invention covers a synapse cell for providing a weighted connection between an input voltage line and an output summing line having an associated capacitance. Connection between input and output lines in the associative network is made using one or more floating-gate transistors which provide both excitatory as well as inhibitory connections. As configured, each transistor's control gate is coupled to an input line and its drain is coupled to an output summing line. The floating-gate of the transistor is used for storing a charge which corresponds to the strength or weight of the neural connection. When a binary voltage pulse having a certain duration is applied to the control gate of the floating-gate transistor, a current is generated which acts to discharge the capacitance associated with the output summing line. The current, and therefore the resulting discharge, is directly proportional to the charge stored on the floating-gate member and the duration of the input pulse.\",\n",
       " 'A hybrid fuzzy logic/neural network prediction system and method is disclosed for predicting response times to service requests to a service provider. Data from a historical database of records including customer requests and weather information are input to the hybrid system. The data is filtered to reject faulty data entries and data not necessarily useful for predicting response times to service requests such as customer comments are eliminated. A backpropagation neural network operating in a supervised learning mode is employed to decrease the effects of the inherent system nonlinearities. The prediction error from the neural network is trained to make predictions within a predetermined error limit. The neural network generates a prediction configuration; i.e. a set of neural network characteristics, for every record per geographical area, time frame, and month. A fuzzy logic classifier is used for further data reliability. A fuzzy logic classifier relying upon the Fuzzy Cell Space Predictor (FCSP) method is employed to improve predicted response times from year to year. The fuzzy logic classifier supervises the overall identification scheme and, for every record, computes a prediction configuration for its corresponding month in the preceding year. The fuzzy logic classifier then computes a prediction estimate for its neighboring months in the preceding year and computes the prediction estimate for the next time frame (i.e. morning and evening). The Center of Gravity method is used to smooth the different prediction estimates to obtain a final predicted response time.',\n",
       " '\" A computer-implemented method and system for monitoring, identifying, classifying and logging musical work performance broadcasts over the public airwaves. The system uses a neural network to classify specially-processed \"\"retinal\"\" signatures of the musical work performance. The neural network is trained for each musical work using a single noise-biased retinal sample of the spectral distribution of preselected dynamic features of the corresponding audio signal. A detection decision is made at the neural network output using fuzzy logic circuitry to compare results of predetermined thresholding. The system of this invention fully automates the real-time identification of broadcast musical work performances. \"',\n",
       " 'A processing element utilizing the learning algorithm EQU W.sub.i =W.sub.i-1 +A.sub.i where A.sub.i is one of .eta.*(X.sub.i -W.sub.i-1), +1, -1, and 0, and where: PA1 W.sub.i =a weight, PA1 W.sub.i-1 =a previous weight, PA1 .eta.=a plasticity signal, and PA1 X.sub.i =an input signal. A method of generating adaptive weight adjustments, A.sub.i, including generating .eta.*(X.sub.i -W.sub.i-1) and additional least significant bits of data representative of the term .eta.*(X.sub.i -W.sub.i-1). Comparing the additional least significant bits of data to a random number and providing >, = and <, comparison signals. Adding one of .eta.*(X.sub.i -W.sub.i-1), +1, -1 and 0, respectively, to the term W.sub.i-1 when one of the following occurs: at least one bit of .eta.*(X.sub.i -W.sub.i-1) equals one; .eta.*(X.sub.i -W.sub.i-1) equals zero, the comparison signal is < and the sign bit is +; .eta.* (X.sub.i -W.sub.i-1) equals zero, the comparison signal is < and the sign bit is -; or .eta.*(X.sub.i -W.sub.i-1) equals zero and the comparison signal is > or =.',\n",
       " 'A method for adaptively setting analog weights in analog cells of a neural network and the like. The process starts by addressing a synapse cell in the network. A target weight for said addressed synapse cell is selected, and the current weight present on the synapse cell is measured. The amplitude and duration of a voltage pulse to be applied to said synapse cell to adjust said synapse cell in the direction of said target weight is calculated using a set of coefficients representing the the physical characteristics of the synapse cell. The voltage pulse is applied to the addressed synapse cell and the new weight of the synapse cell is re-measured. If the synapse cell weight is within acceptable limits of the target weight, the values of the coefficients are saved and the next adjacent synapse cell is addressed until all synapse cells are set. If the synapse cell is not within acceptable limits, new values for the coefficients are calculated in relation to the re-measured weight. A new voltage pulse is generated and applied to the synapse cell. The process is repeated until the weight of the synapse cell is set within an acceptable limit of the target weight.',\n",
       " 'In one embodiment, when a computing system is in a first state, a first set of inputs from one or more first sensors is detected. A first sensor value array is generated, and the first value array is fed as input to a first function generated by a first neural network. One or more first output values are calculated based on the first function, and a determination is made based on these first output values if a first action has occurred. If a first action has occurred, a second sensor value array is generated from a second set of inputs from one or more second sensors. The second sensor value array is fed as input to a second function generated by a second neural network. One or more second output values are calculated based on the second function, and the first state is exited based on these second output values.',\n",
       " 'A method of accelerating the training of an artificial neural network uses a computer configured as an artificial neural network with a network input and a network output, and having a plurality of interconnected units arranged in layers including an input layer and an output layer. Each unit has a multiplicity of unit inputs and a set of variables for operating upon a unit inputs to provide a unit output. The computer is programmed with a back propagation algorithm. A plurality of examples are serially provided to the network input and the network output is observed. The examples are iterated and proposed changes to each set of variables are calculated in response to feedback representing differences betwen the network output for each example and the desired output. The proposed changes are accumulated for a predetermined number of iterations, whereupon the accumulated proposed changes are added to the set of variables.',\n",
       " 'For elevator car dispatching scenarios, the standard remaining response time (RRT) estimation is augmented by a selected amount of time where a horizon floor is to be served before reaching the hall call to be assigned. The augmentation may be made by adding a fixed RRT penalty, by assuming a car call stop after the horizon floor at a selected floor, or by using a neural network.',\n",
       " 'Monaurally-recorded mono or stereo recordings may be processed and converted into binaurally-recorded audio recordings. An analog process of performing this involves output of at least subsets of the monaurally-recorded recording, such as isolated instrument/vocal tracks, to be played to a dummy with two microphones. A digital process of performing this includes simulating audio input from simulated locations corresponding to audio sources. A neural network process of performing this includes training a neural network using speakers and microphones and then automating conversion from monaural audio to binaural audio based on the training of the neural network. The neural network can also be trained with output speakers to eliminate or reduce dead zones and/or speaker crosstalk.',\n",
       " \"A method is disclosed of identifying or fixing the value of the parameters (aerodynamic data) of a pre-determined set of equations forming the aerodynamic models of an aircraft in various configurations, so as to minimize the variance between the values anticipated by using these aerodynamic data, and reference data in cases of known configurations, includes the use of learning or optimization methods to determine at least one portion of the parameters' values. The method includes storing database data, choosing an optimization method or a neural network method, breaking the identification down into several partial identifications, carrying out successive partial identifications, validating the values found for the aerodynamic model's parameters or iterating the method according to a threshold criterion determined on the value of variances between the reference data and the values measured by the identified model.\",\n",
       " \"A method of providing information to a user is provided. The method includes; establishing an user system interface between a client device and an information system; processing informal queries input from the client device with at least one neural network that converts the informal queries from the client device into formal queries; storing interface context in a browser of the client device, the interface context created in forming formal queries from informal queries, wherein the client device contains unique interface context in the client device's browser that is secure to the client device, the interface context aiding in the determination of future formal queries from future informal queries; searching at least one database in response to the formal queries; and providing responses to the informal queries processed by the neural network to a user through the client device.\",\n",
       " 'Described herein are systems and methods for identifying herbal ingredients effective in treating illnesses in Traditional Chinese Medicine (TCM) using an artificial neural network.',\n",
       " 'A controller for controlling an air conditioner comprises a room temperature sensor for measuring a room temperature, a room temperature change computation circuit for computing a difference between the room temperature and a set temperature, an outdoor temperature sensor for measuring an outdoor temperature, a neural network for computing load on the air conditioner according to the temperature change, outdoor temperature, and room temperature, and a controller for controlling, according to the computed load, the operation frequency of a coolant compressor by controlling a compressor motor through a variable frequency circuit, thereby speedily bringing the room temperature to the set temperature and stably maintaining the room temperature at the set temperature. The neural network learns various operation characteristics of a refrigerating cycle of the air conditioner, and according to a result of the learning, controls the air conditioner.',\n",
       " 'Temperatures in a Dr side air-conditioning zone and a Pa side air-conditioning zone are controlled highly independently of each other without temperature interference between each zone. A room internal air temperature sensor and a room external air temperature sensor are provided. Dr side and Pa side temperature setters separately set room setpoint temperatures (Tset(Dr), Tset(Pa)) in each zone. First and second target blow-out temperature calculating portions, which include neural network, input the room setpoint temperatures and the temperature data. Then it calculates Dr side and Pa side target blow-out temperatures (TAO(Dr), TAO(Pa)) relative to each air-conditioning zones by using a neural network. Air-mixing doors separately adjusts the temperatures of conditioned air blown out from Dr side air passage and Pa side air passage to be the first and second target blow-out temperatures. Here, the neural network has the learning function, which adjusts its output to be desired data (teacher signal). Therefore, the output at a specific input condition can be adjusted without temperature interference between each zone.',\n",
       " 'Temperatures in a Dr side air-conditioning zone and a Pa side air-conditioning zone are controlled highly independently of each other without temperature interference between each zone. A room internal air temperature sensor and a room external air temperature sensor are provided. Dr side and Pa side temperature setters separately set room setpoint temperatures (Tset(Dr), Tset(Pa)) in each zone. First and second target blow-out temperature calculating portions, which include neural network, input the room setpoint temperatures and the temperature data. Then it calculates Dr side and Pa side target blow-out temperatures (TAO(Dr), TAO(Pa)) relative to each air-conditioning zones by using a neural network. Air-mixing doors separately adjusts the temperatures of conditioned air blown out from Dr side air passage and Pa side air passage to be the first and second target blow-out temperatures. Here, the neural network has the learning function, which adjusts its output to be desired data (teacher signal). Therefore, the output at a specific input condition can be adjusted without temperature interference between each zone.',\n",
       " 'An air-fuel ratio control system which calculates a basic injection amount of fuel by state detecting sensors (21) each of which detects an operating state of an internal combustion engine, air-amount detecting sensors (22) each of which detects an intake air amount, an air-fuel ratio sensor (23), and a predetermined data group. Further, the air-fuel ratio control system stores past amount data of injected fuel and air-fuel ratio data at each control cycle. A neuro-computation unit (29) reads values of the data detected by the sensors (21,22) and the stored data to obtain an air-fuel ratio estimate to calculate a correction injection amount of fuel by a neural network of a forward neuro-computing unit (210), which has learned beforehand about relations of the injected fuel amount, the detected air-fuel ratio, parameters, and dead time.',\n",
       " 'An air-fuel ratio control system for an internal combustion engine, which is capable of accurately estimating an exhaust gas state parameter according to the properties of fuel, thereby making it possible to properly control the air-fuel ratio of a mixture. The air-fuel ratio control system 1 estimates an exhaust gas state parameter indicative of a state of exhaust gases, as an estimated exhaust gas state parameter (AF13 NN) by inputting a detected combustion state parameter (DCADLYIG) indicative of a combustion state of the mixture in the engine 3, and detected operating state parameters (NE, TW, PBA, IGLOG, TOUT) indicative of operating states of the engine 3, to a neural network (NN) configured as a network to which are input the combustion state parameter (DCADLYIG) and the operating state parameters (NE, TW, PBA, IGLOG, TOUT), and in which the exhaust gas state parameter is used as a teacher signal (step 1), and controls the air-fuel ratio based on the estimated exhaust gas state parameter (AF_NN) (steps 3, 4, and 24 to 28).',\n",
       " 'An air-fuel ratio control system with a high accuracy for an internal combustion engine which is capable of particularly improving the transient response characteristic irrespective of the occurrence of an air-fuel ratio sensor delay and a fuel attachment. An in-cylinder air-fuel ratio is calculated on the basis of engine data obtained in advance so that an neural network (NN) receiving a fuel injection quantity involving the past value and air quantity estimating information such as an intake pressure and outputting a calculated in-cylinder air-fuel ratio undergoes learning. In the actual control, a difference between the in-cylinder air-fuel ratio estimated in the NN and the target air-fuel ratio is taken on the basis of information such as a fuel injection quantity varying with the time and the output of the NN is partially differentiated with respect to the fuel injection quantity, so that the difference therebetween is divided by the resultant partial differential coefficient to obtain a fuel correction amount whereby the in-cylinder air-fuel ratio coincides with the target air-fuel ratio. The fuel injection quantity is corrected with this correction amount to calculate a final fuel injection quantity. That is, the in-cylinder air-fuel ratio is controlled to approach the target air-fuel ratio so that the exhaust gas air-fuel ratio equals the target air-fuel ratio.',\n",
       " 'An air/fuel ratio control apparatus for executing auxiliary control of an air/fuel ratio by compensating an injected fuel amount set by a control system for maintaining the air/fuel ratio at a preset value. The air/fuel ratio control apparatus includes a state detecting unit for detecting a plurality of physical values which can be measured at low temperature and which show a state of an engine, an air/fuel ratio estimating unit for receiving a plurality of physical values detected by the state detecting means as input parameters and for estimating the air/fuel ratio using a neural network, and a compensatory fuel amount calculating unit for calculating a compensatory fuel amount for the injected fuel amount from the estimated air/fuel ratio. Here, low temperature refers to a temperature at which an air/fuel sensor cannot operate.',\n",
       " 'A method for modeling error-driven adaptive control of an aircraft. Normal aircraft plant dynamics is modeled, using an original plant description in which a controller responds to a tracking error e(k) to drive the component to a normal reference value according to an asymptote curve. Where the system senses that (1) at least one aircraft plant component is experiencing an excursion and (2) the return of this component value toward its reference value is not proceeding according to the expected controller characteristics, neural network (NN) modeling of aircraft plant operation may be changed. However, if (1) is satisfied but the error component is returning toward its reference value according to expected controller characteristics, the NN will continue to model operation of the aircraft plant according to an original description.',\n",
       " 'Neural signal amplifiers include an operational amplifier and a feedback network coupled between an output and an input thereof. The feedback network includes a tunnel field effect transistor (“TFET”) pseudo resistor that exhibits bi-directional conductivity. A drain region of the TFET may be electrically connected to the gate electrode thereof to provide a bi-directional resistor having good symmetry in terms of resistance as a function of voltage polarity.',\n",
       " 'The present invention is directed to an analog, oligomer-based method for determining a mathematical result of carrying out an operation of matrix algebra on input data. The method comprises representing at least one m-component vector V=&Sgr;iViei by a set of single-stranded oligomers Ei and Ei which are in 1:1 correspondence with the basis vectors ei, i=1, 2, . . . , m in an abstract m-dimensional vector space. A composition comprising at least one set of oligomers Ei and Ei representing the components of a vector is obtained as input date and is subjected to at least one physical or chemical treatment having an effect on the oligomers that is an analog representation of an operation of matrix algebra. The method can be used to represent the operations of a neural network; for example, to produce a content-addressable memory, or a multilayer perceptron.',\n",
       " 'A neuron circuit and a neural network including a four quadrant analog multiplier/summer circuit constructed in field effect transistors. The neuron circuit includes the analog multiplier/summer formed of an operational amplifier, plural sets of four field effect transistors, an RC circuit and a double inverter. The multiplier/summer circuit includes a set of four identical field effect transistors for each product implemented. This produces a four quadrant multiplication if the four field effect transistors operate in the triode mode. The output of the multiplier/summer is the sum of these products. The neural network includes a plurality of these neuron circuits. Each neuron circuit receives an input and a set of synaptic weight inputs. The output of each neuron circuit is supplied to the corresponding feedback input of each neuron circuit. The multiplier/summer of each neuron circuit produces the sum of the product of each neuron circuit output and its corresponding synaptic weight. The individual neuron circuits and the neural network can be constructed in MOS VLSI.',\n",
       " 'This is a recurrent or feedforward analog neural network processor having a multi-level neuron array and a synaptic matrix for storing weighted analog values of synaptic connection strengths which is characterized by temporarily changing one connection strength at a time to determine its effect on system output relative to the desired target. That connection strength is then adjusted based on the effect, whereby the processor is taught the correct response to training examples connection by connection.',\n",
       " 'Plural-bit digital input signals to be subjected to weighted summation in a neural net layer are bit-sliced; and a number N of respective first through N.sup.th weighted summations of the bits of the digital input signals in each bit slice are performed, resulting in a respective set of first through N.sup.th partial weighted summation results. Weighted summations of the partial weighted summation results of similar ordinal number are then performed to generate first through N.sup.th final weighted summation results. Each weighted summation of a bit slice of the digital input signals is performed using a capacitive network that generates partial weighted summation results in the analog regime. In this capacitive network each weight is determined by the difference in the capacitances of a respective pair of capacitive elements. The weighted summation to generate a final weighted summation result also is advantageously done in the analog regime, since this facilitates the analog final weighted summation result being non-linearly processed in an analog amplifier with sigmoidal response. This non-linear processing generates an analog axonal output response for a neural net layer, which analog axonal output response can then be digitized.',\n",
       " 'An analog storage device employs an electrically erasable programmable transistor as its memory cell. The memory cell transistor has a source and a drain which are disposed spaced apart from each other on a semiconductive substrate to define a channel region therebetween, an insulated floating gate electrode which at least overlaps the channel region, and an insulated control gate electrode disposed above the insulated floating gate electrode. Minority carriers are allowed to tunnel between the channel region and the insulated floating gate. The amount of carriers to be stored on the floating gate electrode is controlled such that it is in proportion to analog data to be stored therein. A variation in the internal field of the transistor which may occur when its floating gate electrode is being charged with minority carriers is monitored. When a field variation is detected, a voltage for compensating for the detected field variation is applied to the control gate electrode, whereby the linearity of analog storage is ensured.',\n",
       " 'A 1-bit nonstandard A/D converter for converting a block u of N samples of a continuous time analog signal u(t) into N corresponding 1-bit binary values x, such that a distortion measure of the form d(u,x)=(Au-Bx).sup.T (Au-Bx) is minimized, is implemented with an N-input parallel sample-and-hold circuit and a neural network having N nonlinear amplifiers, where u and x are n-dimensional vectors, and A and B are N.times.N matrices. Minimization of the above distortion measure is equivalent to minimizing the quantity EQU 1/2x.sup.T B.sup.T Bx-u.sup.T A.sup.T Bx, which is achieved to at least a good approximation by the N-amplifier neural network. Accordingly, the conductances of the feedback connections among the amplifiers are defined by respective off-diagonal elements of the matrix -B.sup.T B. Additionally, each amplifier of the neural network is connected to receive the analog signal samples through respective conductances defined by the matrix B.sup.T. Furthermore, each amplifier receives a respective constant signal defined by the diagonal elements of the matrix -B.sup.T B. The stabilized outputs of the N amplifiers are the binary values of the digital signal x. A multiple-bit nonstandard A/D converter based on for foregoing 1-bit A/D converter is also disclosed.',\n",
       " 'A four quadrant, analog multiplier circuit useful for MOS implementation of feedback/feedforward neural networks. The multiplier circuit uses only one op-amp and one pair of input MOS FETs. It becomes a multiplier/summer by the addition of only one additional pair of input FETs for each additional product to be summed and achieves the vector scalar product of 2 n-tuple vector inputs using only 2(n+1) MOS transistors.',\n",
       " 'Energy dispersive x-ray diffraction spectra are obtained from numerous volume elements within an object. A feature set such as a set of cepstrum coefficients is extracted from each spectrum and classified by a trained classifier such as a neural network to provide an indication of whether or not contraband such as explosives is present in the volume element. Indications for adjacent volume elements are evaluated in conjunction with one another, as by an erosion process, to suppress isolated indications and thereby suppress false alarms.',\n",
       " '\" A method and apparatus for directly identifying and characterizing input data derived from regions of interest in ultrasound images of organs in the presence of attenuation from interposed contrast agent, for the purpose of diagnosing abnormalities. The input data is classified into one of a number of classes depending upon the characteristics of that data, in order to distinguish normal conditions from abnormal conditions. The invention is based on the recognition that significant information relating to the health of tissue exists in regions of interest in ultrasound images in the presence of attenuation from interposed contrast agent. This information is in the form of backscatter speckle patterns that have \"\"texture\"\" characteristics that are distinguishable in healthy versus diseased tissue. The invention classifies such patterns as probably normal or abnormal by means of an analysis system that may include a neural network system. The preferred embodiment of the present invention includes: (1) a data acquisition system for acquiring ultrasound image data indicative of a region of interest in the presence of attenuation from interposed contrast agent; (2) an optional signal conditioning stage to remove signals (e.g., noise) from the input data; and (3) an analysis system designed to detect \"\"texture\"\" characteristics that distinguish healthy tissue from diseased tissue even in the presence of the contrast agent. The output classifies the input data in a uniform, unambiguous manner. The invention is preferably implemented as a computer program executing on a programmable computer. \"',\n",
       " \"A method, apparatus, and article of manufacture for performing data mining applications in a relational database management system. At least one analytic algorithm for enhanced back-propagation neural network processing is performed by a computer, wherein the analytic algorithm for enhanced back-propagation neural network processing includes SQL statements performed by the relational database management system directly against the relational database and programmatic iteration. The analytic algorithm for enhanced back-propagation neural network processing operates on data in the relational database that has been partitioned into training, testing and validation data sets. The analytic algorithm for enhanced back-propagation neural network processing maps the data in the training data sets to nodes in the neural network wherein the data is processed as it moves from an input node of the neural network through a hidden node of the neural network to an output node of the neural network. In addition, the analytic algorithm for enhanced back-propagation neural network processing determines an error difference between the output node's value and a target value as the data is mapped to the output node in the neural network, and changes a weight value for one or more of the nodes based on an accumulation of the error difference for the node, in order to get the neural network to converge on a solution. Finally, the analytic algorithm for enhanced back-propagation neural network processing cross-validates the changed weight value to prevent overfitting the node.\",\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on computer storage media, for using recurrent neural networks to analyze health events. One of the methods includes: processing each of a plurality of initial temporal sequences of health events to generate, for each of the initial temporal sequences, a respective network internal state of a recurrent neural network for each time step in the initial temporal sequence; storing, for each of the initial temporal sequences, one or more of the network internal states for the time steps in the temporal sequence in a repository; obtaining a first temporal sequence; processing the first temporal sequence using the recurrent neural network to generate a sequence internal state for the first temporal sequence; and selecting one or more initial temporal sequences that are likely to include health events that are predictive of future health events in the first temporal sequence.',\n",
       " 'A method for annotation of skin images includes receiving a plurality of dermatoscopic images. Each of the dermatoscopic includes a region of lesion skin and a region of normal skin. A first convolutional neural network is trained according to an interior of the region of lesion skin using each of the plurality of dermatoscopic images. A second convolutional neural network is trained according to a boundary between the region of lesion skin and the region of normal skin. An additional dermatoscopic image is acquired. The first and second convolutional neural networks are used to identify a region of lesion skin within the acquired additional dermatoscopic image.',\n",
       " 'An anomaly monitoring device includes two neural networks which are switchable between a training mode by using training samples and a checking mode for classifying, based on a training result, whether an amount of characteristics obtained by an operation of an apparatus indicates that the operation of an apparatus is normal and a mode switching unit controlling one of the neural networks to operate in training mode and the other neural network to operate in the checking mode. Further, the anomaly monitoring device includes a switching determining unit computing a judgment evaluation value serving to evaluate reliability of a judgment result of the other neural network operating in the checking mode, and for instructing the mode switching unit to have the one of the neural networks operate in the checking mode and the other neural network operate in training mode when the judgment evaluation value does not meet evaluation criteria.',\n",
       " 'A controller is provided for directing control of a process performed to control an amount of a pollutant emitted into the air. The process has multiple process parameters (MPPs) The controller includes either a neural network process model or a non-neural network process model. Whichever type model is included, it will represent a relationship between one of the MPPs and other of the MPPs. The controller also includes a control processor having the logic to determine the validity of a measured value of the one MPP based on the one model. The control processor directs control of the process in accordance with the measured value of the one MPP only if the measured value of the one MPP is determined to be valid. On the other hand, if the measured value is determined to be invalid, the control processor may direct control of the process in accordance with an estimated value of the one MPP.',\n",
       " 'An apparatus for locating a source of acoustic emission in a material comprises four spaced transducers coupled to the material. Each transducer produces an output signal corresponding to a detected acoustic emission activity, and each output signal is amplified, rectified and enveloped before being supplied to a processor. Artificially induced acoustic emission events, of known location, are generated in the material. The processor measures the times taken for each output signal corresponding to artificially induced acoustic emission events, to exceed two predetermined amplitudes from a datum time. A neural network analyzes the measured times to exceed the predetermined amplitudes for the output signals corresponding to the artificially induced acoustic emission events and infers the mathematical relationship between values of time and location of acoustic emission event. The times taken for each output signal, corresponding to acoustic emission events of unknown source location, to exceed two predetermined amplitudes from the datum are measured and are used to calculate the location of the unknown source with the mathematical relationship deduced by the neural network.',\n",
       " 'An apparatus and method are provided for analyzing information relating to the physiological and psychological conditions of a driver. Psychological conditions such as comfortableness or degree of alertness are estimated on the basis of physical data such as fluctuation in brain waves. This apparatus comprises a first neural network having a pre-processed 1/f fluctuation signal for brain waves as an input and for estimating a degree of alertness of the driver, and a second neural network receiving the estimated degree of alertness and the pre-processed 1/f fluctuation signal, for estimating and outputting driving comfortableness. By employing a neural network, which has a mapping ability as well as flexible adaptability even for non-linear data, based on the learning function, more accurate estimation of mental conditions can be achieved in comparison with conventional statistical analysis.',\n",
       " 'An apparatus and method are provided for analyzing information relating to the physiological and psychological conditions of a driver. Psychological conditions such as comfortableness or degree of alertness are estimated on the basis of physical data such as fluctuation in brain waves. This apparatus comprises a first neural network having a pre-processed 1/f fluctuation signal for brain waves as an input and for estimating a degree of alertness of the driver, and a second neural network receiving the estimated degree of alertness and the pre-processed 1/f fluctuation signal, for estimating and outputting driving comfortableness. By employing a neural network, which has a mapping ability as well as flexible adaptability even for non-linear data, based on the learning function, more accurate estimation of mental conditions can be achieved in comparison with conventional statistical analysis.',\n",
       " 'An apparatus and method identify at least one attribute of an article for use in accurately reproducing the article. The apparatus includes at least one detector having an array of cells. At least one cell, in the detector array, the sensor cell, is provided with an extra colored coating or is painted with an extra color. When the article is scanned by the detector, the at least one sensor cell will read a different color value from the other cells due to the extra coating applied to it. The color that the at least one sensor cell would have output without the extra coating is interpolated from the detection results of the neighboring cells. This color and the color actually detected by the at least one sensor cell are then input to a controller which determines the at least one attribute of the scanned article using a model, such as a neural network, an expert system, a fuzzy logic model, and the like. The controller performs appropriate processing based on the at least one determined attribute.',\n",
       " 'An apparatus and method for categorizing health care utilization provides an efficient aid in identifying patients who are seeking inappropriate care. The invention involves a computer system having a neural network responsive to several input variables to categorize the utilization characteristics of the patient. The input variables define selected characteristics of a patient. In one embodiment, a screening process identifies patients who are at high risk to an immediate threat to their health and eliminates those least likely to be seeking inappropriate care.',\n",
       " 'The present invention provides an apparatus and a method for classifying and recognizing image patterns using a second-order neural network, thereby achieving high-rate parallel processing while lowering the complexity. The second-order neural network, which is made of adders and multipliers, corrects positional translations generated in a complex-log mapping unit to output the same result for the same object irrespective of the scale and/or rotation of the object. The present invention enables high-rate image pattern classification and recognition based on parallel processing, which is the advantage obtained in neural network models, because consistent neural networks and consistent network structure computation models are applied to all steps from the image input step to the pattern classifying and recognizing step.',\n",
       " '\" A method and apparatus for constructing, training and utilizing an artificial neural network (also termed herein a \"\"neural network\"\", an ANN, or an NN) in order to transform a first color value in a first color coordinate system into a second color value in a second color coordinate system. \"',\n",
       " 'An intelligent agent and its client communicate using a selector known by both parties to generate and interpret messages and thereby effectively disguise confidential information transmitted in the messages from third parties. Moreover, a neural network is used to implement the decision logic and/or the message disguising functions of an agent such that the logic employed in such functions is not readily reverse compiled or scanned by third parties.',\n",
       " 'There are provided an apparatus and a method for compressing data, an apparatus and a method for analyzing data and a data management system, which are capable of compressing huge data and accurately reproducing the characteristics of the original data from the compressed data.The data compressing apparatus includes detection means for detecting a multiplicity of data sets, each including n parameter values that vary according to an operation of an object, where n is a natural number; and data compressing means for compressing the data sets by inputting the data sets into an n-dimensional space, arranging neurons smaller in number than the data sets in the n-dimensional space, carrying out unsupervised learning for a neural network on the neurons, and converting the data sets into a neuron model parameter characterizing a neuron model obtained by the unsupervised learning.',\n",
       " 'In an apparatus and a method for detecting and assessing a spatially discrete dot pattern disposed in a multidimensional coordinate system, each dot in the pattern assumes at least two differentiatable status values. A measuring device records the coordinate values and status values of each dot of the multidimensional spatial dot pattern. A memory stores data that correspond to the recorded coordinate values and status values of each dot of the multidimensional spatial dot pattern. A computer into which the stored data are entered and in which a coordinate counter for each coordinate value of a coordinate axis is determined from the stored data, is associated with the memory. The value of the coordinate counter is formed from the number of detected dots of the coordinates that have a predetermined status value. A neural network is associated with the computer. An n-dimensional input vector with components formed from the calculated coordinate counters of each dot of the spatially discrete dot pattern is entered in the neural network. The neural network calculates an output vector by comparing the calculated input vector of the measured dot pattern with stored set-point vectors obtained on the basis of exemplary dot patterns. The neural network assigns a classification value of the measured dot pattern from the output vector ascertained and outputs it.',\n",
       " 'A disk drive is tested during the manufacturing process, after the head/disk assembly is completely assembled and enclosed in its protective enclosure. A known data pattern is written to selected tracks on the disk surface, and the data is read back. During the read process, the analog read signal is sampled at first and third harmonic rates, and the logarithmic ratio of the two sampled signals used to derive a harmonic ratio flyheight (HRF) signal approximating the flyheight of the head. When a transducer head passes over a surface asperity, a collision occurs, causing the transducer to be lifted momentarily above its normal flyheight. If the amplitude of the HRF signal exceeds a predetermined clipping level, a possible disk defect is indicated. In order to characterize the possible defect, a window of the HRF signal samples in the vicinity of the suspected abnormality is digitized and used as the input to a neural network. The neural network is trained with actual HRF samples from previously detected disk drive abnormalities, which have been categorized by microscopic examination or other means. The neural network produces an output for the HRF signal samples from the drive being tested which indicates whether the defect is of a type which can be ignored, or of a type which requires scrapping or rework of the drive.',\n",
       " 'A glass break detector is disclosed that uses a neural network to determine if an audio signal is breaking glass. A characteristic extraction unit is used to extract a set of signal characteristics from a time domain signal based on the audio signal. The set of signal characteristics is the set of the magnitudes of the discrete Fourier transform coefficients of an acquired time domain signal, or the Fourier transform coefficients themselves. A classifier is connected to the characteristic extraction unit. It is a two-layer neural network that uses the set of signal characteristics to accurately determine whether the acquired time domain signal represents breaking glass.',\n",
       " 'Apparatus for detecting molecular vapors in an atmospheric region includes an interferometer which monitors light parameter data signals received and provides an interferometer light parameter signal corresponding to the light parameter data signals at a plurality of frequencies. The apparatus further includes an interferogram detector/converter which records and digitizes the interferometer light parameter signal to generate a plurality of discrete data points wherein each discrete data point corresponds to the interferometer light parameter signal at a specific frequency. The apparatus also includes a Fourier transform circuit for receiving the discrete interferometer light parameter signal and providing a Fourier transformed molecular parameter data signal. The apparatus further includes a probabilistic neural network for receiving and sorting the Fourier transformed molecular parameter data signals without the use of a priori training data.',\n",
       " 'Apparatus for detecting molecular vapors in an atmospheric region includes an interferometer which monitors light parameter data signals received and provides an interferometer light parameter signal corresponding to the light parameter data signals at a plurality of frequencies. The apparatus further includes an interferogram detector/converter which records and digitizes the interferometer light parameter signal to generate a plurality of discrete data points wherein each discrete data point corresponds to the interferometer light parameter signal at a specific frequency. The apparatus also includes a Fourier transform circuit for receiving the discrete interferometer light parameter signal and providing a Fourier transformed molecular parameter data signal. The apparatus further includes a probabilistic neural network for receiving and sorting the Fourier transformed molecular parameter data signals without the use of a priori training data.',\n",
       " 'An apparatus and method for diagnosing an engine using computer based models in combination with a neural network which reduces the neural network training and updating required is disclosed. The method and apparatus determine modeled values for a plurality of engine parameters as a function of sensed values in a plurality of initial values; sense a plurality of actual values for the engine parameters; and determine a difference between the actual values and the modeled values for the respective engine parameters. The differences are inputted into a neural network which generates an output pattern as a function of the differences and a plurality of weight values. The weight values and the initial values are then updated as a function of a comparison between the output patterns and a desired pattern, and the engine is responsively diagnosed as a function of the output pattern.',\n",
       " \"An apparatus and a method are provided for coupling to a patient's heart for discriminating between tachycardias of physiological origin, and those of pathological origin having similar rates; and also for discriminating amongst those of pathological origin having similar rates. The apparatus includes transducers and/or sensing electrodes in either or both the atrium and/or ventricle. Also included are signal processing elements for determining the times of atrial and ventricular events and for extracting morphological features from the waveforms, and a neural network for classifying the heart rhythm. The method includes a step of discriminating between different types of heart rhythms having overlapping rates. The method utilizes atrial-atrial, ventricular-ventricular and atrio-ventricular intervals; integrated waveforms; sums of differences of waveform samples; rectified integrated bandpass filtered waveforms; numbers of zero crossings in the electrogram; area under the ventricular electrogram; and R wave slope, QR area and RS area of the electrogram.\",\n",
       " 'An apparatus and method for editing an optimized color preference are provided. The apparatus includes a color information controlling unit which extracts data about a preference by comparing color information of a transformed image generated by transforming color information of an original image and the original image according to a user preference; a learning unit which teaches a neural network about the preference, based on the extracted data, and predicts color information variation by the neural network; and an image correcting unit which corrects color information of an input image according to the predicted color information variation. The method includes extracting data about a preference; teaching a neural network about the preference, based on the extracted data; predicting color information variation by the neural network; and correcting color information of an input image according to the predicted color information variation.',\n",
       " 'A device for calculating numerical solutions for partial differential equations in successive intervals using adaptive meshes, comprises: a neural network part for producing predictions of gradients at a following interval based on gradients available from previous intervals, and a mesh adaptation part, associated with the neural network part, configured for adapting a mesh over a domain of a respective partial differential equation using the predictions, such that the mesh adaptively refines itself about emerging regions of complexity as the partial differential equation progresses over the successive intervals. The neural network part succeeds in its predictions since its use herein is equivalent to using time series function fitting techniques.',\n",
       " 'Embodiments of the present invention provide an apparatus for storing emails, comprising a neural network arranged to receive information associated with an email, to determine a storage location of the email according to one or more of the attributes of the email and to output information identifying the determined storage location.',\n",
       " 'Disclosed is an apparatus and method for estimating a state of charge (SOC) in a battery, the apparatus including a detector unit; a soft computing unit for calculating and outputting a battery SOC estimation value by processing a current, a voltage and a temperature detected by the detector unit using a computing algorithm, which is a fuzzy algorithm implemented as a neural network, the soft computing unit storing the battery SOC estimation value in a memory, where the fuzzy algorithm has a form expressed as F=Φ(P,X)W, where Φ is one of a fuzzy radial function, a radial basis function, and an activation function in the neural network, P is a learning parameter, X is an input, and W is a weight to be updated during learning.',\n",
       " 'Disclosed are an apparatus and a method for estimating a state of charge of a battery representing a non-linear characteristic by using a neural network. The apparatus includes a sensing section for detecting current, voltage and a temperature from a battery cell, a neural network performing a neural network algorithm and a learning algorithm based on data of the current, voltage and temperature transmitted thereto from the sensing section and present time data, thereby outputting the SOC of the battery estimated through a final learning algorithm, and a comparator for comparing an output value of the neural network with a predetermined target value and making the neural network iteratively perform the learning algorithm if a difference between the output value of the neural network and the predetermined target value is out of a predetermined limit, thereby update the learning algorithm to generate the final learning algorithm. The state of charge of the battery is precisely estimated through the neural network algorithm.',\n",
       " 'A neural network development utility assists a developer in generating one or more filters for data to be input to or output from a neural network. A filter is a device which translates data in accordance with a data transformation definition contained in a translate template. Source data for the neural network may be expressed in any arbitrary combination of symbolic or numeric fields in a data base. The developer selects those fields to be used from an interactive menu. The utility scans the selected field entries in the source data base to identify the logical type of each field, and creates a default translate template based on this scan. Numeric data is automatically scaled. The developer may use the default template, or edit it from an interactive editor. When editing the template, the developer may select from a menu of commonly used neural network data formats, and from a menu of commonly used primitive mathematical operations. The developer may interactively define additional filters to perform data transformations in series, thus achieving more complex mathematical operations on the data. Templates may be edited at any time during the development process. If a network does not appear to be giving satisfactory results, the developer may easily alter the template to present inputs in some other format.',\n",
       " 'The present invention generates a plurality of video image data of different camera positions for an object shot by a camera and modifies and synthesizes the video image data of a pseudo camera position sandwiched between the related camera angles from a plurality of video image data of the aforesaid different camera positions. By this, the video image of a pseudo camera position not actually shot can be obtained.',\n",
       " 'The present invention is an apparatus and method for object recognition from at least an image stream from at least an image frame utilizing at least an artificial neural network. The present invention further comprises means for generating multiple components of an image pyramid simultaneously from a single image stream, means for providing the active pixel and interlayer neuron data to at least a subwindow processor, means for multiplying and accumulating the product of a pixel data or interlayer data and a synapse weight, and means for performing the activation of an accumulation. The present invention allows the artificial neural networks to be reconfigurable, thus embracing a broad range of object recognition applications in a flexible way. The subwindow processor in the present invention also further comprises means for performing neuron computations for at least a neuron. An exemplary embodiment of the present invention is used for object recognition, including face detection and gender recognition, in hardware. The apparatus comprises a digital circuitry system or IC that embodies the components of the present invention.',\n",
       " 'Provided is an apparatus for large vocabulary continuous speech recognition (LVCSR) based on a context-dependent deep neural network hidden Markov model (CD-DNN-HMM) algorithm. The apparatus may include an extractor configured to extract acoustic model-state level information corresponding to an input speech signal from a training data model set using at least one of a first feature vector based on a gammatone filterbank signal analysis algorithm and a second feature vector based on a bottleneck algorithm, and a speech recognizer configured to provide a result of recognizing the input speech signal based on the extracted acoustic model-state level information.',\n",
       " 'An apparatus for measuring a bending angle of a sheet, comprising a processing unit and at least one sensor comprising a light source which projects a light pattern on at least one side of the sheet, and recording means adapted to record an image of the projection of said light pattern on the at least one side of the sheet. The processing unit is adapted to control the recording means for recording the image in at least one time instant (Treg1; Treg1, Treg2 . . . Tregn) during an operation of bending the sheet; a control unit is capable of transforming the recorded image into a point cloud and comprises a neural network adapted to associate a bending angle value with the point cloud.',\n",
       " 'An apparatus and method for monitoring material removal from a workpiece by a beam of energy during a material processing operation are disclosed. A detector is positioned for sensing optical emissions from the workpiece caused by removal of material when an energy beam pulse is incident upon the surface of the workpiece. A computing circuit, algorithm or artificial neural network is provided for determining a quantity of material removed from the sensed optical emissions in real-time during the material processing operation. Analysis of the optical emission pulses caused by the material removal provides an indication of the efficiency of the material processing system and provides feedback for manual or automatic adjustment of material processing parameters during the material processing operation.',\n",
       " 'Apparatus for motion detection and tracking of objects in a region for collision avoidance includes a signal transmitter which provides first and second detection signals for at least partial reflection by an object located in a spatial region. The apparatus further includes a signal receiver for receiving the deflected first and second detection signals corresponding to first and second object parameter data signals. The apparatus further includes a Fourier transform circuit for receiving the first and second object parameter data signals and providing first and second Fourier transform object parameter data signals. The apparatus further includes a probabilistic neural network for receiving and sorting the first and second Fourier transform object parameter data signals without the use of a priori training data.',\n",
       " \"The neural computing paradigm is characterized as a dynamic and highly computationally intensive system typically consisting of input weight multiplications, product summation, neural state calculations, and complete connectivity among the neurons. Herein is described neural network architecture for a Scalable Neural Array Process (SNAP) which uses a unique interconnection and communication scheme within an array structure that provides high performance for completely connected network models such as the Hopfield model. SNAP's packaging and expansion capabilities are addressed, demonstrating SNAP's scalability to larger networks. The array processor is made up of multiple sets of orthogonal interconnections and activity generators. Each activity generator is responsive to an output signal in order to generate a neuron value. The interconnection structure also uses special adder trees which respond in a first state to generate an output signal and in a second state to communicate a neuron value back to the input of the array processor.\",\n",
       " 'A new approach to objective quality assessment of DCT-coded video sequences, with or without a reference is proposed. The system is comprised of a proprietary segmentation algorithm, a feature extraction process and a nonlinear feed-forward-type neural network for feature analysis. The methods mimic function of the human visual system (HVS): A neural network training algorithm is used for determining the optimal network weights and biases for both system modes of operation. The proposed method allows for assessment of DCT-coded video sequences without the original source being available (pseudo-reference mode). The pseudo-reference mode is also comprised of a proprietary DCT-coded video (MPEG) noise reducer (MNR), co-pending patent application No. 60/592,143.',\n",
       " 'Apparatus and methods for partial evaluation of synaptic updates in neural networks. In one embodiment, a pre-synaptic unit is connected to a several post synaptic units via communication channels. Information related to a plurality of post-synaptic pulses generated by the post-synaptic units is stored by the network in response to a system event. Synaptic channel updates are performed by the network using the time intervals between a pre-synaptic pulse, which is being generated prior to the system event, and at least a portion of the plurality of the post synaptic pulses. The system event enables removal of the information related to the portion of the post-synaptic pulses from the storage device. A shared memory block within the storage device is used to store data related to post-synaptic pulses generated by different post-synaptic nodes. This configuration enables memory use optimization of post-synaptic units with different firing rates.',\n",
       " 'Apparatus and methods for partial evaluation of synaptic updates in neural networks. In one embodiment, a pre-synaptic unit is connected to a several post synaptic units via communication channels. Information related to a plurality of post-synaptic pulses generated by the post-synaptic units is stored by the network in response to a system event. Synaptic channel updates are performed by the network using the time intervals between a pre-synaptic pulse, which is being generated prior to the system event, and at least a portion of the plurality of the post synaptic pulses. The system event enables removal of the information related to the portion of the post-synaptic pulses from the storage device. A shared memory block within the storage device is used to store data related to post-synaptic pulses generated by different post-synaptic nodes. This configuration enables memory use optimization of post-synaptic units with different firing rates.',\n",
       " 'An apparatus for processing an audio signal to obtain control information for a speech enhancement filter has a feature extractor for extracting at least one feature per frequency band of a plurality of frequency bands of a short-time spectral representation of a plurality of short-time spectral representations, where the at least one feature represents a spectral shape of the short-time spectral representation in the frequency band. The apparatus additionally has a feature combiner for combining the at least one feature for each frequency band using combination parameters to obtain the control information for the speech enhancement filter for a time portion of the audio signal. The feature combiner can use a neural network regression method, which is based on combination parameters determined in a training phase for the neural network.',\n",
       " 'An authentication system authenticates an object. The authentication system includes a capture device for capturing at least one biometric output data record (BD) for the object; a reading device for reading configuration data (Konf), associated with the object, for an artificial neural network; a processing device designed to produce the artificial neural network and to input the BD into the neural network; a verification device which captures an output from the neural network to authenticate the object, wherein the neural network is a bidirectional associative memory, particularly a Hopfield network, having a multiplicity of network states. The verification device is designed to determine the output from the neural network by capturing a final state derived from the input of the BD. The neural network stores a key associated with a particular person. The key is released only when appropriate biometric data are input into the neural network.',\n",
       " 'A source of high frequency electromagnetic radiation is coupled to a specimen containing a target chemical whose presence and/or concentration is to be ascertained. Preferably the source radiation includes a plurality of high frequency spectra, at least one of which encourages energy transfer with the chemical of interest. The source radiation is coupled to the specimen via a probe pair that is also used to access a return signal representing an interaction between the source signal and the specimen. The return signal is processed to yield a spectral signature correlating to the target chemical and/or its concentration. Preferably signal processing compares frequency spectra within the source signal to spectra within a sampled return signal. The sampled return signal is a signal obtained by sampling a return signal at the probe pair and by sampling the response to the source signal of a circuit that electrically approximates the specimen. The amplitude and/or phase difference between the sampled return signal and the source signal provides recognition of the spectral signature. Target chemical concentration data may be obtained from the signature and can be displayed in a number of ways. Operation of the signal processor may be optimized using a neural network. In the preferred embodiment, the specimen is a human finger that is pressed against the probe pair, and the chemical is glucose. The invention thus permits a lay user to non-invasively determine his or her glucose level.',\n",
       " 'A speech recognition apparatus based on a deep-neural-network (DNN) sound model includes a memory and a processor. As the processor executes a program stored in the memory, the processor generates sound-model state sets corresponding to a plurality of pieces of set training speech data included in multi-set training speech data, generates a multi-set state cluster from the sound-model state sets, and sets the multi-set training speech data as an input node and the multi-set state cluster as output nodes so as to learn a DNN structured parameter.',\n",
       " 'The present invention provides a data selection apparatus which augments a set of training examples with the desired output data. The resulting augmented data set is normalized such that the augmented data values range between -1 and +1 and such that the mean of the augmented data set is zero. The data selection apparatus then groups the augmented and normalized data set into related clusters using a clusterizer. Preferably, the clusterizer is a neural network such as a Kohonen self-organizing map (SOM). The data selection apparatus further applies an extractor to cull a working set of data from the clusterized data set. The present invention thus picks, or filters, a set of data which is more nearly uniformly distributed across the portion of the input space of interest to minimize the maximum absolute error over the entire input space. The output of the data selection apparatus is provided to train the analyzer with important sub-sets of the training data rather than with all available training data. A smaller training data set significantly reduces the complexity of the model building or analyzer construction process.',\n",
       " 'An apparatus and method for selecting the length of a variable length code bitstream by using a neural network are provided. The apparatus for selecting the length of a variable length code bitstream includes a bitstream estimation length receiving unit which inputs a predetermined quantization DCT coefficient block to a neural network whose training is finished, and receives the estimation length of a bitstream corresponding to the quantization DCT coefficient block from the neural network; and a bitstream estimation length selection unit which receives user selection about an estimation length received by the bitstream estimation length receiving unit. According to the method and apparatus the length of a variable length code bit stream can be estimated such that a user can select a desired length of a bitstream in advance without performing variable length coding.',\n",
       " 'An apparatus for sensing and processing images is provided with a photo detector array arranged in a matrix form, a control circuit for feeding a row of the array with voltage for sensitivity control, and a neural network for processing current flowing from a column of the array to the ground in order to obtain an apparatus for sensing and processing images having a simple configuration, a high frame speed, the capability of forming a focus of attention, and high throughput of data and possibility of connecting to the neural network.',\n",
       " \"An apparatus includes a deformable structure in which a neural network comprising a plurality of deformation sensors, e.g. nanowire sensors, and distributed in-situ processing circuits. The circuits generate a signal characterizing features of the local deformation of the structure and/or a command signal corresponding to the detected deformation. The structure may be a wearable sleeve that conforms to deformations of a user's skin, part of an electronic device, such as a touch sensitive screen, or an object in itself. The apparatus can provide a user interface, wherein a command corresponding to a current shape of the structure is generated and acted upon by a integrated or remote device, or a device for monitoring a user's position or movement e.g. for replication by a robotic device. The apparatus may have machine learning capability to improve the matching of commands with determined shapes of the deformable structure.\",\n",
       " 'An apparatus and method for reproducing pit information precisely from a magnetic optical disk without being adversely affected by heat accumulation. The signal reproducing apparatus reproduces signals using a neural network constituting a decoder that decodes pits on the disk. The signal reproducing method provides learning using a sigmoid function and carries out signal reproduction using a step function.',\n",
       " 'A tactile sensor, computer readable medium, methods of using and manufacturing the tactile sensor, and methods and apparatuses for processing the information generated by the tactile sensor. The tactile sensor includes a planar optical waveguide comprised of a flexible and transparent layer; a light configured to direct light into the optical waveguide; a light sensor or an imager facing the optical waveguide and configured to generate signals from light scattered out of the optical waveguide; and a controller which may be configured to generate an image of the object and characteristics of the object. The waveguide may be configured so that some of the light directed into the optical waveguide is scattered out of the waveguide if the waveguide is deformed by being pressed against the object. A finite element and a neural network are used to estimate mechanical characteristics of the objects.',\n",
       " 'A method and apparatus for testing automotive electronic control units and batteries and other equipment for identification and performance purposes utilizes neural networks to effect waveform analysis on a digitized signal. Identification of electronic control units is by means of correlation of resultant waveform data with corresponding data on known units. Battery testing is by waveform analysis of the battery current during transient connection of a load by a transistorized switching circuit. In both cases the method of testing includes a network learning stage and an ensuing recognition test routine for characteristic waveforms.',\n",
       " 'An apparatus and method for the detection and treatment of arrhythmias using a processor having a neural network with a hierarchical arrangement including a first lower level for classifying individual waveforms, a second higher level for diagnosing detected arrhythmias and a third higher level for the application of therapy in response to a diagnosed arrhythmia. The neural network may be a back propogation neural network or an associative memory type neural network. The arrhythmias detected may be at least one of bradycardia, tachycardia and fibrillation. The apparatus may include a cardioverting/defibrillating pacemaker. In general, the apparatus acquires physiological signals representative of heart activity in a patient. A neural network receives the physiological signals and determines if any arrhythmia is present, and if present, selects therapy to be applied to the heart. A therapy generator then applies the therapy selected by the neural network. The physiological signals may be processed or unprocessed ECG signal, signals indicative of the properties of the blood including the presence of gases, blood temperature, and blood flow signals or signals representative of ventricular wall impedance or ventricular volume.',\n",
       " 'The method of the invention identifies damage to an in-service conductor associated with the delivery (transmission and distribution) of electric power. Electro-magnetic acoustic energy is generated in an in-service conductor associated with the delivery of electric power. Corresponding return electro-magnetic acoustic energy is then measured. Features are then extracted from the return electro-magnetic acoustic energy to characterize damage to the in-service conductor. The features may be extracted through a variety of signal processing techniques, such as wavelet signal processing. The extracted features may be classified using a neural network, fuzzy logic, or a combination of both.',\n",
       " 'A method of evaluating whether a vehicle under test is operating as intended. Parameters of the vehicle are sampled at a plurality of sample times to obtain a plurality of data samples. Data samples from more than one of the sample times are included in a sample set. The sample set is input to an artificial neural network (ANN). Many time-varying parameters, e.g., response times in motor vehicle systems, can be detected and evaluated.',\n",
       " 'An embodiment of a computer implemented method for determining the disposition of a hyperdocument includes retrieving a hyperdocument from an information source, providing information about content of the hyperdocument to a trained artificial neural network (ANN), the ANN being capable of evaluating the information and providing results reflecting the evaluation, and determining the disposition of the hyperdocument based upon results of the ANN.',\n",
       " 'An embodiment of a computer implemented method for determining the disposition of a hyperdocument includes retrieving a hyperdocument from an information source, providing information about content of the hyperdocument to a trained artificial neural network (ANN), the ANN being capable of evaluating the information and providing results reflecting the evaluation and determining the disposition of the hyperdocument based upon results of the ANN.',\n",
       " 'Apparatus and methods for universal node design implementing a universal learning rule in a mixed signal spiking neural network. In one implementation, at one instance, the node apparatus, operable according to the parameterized universal learning model, receives a mixture of analog and spiking inputs, and generates a spiking output based on the model parameter for that node that is selected by the parameterized model for that specific mix of inputs. At another instance, the same node receives a different mix of inputs, that also may comprise only analog or only spiking inputs and generates an analog output based on a different value of the node parameter that is selected by the model for the second mix of inputs. In another implementation, the node apparatus may change its output from analog to spiking responsive to a training input for the same inputs.',\n",
       " 'Provided herein are apparatus and methods relating to the development of instrumentation for high throughput network electrophysiology and cellular analysis. More specifically, provided herein are multiwell microelectrode arrays (MEAs) and methods for the development of such an apparatus in an inexpensive fashion with a flexible, ANSI/SBS-compliant (American National Standards Institute/Society for Biomolecular Screening) format. Microelectrode arrays are a grid of tightly spaced microelectrodes useful for stimulating and sensing electrically active cells, networks and tissue. The techniques described herein relate to the use of microfabrication in combination with certain large-area processes that have been employed to achieve multiwell MEAs in ANSI/SBS-compliant culture well formats, which are also transparent for inverted/backside microscopy compatibility. These multiwell MEAs can be used to investigate two and three-dimensional networks of electrically active cells and tissue such as cardiac, neural, and muscular in a high throughput fashion. Also being ANSI/SBS-compliant, they are compatible with machinery and robotics developed for the pharmaceutical industry for drug screening applications.',\n",
       " 'Apparatus and methods are provided for predicting a plurality of unknown parameter values (e.g. overlay error or critical dimension) using a plurality of known parameter values. In one embodiment, the method involves training a neural network to predict the plurality of parameter values. In other embodiments, the prediction process does not depend on an optical property of a photolithography tool. Such predictions may be used to determine wafer lot disposition.',\n",
       " 'Neural network apparatus and methods for implementing reinforcement learning. In one implementation, the neural network is a spiking neural network, and the apparatus and methods may be used for example to enable an adaptive signal processing system to effect focused exploration by associative adaptation, including providing a negative reward signal to the network, which may increase excitability of the neurons in combination with decrease in excitability of active neurons. In certain implementations, the increase is gradual and of smaller magnitude, compared to the excitability decrease. In some implementations, the increase/decrease of the neuron excitability is effectuated by increasing/decreasing an efficacy of the respective synaptic connections delivering presynaptic inputs into the neuron. The focused exploration may be achieved for instance by non-associative potentiation configured based at least on the input spike rate. The non-associative potentiation may further comprise depression of connections that provide input in excess of a desired limit.',\n",
       " 'Apparatus and methods for efficient synaptic update in a network such as a spiking neural network. In one embodiment, the post-synaptic updates, in response to generation of a post-synaptic pulse by a post-synaptic unit, are delayed until a subsequent pre-synaptic pulse is received by the unit. Pre-synaptic updates are performed first following by the post-synaptic update, thus ensuring synaptic connection status is up-to-date. The delay update mechanism is used in conjunction with system “flush” events in order to ensure accurate network operation, and prevent loss of information under a variety of pre-synaptic and post-synaptic unit firing rates. A large network partition mechanism is used in one variant with network processing apparatus in order to enable processing of network signals in a limited functionality embedded hardware environment.',\n",
       " 'An apparatus based on an n-variable unlimited recurrent adjustable network (URAN.sub.n) comprises: two layers, each layer having the same number (n) of neuron elements; linear neuron elements x.sub.i constituting a first layer; nonlinear artificial neuron elements y.sub.j having respective temperature-dependent parameters Tj and constituting a second layer. Each linear and nonlinear neuron element of the first and second layers is connected using a feedforward connection part, a recurrent connection part, and an auto connection part. A nonlinear oscillation apparatus having the recurrent neural network is generally operated in accordance with the equation (1) described below: ##EQU1##',\n",
       " 'An artificial network for encoding the binary on-state of one-out-of-N inputs, say j, when only one state is on at a time wherein the jth on-state is represented by a suitable output level of an N-input MP type neuron operating in the non-saturated region of the neuron output nonlinearity. A single line transmits the encoded amplitude level signal to a decoder having N single input neural networks. The N outputs of the decoder are in the off-state except for the output corresponding to the active input node of the encoder',\n",
       " 'A sensor based automated cooking apparatus is provided. A humidity sensor measures the moisture content within a cooking cavity. An output of the sensor is provided to a digital filter to remove noise therefrom before being passed to a feature extractor which performs a data compression step and extracts salient features relating to the shape of the humidity versus time characteristic. The parameters are analyzed by a neural network to estimate a degree of doneness of the food. A controller uses the degree of doneness to estimate the remaining cooking time and appropriate power level. The cooking apparatus then operates in an open loop mode for the remainder of the cooking time using the appropriate power level.',\n",
       " \"An apparatus (5) for generating an approximation function based on first pairs ((X.sub.1, Y.sub.1) to (X.sub.6, Y.sub.6)) of values associating a dependent variable (Y.sub.1 to Y.sub.6) with an independent variable (X.sub.1 to X.sub.6), and for determining second pairs (X.sub.A, Y'.sub.A) of values of said variables in accordance with said approximation function. The apparatus comprises: a) first means (10) for iteratively determining at least one current linear regression function, for selecting that one of the current linear functions which produces the approximation of all the pairs of said series with minimal errors, and for coding the selected linear regression function with the aid of specific codes (p, q), and b) second means (17) for determining said second pairs (X.sub.A, Y'.sub.A) with the aid of said specific codes. The apparatus can also be used for calculating approximated values of mathematical functions, for example a in a neural network, or for determining a regression function forming an approximation to experimental measurement results, for example distributed measurements resulting from monitoring an industrial process. The invention also relates to a method of generating an approximation function.\",\n",
       " \"A user authentication apparatus for use in controlling access to a system inputs an owner's login name and password and then extracts the owner's timing vectors from keystroke characteristics with which the owner repeatedly types the owner's password to thereby form a training set. A neural network is trained by using each of the owner's timing vectors in the training set as an input. Thereafter, when a user inputs the owner's login name and password, it is checked if the user's password is identical to the owner's password. The user's timing vector is extracted from a keystroke characteristic to type the user's password if the checked result is affirmative, and the user is prohibited from accessing the system if otherwise. The user's timing vector is applied to the trained neural network as an input and a difference between the input and an output of the neural network is compared with a predetermined threshold. The user will be permitted to access the system if the difference is not greater than the threshold and prohibited from accessing the system if otherwise.\",\n",
       " 'There are disclosed an apparatus for calculating a posteriori probabilities of phoneme symbols and a speech recognition apparatus using the apparatus for calculating a posteriori probabilities of phoneme symbols. A feature extracting section extracts speech feature parameters from a speech signal of an uttered speech sentence composed of an inputted character series, and a calculating section calculates a a posteriori probability of a phoneme symbol of the speech signal, by using a bidirectional recurrent neural network. The bidirectional recurrent neural network includes (a) an input layer for receiving the speech feature parameters extracted by the feature extracting means and a plurality of hypothetical phoneme symbol series signals, (b) an intermediate layer of at least one layer having a plurality of units, and (c) an output layer for outputting a a posteriori probability of each phoneme symbol. The input layer includes (a) a first input neuron group having a plurality of units, for receiving a plurality of speech feature parameters and a plurality of phoneme symbol series signals, (b) a forward module, and (c) a backward module.',\n",
       " 'The past record of the synaptic weight values set in the learning of a neural network is stored in a weight record memory. The past stored in the weight record memory is supplied to a control unit. If there exists a synaptic connection representing a record of weight values which have been used in a predetermined number of learning processes just prior to the present learning process and which satisfy a predetermined condition, the synaptic weight value used in the succeeding learning processes for the synaptic connection is re-set to a predetermined value by a weight setting unit. That is, the past record of the synaptic weight values is monitored, and the synaptic weight value which has been set in a learning process can be re-set as required.',\n",
       " 'An apparatus for storing weight coefficients for a multi-layer neural network is disclosed, wherein information representing connection coefficients is stored which represent strengths of connections between neurons of a multi-layer neural network constituted of an input layer, an intermediate layer, and an output layer, each of the input layer, the intermediate layer, and the output layer being composed of at least a single neuron. The apparatus for storing weight coefficients for a multi-layer neural network is provided with a device for classifying connections, which classifies the connections as having a high degree of connection or having a low degree of connection by comparing the connection coefficients with a predetermined threshold value, and which classifies the connections on the input side of each of the neurons as having a low degree of connection in cases where all of the connections on the output side of each said neuron have been classified as having a low degree of connection, and a storage device for storing information representing the connection coefficients of the connections, which have been classified as having a high degree of connection, and information concerning the corresponding table, which indicates whether the connections between the neurons have been classified as having a high degree of connection or having a low degree of connection by the device for classifying connections.',\n",
       " 'An array of spaced parallel linear radiation beams are projected across a passage in sequentially spaced regions. Detectors sense when the beams are interrupted by one or more persons moving in the passage in either of two opposite directions. The beams are interrupted at different times in a sequence corresponding to the number of and direction of movement of persons. The sequentially generated interrupted beam signals are stored as object movement historic information in memory and later processed to generate composite beam interrupt patterns manifesting the number of persons and direction of movement, the patterns being a function of time domain and sensor index, i.e., sensor identity and position in the passage. The resulting generated patterns are compared to reference patterns utilizing computerized pattern recognition analysis such as with an artificial neural network. The comparison classifies the persons in the passage into direction of movement and number.',\n",
       " 'Apparatus for communication between a neural network and a user system via a bus includes an activity/frequency converter for each neurone of the network. The activity/frequency converter produces activity pulses which are encoded by encoders and then placed on the communication bus. Arbitration arrangements for each converter include an inhibition control circuit and a blocking circuit connected in common to all the converters to transmit a temporary blocking command to them. Each control circuit detects the presence of a pulse at the output of its associated converter and, while any such pulse is present, activates the blocking circuit so that it transmits the command for temporarily blocking their operation to the other converters.',\n",
       " 'In a neural network having neurons connected in a multi-layer, firstly, input signal sets are sequentially entered to statistically process the outputs of hidden neurons and determine the optimum number of hidden neurons. Secondly, while changing the input signal entered to each input neuron to the maximum change limit, the change of output values of the other input neurons are checked to thereby determine an unnecessary input neuron. Thirdly, the weights between input neurons and hidden neurons are set to be in correspondence with a hyperplane to enable pattern recognition.',\n",
       " \"An apparatus for deciding a shift pattern suitable for a driver's habit using a neural network operation and fuzzy inference and a control method thereof which perform a neural network operation by inputting a driver's driving operation quantity as a deciding condition of a shift pattern, and decide an optimal shift pattern by performing fuzzy inference from the output from the a neural network operation.\",\n",
       " 'A latching tester for testing continuity of wires in a system has an array of pin electronics cells, where each pin cell couples a signal to a row sense line and a column sense line when a change in current flow through a pin occurs; apparatus for detecting the signal on the row sense line; and apparatus for detecting the signal on the column sense line. The array of pin electronics cells may also operate as a capacitively coupled neural network, where a signal coupled onto the row and column lines from a stimulus line varies with the load on each pin of the pin electronics cells. An alternate mode of operation permits stimulus of the network and attached loads, and generation of a signature based upon the response of the network to the stimulus, as observed on the row and column sense lines. In yet another mode of operation, the tester may serve to recognize particular signals.',\n",
       " 'Apparatus for detecting sonar signals embedded in noise includes a neural network trained to detect signals in response to the slope of amplitude rank ordered noise corrected powers. A detector detects an analog waveform. Means samples and digitizes the analog waveform to obtain digital samples which in turn are passed through a cosine window. The digital samples are Fourier transformed into conjugate sets of complex numbers representing amplitude and phase. One conjugate set of the complex numbers are discarded, and the remaining complex numbers ranked according to frequency. The sum of the square of the real and imaginary component of each of the remaining complex numbers in a frequency band are provided to obtain a corresponding series of representing estimated power ranked by frequency over the band. The noise contained in subbands of the band is estimated. Each estimated power is then divided by the estimated noise of the subband containing the estimated power to obtain corresponding noise corrected powers, which are ranked ordered according to amplitude. The amplitude rank ordered noise powers are provided to corresponding inputs of the neural network.',\n",
       " 'A nondestructive inspection apparatus includes a sensor unit for detecting vibrations transmitted through a test object from a vibration generator and a signal input unit for extracting a target signal from an electric signal outputted from the sensor unit. An amount of characteristics extracting unit is also included for extracting multiple frequency components from the test signal as an amount of characteristics. Further, a decision unit has a competitive learning neural network for determining whether the amount of the characteristics belongs to a category, wherein the competitive learning neural network has been trained by using training samples belong to the category representing an internal state of the test object, wherein distributions of membership degrees of the training samples are set in the decision unit.',\n",
       " 'A method and apparatus under software control for pattern recognition utilizes a neural network implementation to recognize two dimensional input images which are sufficiently similar to a database of previously stored two dimensional images. Images are first image processed and subjected to a Fourier transform which yields a power spectrum. An in-class to out-of-class study is performed on a typical collection of images in order to determine the most discriminatory regions of the Fourier transform. A feature vector consisting of the highest order (most discriminatory) magnitude information from the power spectrum of the Fourier transform of the image is formed. Feature vectors are input to a neural network having preferably two hidden layers, input dimensionality of the number of elements in the feature vector and output dimensionality of the number of data elements stored in the database. Unique identifier numbers are preferably stored along with the feature vector. Application of a query feature vector to the neural network will result in an output vector. The output vector is subjected to statistical analysis to determine if a sufficiently high confidence level exists to indicate that a successful identification has been made. Where a successful identification has occurred, the unique identifier number may be displayed.',\n",
       " 'A signal processing method and system combines multi-scale decomposition, such as wavelet, pre-processing together with a compression technique, such as an auto-associative artificial neural network, operating in the multi-scale decomposition domain for signal denoising and extraction. All compressions are performed in the decomposed domain. A reverse decomposition such as an inverse discrete wavelet transform is performed on the combined outputs from all the compression modules to recover a clean signal back in the time domain. A low-cost, non-drug, non-invasive, on-demand therapy braincap system and method are pharmaceutically non-intrusive to the body for the purpose of disease diagnosis, treatment therapy, and direct mind control of external devices and systems. It is based on recognizing abnormal brainwave signatures and intervenes at the earliest moment, using magnetic and/or electric stimulations to reset the brainwaves back to normality. The feedback system is self-regulatory and the treatment stops when the brainwaves return to normal. The braincap contains multiple sensing electrodes and microcoils; the microcoils are pairs of crossed microcoils or 3-axis triple crossed microcoils.',\n",
       " 'Apparatus for inspecting an electric resistance welding state including a first electrode connected to a power source, a second electrode connected to another terminal of the power source, and a welding object interposed between the first and the second electrodes. A voltage waveform measuring system includes a first analog-to-digital converter for detecting voltage applied, during a welding process, to both ends of the welding object. An electrode movement measuring system includes a sensor for detecting a change of a gap between the first and the second electrodes during the welding process, and a second analog-to-digital converter for receiving an output of the sensor. A computer system which includes a neural network inspection system for receiving outputs from the voltage waveform measuring system and from the electrode movement measuring system is provided.',\n",
       " 'An apparatus that performs the mathematical matrix-vector multiplication approximation operations using crossbar arrays of resistive memory devices (e.g. memristor, resistive random-access memory, spintronics, etc.). A crossbar array formed by resistive memory devices serves as a memory array that stores the coefficients of a matrix. Combined with input and output analog circuits, the crossbar array system realizes the method of performing matrix-vector multiplication approximation operations with significant performance, area and energy advantages over existing methods and designs. This invention also includes an extended method that realizes the auto-associative neural network recall function using the resistive memory crossbar architecture.',\n",
       " 'A borehole logging tool is lowered into a borehole traversing a subsurface formation and a neutron detector measures the die-away of nuclear radiation in the formation. Intensity signals are produced representing the die-away of nuclear radiation as the logging tool traverses the borehole A signal processor, employing at least one neural network, processes the intensity signals and produces a standoff-corrected epithermal neutron lifetime signal to correct for standoff from the borehole wall encountered by the detector as the logging tool traverses the borehole. The signal processor further generates a porosity signal from the standoff-corrected epithermal neutron lifetime signal derived from measurements in borehole models at known porosities and conditions of detector standoff. A log is generated of such porosity signal versus depth as the logging tool traverses the borehole.',\n",
       " 'Apparatus for pulsed electrical power circuitry includes a pulsed power supply circuit, monitor for monitoring a voltage or current characteristic within the supply circuit and an artificial neural network trained to identify whether the detected characteristic is acceptable or harmful and adapted to produce an output accordingly. The circuit may be arranged to deliver its output to a gas discharge load and the output of the trained network may be adapted to be fed to control a parameter in the circuit or in the load whereby a harmful condition in the circuit may be avoided.',\n",
       " 'An apparatus for recognizing driving environments of a vehicle including a plurality of sensors for detecting various parameters relating to driving conditions of the vehicle such as throttle valve open angle, vehicle running speed, brake pedal depression amount and gear shift range of an automatic transmission, first and second neuron interfaces for converting parameter values detected by the sensors into a plurality of input patterns having predetermined configuration, first and second neural networks having input layers to which corresponding input patterns are applied, hidden layers and output layers for producing recognition results, and a multiplexer for selecting one of the recognition results produced on the output layers of the first and second neural networks. The first neural network has a superior separating or recognizing and learning faculty, while the second neural network has a superior associating faculty. A accelerating pedal depression amount is detected by a sensor and a variation of the thus detected amount is compared with a reference value. When the variation is larger than the reference value, the recognition result produced by the first neural network is selected and when the variation is smaller than the reference value, the recognition result from the second neural network is selected.',\n",
       " 'A computer system with an image reader and nerual network is provided for determining whether an image of text has been generated by a machine or by hand. This serves the useful purpose of allowing one to use speciallized recognition techiques that are more suited to one form of printing, thus achieving a higher recognition accuracy than by using a single recognition technique for both types of printing. The method is based on the premise that the spatial spectra for an image of machine text will have more higher frequency components than one generated by hand, because of the nonregular, nonuniform slant of the handprint. The method proposed generates this spectra by convolving spatial templates with vertical histograms from each line of text, and uses a neural network to classify the resulting spectra.',\n",
       " 'In a reproduced color correction system, a photometer measures external illuminant light and sends a measured result to a workstation. The workstation determines the type of an illuminant on the basis of the measured result and sends a selection signal and corresponding colorimetric value data to a neural network management unit. The neural network management unit is provided with a plurality of neural networks associated with types of illuminants. The neural network selected according to the selection signal converts the colorimetric value to a color separation value according to a post-learning transformation function. A color printing device outputs a color image on the basis of the generated color separation value. Thus, the neural network associated with the illuminant used for observation reference is selected, and appropriate color transformation is performed. Accordingly, even if the viewing condition is changed, color matching can be performed so that observed reproduced colors are unchanged.',\n",
       " 'An apparatus according to the invention for the classification of physiological events has a signal input for the input of a physiological signal representing or constituting a physiological event and a classification unit 1 for classifying the physiological signal on the basis of its signal shape. The classification unit 1 includes a transformation unit 3 which is designed to carry out transformation of the physiological signal in such a way that as the output signal it outputs a number of values representing the physiological signal and based on the transformation; and a probabilistic neural network which is connected to the transformation unit 3 to receive the values and which contains a number of event classes which represent physiological events and which in turn are each represented by a set of comparative values, which probabilistic neural network is adapted on the basis of the comparison of the values with the comparative values to effect an association of the physiological signal represented by the values with one of the event classes.',\n",
       " 'Apparatus for the operation of a plant for producing deinked pulp with state analysers constructed in the form of neural networks for the waste paper suspension. At least one measuring device (ME) records spectral and/or physical characteristic values (IMf, Mp) of a waste paper suspension (PS). Furthermore, there are closed-loop or open-loop control devices (RS1 . . . RS8) for operating means of a waste paper preparation (AAA) in the plant. According to the invention, there is at least one state analyser (ZA), configured in the form of a neural network (NNg) or a plurality of parallel neural networks (NN1 . . . NN4), for the waste paper suspension (PS). This analyser forms from the characteristic values (IMf, Mp) controlled variables (ST: AB, AZ, FL, AA, AS, AT) for process control of the closed-loop or open-loop control devices (RS1 . . . RS8) of operating means at least of the waste paper preparation (AAA). As controlled variables, the ratio of white to coloured papers (AB), the ratio of illustrated-magazine paper to newsprint paper (AZ), the average fibre length (FL), the ash content (AA), the content of dirt (AS) and/or the content of adhesive contaminants (AT) in the waste paper suspension (PS) are suitable with preference.',\n",
       " \"An apparatus for transforming a voice signal of a talker into a voice signal having characteristics of a different person provides apparatus for separating the talker's voice signal into a plurality of voice parameters including frequency components, a neural network for transforming at least some of the separated frequency components into those characteristic of the different person, and apparatus for combining the voice parameters for reconstituting the talker's voice signal having characteristics of the different person.\",\n",
       " 'A signal processing method and system combines multi-scale decomposition, such as wavelet, pre-processing together with a compression technique, such as an auto-associative artificial neural network, operating in the multi-scale decomposition domain for signal denoising and extraction. All compressions are performed in the decomposed domain. A reverse decomposition such as an inverse discrete wavelet transform is performed on the combined outputs from all the compression modules to recover a clean signal back in the time domain. A low-cost, non-drug, non-invasive, on-demand therapy braincap system and method are pharmaceutically non-intrusive to the body for the purpose of disease diagnosis, treatment therapy, and direct mind control of external devices and systems. It is based on recognizing abnormal brainwave signatures and intervenes at the earliest moment, using magnetic and/or electric stimulations to reset the brainwaves back to normality. The feedback system is self-regulatory and the treatment stops when the brainwaves return to normal. The braincap contains multiple sensing electrodes and microcoils; the microcoils are pairs of crossed microcoils or 3-axis triple crossed microcoils.',\n",
       " 'A basic image of objects is extracted from a two-dimensional image of objects. Geometrical elements of the objects are extracted from the extracted basic image. The objects to be recognized are identified by searching a combination of the geometrical elements which match a geometrical model and then utilizing candidate position/orientation of the objects to be recognized, said candidate position/orientation being determined from a relationship in relative position between the combination of geometrical elements and the geometrical model. Mesh cells fixed to the geometrical model are mapped on the basic image based on the candidate position/orientation. In addition, verification is made as to whether an image of the geometrical model mapped by the candidate position/orientation is accurately matched with an image of one of the objects to be recognized, through a neural network to which values got from the basic image included in the individual mesh cells are to be applied as input values. Combination weight factors employed in the neural network are learned according to the verified results. It is also possible to recognize the multi-purpose objects according to how to learn the combination weight factors.',\n",
       " 'A signal processing apparatus using a neural network according to this invention includes a reference signal generating section for generating a plurality of reference signals having different signal values, a complement signal generating section for receiving the reference signals and an unknown input signal as an object to be processed, and generating a plurality of complement signals, indicating complement values of the corresponding reference signals with respect to a signal value obtained by multiplying the unknown input signal with a natural number, a multiplication section for receiving the reference signals and the complement signals, and multiplying the reference signals with the corresponding complement signals, and a neural network, in which a plurality of neurons are reciprocal-inhibition-coupled, the neurons receive the products obtained by the multiplication section, and the neuron, which receives the product having a largest value, outputs a spark signal.',\n",
       " 'A weld controller utilizes a neural network to compute power factor of a secondary circuit of a welding transformer supply power to a workpiece through a pair of welding electrodes. Phase controlled switches supply power to the transformer and the neural network uses the phase angle at the time of energization of the switches and the length of time that the switches conduct to compute the power factor. The computed power factor is compared with previous computations of power factor online and any changes are interpreted as changes in resistance of the secondary circuit. This provides a measure of contact wear and the weld controller can compensate for these changes by increasing weld power. The neural network is adaptable for use with other types of control systems.',\n",
       " 'The invention relates to a method for performing an oilfield operation. The method steps include obtaining oilfield data sets associated with oilfield entities, generating a stochastic database from the oilfield data sets based on an artificial neural network of the oilfield data sets, screening the oilfield data sets to identify candidates from the oilfield entities, wherein the screening is based on the stochastic database, performing a detail evaluation of each candidates, selecting an oilfield entity from the candidates based on the detail evaluation, and performing the oilfield operation for the selected oilfield entity.',\n",
       " 'An apparatus discriminates a potential obstacle in the path of a vehicle from among various objects in an image shot by a monocular camera. First, an object detecting unit detects an object in the image by applying a saliency calculation to the image. Second, an object discriminating unit discriminates an object from among the objects detected by the object detecting unit as a potential obstacle by applying a neural network method to the objects.',\n",
       " 'Methods and systems are disclosed herein in which a physical neural network can be configured utilizing nanotechnology. Such a physical neural network can comprise a plurality of molecular conductors (e.g., nanoconductors) which form neural connections between pre-synaptic and post-synaptic components of the physical neural network. Additionally, a learning mechanism can be applied for implementing Hebbian learning via the physical neural network. Such a learning mechanism can utilize a voltage gradient or voltage gradient dependencies to implement Hebbian and/or anti-Hebbian plasticity within the physical neural network. The learning mechanism can also utilize pre-synaptic and post-synaptic frequencies to provide Hebbian and/or anti-Hebbian learning within the physical neural network.',\n",
       " 'A method for computer-aided detection of anomalies in an image comprise the steps of: (1) dividing the image into a plurality of m.times.n regions; (2) subtracting the background from each of the regions; (3) for each of the regions, selecting a smaller p.times.q subregion; (4) normalizing the p.times.q subregion; (5) feeding the p.times.q subregions into a neural network system, the neural network system having plural member neural networks, each trained to recognize a particular preselected anomaly type; (6) comparing each output value of the plurality of member neural networks to a first threshold; (7) selecting a maximum value from the output values which are greater than the first threshold; (8) comparing the maximum value to a second threshold above which the presence of an anomaly is indicated, and storing the result; (9) clustering a plurality of the stored results to form clusters; and (10) marking the location of the clusters.',\n",
       " 'An information processing system having neuron-like signal processors that are interconnected by synapse-like processing junctions that simulates and extends capabilities of biological neural networks. The information processing systems uses integrate-and-fire neurons and Temporally Asymmetric Hebbian learning (spike timing-dependent learning) to adapt the synaptic strengths. The synaptic strengths of each neuron are guaranteed to become optimal during the course of learning either for estimating the parameters of a dynamic system (system identification) or for computing the first principal component. This neural network is well-suited for hardware implementations, since the learning rule for the synaptic strengths only requires computing either spike-time differences or correlations. Such hardware implementation may be used for predicting and recognizing audiovisual information or for improving cortical processing by a prosthetic device.',\n",
       " 'Software for controlling processes in a heterogeneous semiconductor manufacturing environment may include a wafer-centric database, a real-time scheduler using a neural network, and a graphical user interface displaying simulated operation of the system. These features may be employed alone or in combination to offer improved usability and computational efficiency for real time control and monitoring of a semiconductor manufacturing process. More generally, these techniques may be usefully employed in a variety of real time control systems, particularly systems requiring complex scheduling decisions or heterogeneous systems constructed of hardware from numerous independent vendors.',\n",
       " 'A neural network system including a plurality of tiers of interconnected computing elements. The plurality of tiers includes an input tier whereto a sequence of input speech vectors is applied at a first rate. Two of the plurality of tiers are interconnected through a decimator configured to reduce the first rate of the sequence of input vectors. Alternatively, two of the plurality of tiers are interconnected through an interpolator configured to increase the first rate of the sequence of input vectors.',\n",
       " 'A restraining device for use in a water environment includes a plurality of tendrils that can be launched from a submerged device when an unauthorized swimmer is proximate the restraining device. Data communication in a neural-network of restraining devices is facilitated by a central command that has the capability of directing restraining devices, normally, aquatic mines, to a target.',\n",
       " 'An architecture, systems and methods for a scalable artificial neural network, wherein the architecture includes: an input layer; at least one hidden layer; an output layer; and a parallelization subsystem configured to provide a variable degree of parallelization to the input layer, at least one hidden layer, and output layer. In a particular case, the architecture includes a back-propagation subsystem that is configured to adjust weights in the scalable artificial neural network in accordance with the variable degree of parallelization. Systems and methods are also provided for selecting an appropriate degree of parallelization based on factors such as hardware resources and performance requirements.',\n",
       " 'Systems and methods for a scalable artificial neural network, wherein the architecture includes: an input layer; at least one hidden layer; an output layer; and a parallelization subsystem configured to provide a variable degree of parallelization to the artificial neural network by providing scalability to neurons and layers. In a particular case, the systems and methods may include a back-propagation subsystem that is configured to scalably adjust weights in the artificial neural network in accordance with the variable degree of parallelization. Systems and methods are also provided for selecting an appropriate degree of parallelization based on factors such as hardware resources and performance requirements.',\n",
       " 'In some examples, an arousal network of a brain of a patient can be activated to modify the arousal state of the patient, which may be useful in treating a cognitive disorder of the patient. In some examples, a bioelectrical brain signal indicative of electrical activity in a first portion of the brain is monitored to determine whether the patient is in a first arousal state, and, in response to determining the patient is in the first arousal state, electrical stimulation is delivered to a second portion of the brain to activate an arousal neural network in the first portion of the brain to induce a second arousal state to treat the cognitive disorder, where the second arousal state is different than the first arousal state.',\n",
       " 'An arrangement for modeling a non-linear process including at least one input variable (x1, x2) and at least one output variable (y) can include a neural network and a device for specifying functional (or operational) values. A function of the neural network is determined in a first part of the domain of input variables (x1, x2) by learning from measuring data, which are obtained from the process by acquiring measured values. An empirically based device for specifying functional (or operational) values, preferably a fuzzy system, is provided in a second part of the domain of input variables (x1, x2) in which there are no measuring data for training the neural network. This arrangement is particularly useful when it is implemented in controllers.',\n",
       " 'An arrangement and method are presented that enable a prediction of an abnormality and implement a suitable action opposing the abnormality. An information flow underlying a dynamic system is interpreted and a prediction quantity that comprises the abnormality as characterizing quantity of the dynamic system is determined from it. A neural network is trained with measured data of the system. After the training, the abnormality can be indicated on the basis of the prediction quantity before it occurs and the occurrence can be opposed with suitable measures.',\n",
       " 'An arrangement of data cells which stores at least one matrix of data words which are arranged in rows and columns, the matrix being distributed in the arrangement in order to deliver/receive, via a single bus, permuted data words which correspond either to a row or to a column of the matrix. Each data cell is connected to the single bus via series-connected switches which are associated with a respective addressing mode, the switches which address a same word of a same mode being directly controlled by a same selection signal. Circulation members enable the original order of the data on the bus to be restored. An arrangement of this kind is used in a layered neural network system for executing the error backpropagation algorithm. Application: Calculator, microprocessors, processor, neural network system. Reference: FIG. 4.',\n",
       " 'An arrangement of data cells which stores at least one matrix of data words which are arranged in rows and columns, the matrix being distributed in the arrangement in order to deliver/receive, via a single bus, permuted data words which correspond either to a row or to a column of the matrix. Each data cell is connected to the single bus via series-connected switches which are associated with a respective addressing mode, the switches which address a same word of a same mode being directly controlled by a same selection signal. Circulation members enable the original order of the data on the bus to be restored. An arrangement of this kind is used in a layered neural network system for executing the error backpropagation algorithm.',\n",
       " 'An arrangement of data cells which stores at least one matrix of data words which are arranged in rows and columns, the matrix being distributed in the arrangement in order to deliver/receive, via a single bus, permuted data words which correspond either to a row or to a column of the matrix. Each data cell is connected to the single bus via series-connected switches which are associated with a respective addressing mode, the switches which address a same word of a same mode being directly controlled by a same selection signal. Circulation members enable the original order of the data on the bus to be restored. An arrangement of this kind is used in a layered neural network system for executing the error backpropagation algorithm.',\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on computer storage media, for correcting a corrupted data sample using a trained deep neural network, the method including obtaining a feature representation of a corrupted data sample; and modifying the feature representation of the corrupted data sample to generate a feature representation of a corrected data sample by iteratively processing a current version of the feature representation of the corrupted data sample using the trained deep neural network to generate a current corruption score for the current version of the feature representation of the corrupted data sample and generating a less-corrupted version of the feature representation by performing an iteration of gradient descent against the current version of the feature representation of the corrupted data sample to reduce the current corruption score.',\n",
       " 'Described herein are systems and methods for normalizing data without the use of external controls. Also described herein are systems and methods for analyzing cluster data, such as genotyping data, using an artificial neural network.',\n",
       " 'Described herein are systems and methods for normalizing data without the use of external controls. Also described herein are systems and methods for analyzing cluster data, such as genotyping data, using an artificial neural network.',\n",
       " 'A system and method facilitating lithography defect solution generation is provided. The invention includes a defect solution component and a defect alert component. The defect solution component provides potential solution(s) to a defect within the lithography process utilizing artificial intelligence technique(s) (e.g., Bayesian learning methods that perform analysis over alternative dependent structures and apply a score, Bayesian classifiers and other statistical classifiers, including decision tree learning methods, support vector machines, linear and non-linear regression and/or neural network).',\n",
       " 'A data processing system program to develop, train, and implement a neural network for identifying customers who represent a bad debt risk is disclosed. A feature vector is applied to a neural network to generate outputs that approximate the relative likelihood that customers who are the subjects of the records used to generate the feature vector will be a bad debt risk. Statistical values relating categorical attributes of the customers to the likelihood of their becoming a bad debt risk are substituted for the categorical attributes, and the attributes are normalized before the feature vector is applied to the network. In one embodiment the customers are customers of a long distance service provider.',\n",
       " 'A data processing system program to develop, train, and implement a neural network for identifying customers who represent a bad debt risk is disclosed. A feature vector is applied to a neural network to generate outputs that approximate the relative likelihood that customers who are the subjects of the records used to generate the feature vector will be a bad debt risk. Statistical values relating categorical attributes of the customers to the likelihood of their becoming a bad debt risk are substituted for the categorical attributes, and the attributes are normalized before the feature vector is applied to the network. In one embodiment the customers are customers of a long distance service provider.',\n",
       " 'An artificial neural synapse (10) is constructed to function as a modifiable excitatory synapse. In accordance with an embodiment of the invention the synapse is fabricated as a silicon MOSFET that is modified to have ions within a gate oxide. The ions, such as lithium, sodium, potassium or fluoride ions, are selected for their ability to drift within the gate oxide under the influence of an applied electric field. In response to a positive voltage applied to a gate terminal of the device, positively charged ions, such as sodium or potassium ions, drift to a silicon/silicon dioxide interface, causing an increase in current flow through the device. The invention also pertains to assemblages of such devices that are interconnected to form an artificial neuron and to assemblages of such artificial neurons that form an artificial neural network.',\n",
       " 'A computer-based artificial network is presented that is capable of learning, recognizing, and generating temporal-spatial sequences. The network system includes time-delays and artificial neural subnetworks. The system generally includes three parts: (1) comparator units, (2) a parallel array of subnetworks and (3) delayed feedback lines from the output of the system to the neural subnetwork layer.',\n",
       " 'An artificial neural network that can act like the real neural network according to the input history of signals input. The network includes a learning circuit that stores an input history of an input signal, an output circuit that is connected to the learning circuit, and a reset circuit that resets the input history stored in the learning circuit. The learning circuit changes a potential-change characteristic of an internal node included in the output circuit, according to the input history. The output circuit starts an output operation of data when a potential at the internal node exceeds a threshold value. The artificial neural network of this invention can operate almost in the same way as the real neural network, because it performs an output operation, such as an oscillating operation, in response to the history of the input signal.',\n",
       " 'An artificial neural network comprises at least one input layer with a predetermined number of input nodes and at least one output layer with a predetermined number of output nodes or also at least one intermediate hidden layer with a predetermined number of nodes between the input and the output layer. At least the nodes of the output layer and/or of the hidden layer and/or also of the input layer carry out a non linear transformation of a first non linear transformation of the input data for computing an output value to be fed as an input value to a following layer or the output data if the output layer is considered.',\n",
       " 'An artificial neural network (ANN) classifier provides a series of outputs indicative of a series of classes to which input feature vectors are classified. The ANN provides only one output for each input feature vector to partition said input into one class. The one output of the classifier is coupled to the interrupt input of an associated digital computer or CPU. Upon receipt of the output, the CPU immediately interrupts a main program and executes an interrupt service routine which is triggered by the output of the classifier. In this manner, the CPU is immediately accessed in the interrupt mode by the transition of one of the output class processing elements when activated.',\n",
       " 'Power industry boiler tube failures are a major cause of utility forced outages in the United States, with approximately 41,000 tube failures occurring every year at a cost of $5 billion a year. Accordingly, early tube leak detection and isolation is highly desirable. Early detection allows scheduling of a repair rather than suffering a forced outage, and significantly increases the chance of preventing damage to adjacent tubes. The instant detection scheme starts with identification of boiler tube leak process variables which are divided into universal sensitive variables, local leak sensitive variables, group leak sensitive variables, and subgroup leak sensitive variables, and which may be automatically be obtained using a data driven approach and a leak sensitivity function. One embodiment uses artificial neural networks (ANN) to learn the map between appropriate leak sensitive variables and the leak behavior. The second design philosophy integrates ANNs with approximate reasoning using fuzzy logic and fuzzy sets. In the second design, ANNs are used for learning, while approximate reasoning and inference engines are used for decision making. Advantages include use of already monitored process variables, no additional hardware and/or maintenance requirements, systematic processing does not require an expert system and/or a skilled operator, and the systems are portable and can be easily tailored for use on a variety of different boilers.',\n",
       " 'Power industry boiler tube failures are a major cause of utility forced outages in the United States, with approximately 41,000 tube failures occurring every year at a cost of $5 billion a year. Accordingly, early tube leak detection and isolation is highly desirable. Early detection allows scheduling of a repair rather than suffering a forced outage, and significantly increases the chance of preventing damage to adjacent tubes. The instant detection scheme starts with identification of boiler tube leak process variables which are divided into universal sensitive variables, local leak sensitive variables, group leak sensitive variables, and subgroup leak sensitive variables, and which may be automatically be obtained using a data driven approach and a leak sensitivity function. One embodiment uses artificial neural networks (ANN) to learn the map between appropriate leak sensitive variables and the leak behavior. The second design philosophy integrates ANNs with approximate reasoning using fuzzy logic and fuzzy sets. In the second design, ANNs are used for learning, while approximate reasoning and inference engines are used for decision making. Advantages include use of already monitored process variables, no additional hardware and/or maintenance requirements, systematic processing does not require an expert system and/or a skilled operator, and the systems are portable and can be easily tailored for use on a variety of different boilers.',\n",
       " 'A method for predicting and optimizing magnetic core width of a write head using neural networks to analyze manufacturing parameters, and determining new manufacturing parameters that will provide more optimal magnetic core width results. The manufacturing parameters can include: write pole flare point; wrap around shield dimension; and side gap dimension.',\n",
       " 'A system for classification of the emotional content of music is provided. An encoder receives a digital audio recording of a piece of music, and encodes it using musical notes and associated amplitudes. The artificial neural network is configured to take a plurality of encoded time slices and provide output indicative of the emotional content of the music.',\n",
       " 'A neural network based universal time series prediction system for financial securities includes a pipelined recurrent ANN architecutre having a plurality of identical modules to first adjust internal weights and biases in response to a first training set representing a nonlinear financial time series of samples of a financial quantity and a target value, and then determine and store an estimated prediction error of the ANN in order to adjust short time stock price predictions in accordance with the stored prediction error. The prediction system is also designed to output upper and lower prediction bounds within a confidence region.',\n",
       " 'The present invention is a method of diagnosing a cardiopulmonary condition in an individual by comparing data from a progressive multi-stage test for the individual to a non-linear multi-variate model, preferably a recurrent artificial neural network having sensor fusion. The present invention relies on a cardiovascular model developed from physiological measurements of an individual. Any differences between the modeled parameters and the parameters of an individual at a given time are used for diagnosis.',\n",
       " 'Disclosed herein is a programming tool stored on a computer-readable medium and adapted for implementation by a computer for designing an artificial neural network. The programming tool includes a network configuration module to provide a first display interface to support configuration of the artificial neural network, and a pattern data module to provide a second display interface to support establishment and modification of first and second pattern data sets for training and testing the artificial neural network, respectively.',\n",
       " 'Methods and apparatuses for balancing computing workload via migrating computing tasks are disclosed. An artificial neural network (ANN) is trained based on the workload distribution over time for a host. The ANN predicts the workload for the host, and an indication may be sent to migrate at least one computing task away from the host. The indication is sent when the method is operating in a proactive mode and when the predicted workload is outside of a desired operating range. Some embodiments monitor the workload; and automatically switch the method to the proactive mode, when a difference between the monitored workload and the predicted workload is small. Other embodiments monitor the workload; and automatically switch the method to a reactive mode, when the monitored workload is outside of a failsafe operating range for the particular host.',\n",
       " 'A method for predicting respiratory disturbances, and a method for developing such an artificial neural network. The inputs to the method and to the artificial neural network of the present invention are the answers given by a person to a series of questions. The output of the artificial neural network is a predicted respiratory disturbance index.',\n",
       " 'An artificial neural network having analog circuits for simultaneous parallel processing using individually variable synaptic input weights. The processing is implemented with a circuit adapted to vary the weight, which may be stored in a metal oxide field effect transistor, for teaching the network by addressing from outside the network or for Hebbian or delta rule learning by the network itself.',\n",
       " 'An architecture and data processing method for a neural network that can approximate any mapping function between the input and output vectors without the use of hidden layers. The data processing is done at the sibling nodes (second row). It is based on the orthogonal expansion of the functions that map the input vector to the output vector. Because the nodes of the second row are simply data processing stations, they remain passive during training. As a result the system is basically a single-layer linear network with a filter at its entrance. Because of this it is free from the problems of local minima. The invention also includes a method that reduces the sum of the square of errors over all the output nodes to zero (0.000000) in fewer than ten cycles. This is done by initialization of the synaptic links with the coefficients of the orthogonal expansion. This feature makes it possible to design a computer chip which can perform the training process in real time. Similarly, the ability to train in real time allows the system to retrain itself and improve its performance while executing its normal testing functions.',\n",
       " 'An architecture and data processing method for a neural network that can approximate any mapping function between the input and output vectors without the use of hidden layers. The data processing is done at the sibling nodes (second row). It is based on the orthogonal expansion of the functions that map the input vector to the output vector. Because the nodes of the second row are simply data processing stations, they remain passive during training. As a result the system is basically a single-layer linear network with a filter at its entrance. Because of this it is free from the problems of local minima. The invention also includes a method that reduces the sum of the square of errors over all the output nodes to zero (0.000000) in fewer than ten cycles. This is done by initialization of the synaptic links with the coefficients of the orthogonal expansion. This feature makes it possible to design a computer chip which can perform the training process in real time. Similarly, the ability to train in real time allows the system to retrain itself and improve its performance while executing its normal testing functions. Because the second synaptic link values represent the frequency spectrum of the signal appearing on a given output node, by training the ONN with all N sibling nodes and using only some of them in testing, we can create a low pass, a high pass or a band pass filter.',\n",
       " 'A system and method for modeling technology to predict accurately water-oil relative permeability uses a type of artificial neural network (ANN) known as a Generalized Regression Neural Network (GRNN) The ANN models of relative permeability are developed using experimental data from waterflood core test samples collected from carbonate reservoirs of Arabian oil fields Three groups of data sets are used for training, verification, and testing the ANN models Analysis of the results of the testing data set show excellent correlation with the experimental data of relative permeability, and error analyses show these ANN models outperform all published correlations',\n",
       " 'Here the inventors describe a tumor classifier based on protein expression. Also disclosed is the use of proteomics to construct a highly accurate artificial neural network (ANN)-based classifier for the detection of an individual tumor type, as well as distinguishing between six common tumor types in an unknown primary diagnosis setting. Discriminating sets of proteins are also identified and are used as biomarkers for six carcinomas. A leave-one-out cross validation (LOOCV) method was used to test the ability of the constructed network to predict the single held out sample from each iteration with a maximum predictive accuracy of 87% and an average predictive accuracy of 82% over the range of proteins chosen for its construction.',\n",
       " 'A magnetic read channel employs an artificial neural network for reconstruction of a recorded magnetic signal and its corresponding synchronization signal. A magnetic read head receives magnetic signals from a magnetic recording media such as a magnetic tape or disk and converts it to an electronic signal. A preamplifier receives and amplifies the electronic signal from the magnetic read head to produce an amplified electronic signal. A delay line receives the amplified electronic signal from the preamplifier, storing delayed successive representations of the received signal. An artificial neural network receives the delayed successive representations from the delay line for reconstruction of the originally recorded data signal. Prior to use in an application, the artificial neural network is trained via a training method with a known training set of corresponding simultaneously generated data and clock pairs. Training the network with data having such known clock (synchronization) signal enables extraction of the synchronization signal from its nonlinear properties hidden within its corresponding data.',\n",
       " 'A non-biological asynchronous neural network system comprising multiple neurons to receive respective input signals representing an input stimulus for the network, supply an output signal representing a spatio-temporal sequence of rhythmic electric pulses to an external system, wherein respective ones of the multiple neurons are connected using multiple mutually inhibitory links.',\n",
       " 'An artificial neural network, which has a plurality of neurons each receiving a plurality of inputs whose effect is determined by adjust able weights at synapses individually connecting the inputs to the neuron to provide a sum signal to a sigmoidal function generator determining the output of the neuron, undergoes memory modification by a steepest-descent method in which individual variations in the outputs of the neurons are successively generated by small perturbations imposed on the sum signals. As each variation is generated on the output of a neuron, an overall error of all the neuron outputs in relation to their desired values is measured and compared to this error prior to the perturbation. The difference in these errors, with adjustments which may be changed as the neuron outputs converge toward their desired values, is used to modify each weight of the neuron presently subjected to the perturbation.',\n",
       " 'An artificial neural network (ANN) decoding system decodes a convolutionally-encoded data stream at high speed and with high efficiency. The ANN decoding system implements the Viterbi algorithm and is significantly faster than comparable digital-only designs due to its fully parallel architecture. Several modifications to the fully analog system are described, including an analog/digital hybrid design that results in an extremely fast and efficient Viterbi decoding system. A complexity and analysis shows that the modified ANN decoding system is much simpler and easier to implement than its fully digital counterpart. The structure of the ANN decoding system of the invention provides a natural fit for VLSI implementation. Simulation results show that the performance of the ANN decoding system exactly matches that of an ideal Viterbi decoding system.',\n",
       " 'A robust Artificial Neural Network controller is proposed for the motion control of a magnetic disk drive voice coil motor (voice coil motor). The neural controller is used to approximate the nonlinear functions (actuator electromechanical dynamics) of the voice coil motor while having on line training. One main advantage of this approach, when compared with standard adaptive control, is that complex dynamical analysis is not needed. Using this design, not only strong robustness with respect to uncertain dynamics and non-linearities can be obtained, but also the output tracking error between the plant output and the desired reference can asymptotically converge to zero. Additionally, standard offline training, utilizing training vectors to stimulate the voice coil motor, is not required.',\n",
       " \"A neural network circuit is provided having a plurality of circuits capable of charge storage. Also provided is a plurality of circuits each coupled to at least one of the plurality of charge storage circuits and constructed to generate an output in accordance with a neuron transfer function. Each of a plurality of circuits is coupled to one of the plurality of neuron transfer function circuits and constructed to generate a derivative of the output. A weight update circuit updates the charge storage circuits based upon output from the plurality of transfer function circuits and output from the plurality of derivative circuits. In preferred embodiments, separate training and validation networks share the same set of charge storage circuits and may operate concurrently. The validation network has a separate transfer function circuits each being coupled to the charge storage circuits so as to replicate the training network's coupling of the plurality of charge storage to the plurality of transfer function circuits. The plurality of transfer function circuits may be constructed each having a transconductance amplifier providing differential currents combined to provide an output in accordance with a transfer function. The derivative circuits may have a circuit constructed to generate a biased differential currents combined so as to provide the derivative of the transfer function.\",\n",
       " 'A low-order model (LOM) of biological neural networks and its mathematical equivalents including the clusterer interpreter probabilistic associative memory (CIPAM) are disclosed. They are artificial neural networks (ANNs) organized as networks of processing units (PUs), Each PU comprising artificial neuronal encoders, synapses, spiking/nonspiking neurons, and a scheme for maximal generalization. If the weights in the artificial synapses in a PU have been learned (and then fixed) or can be adjusted by the unsupervised accumulation rule and the unsupervised covariance rule (or supervised covariance rule), the PU is called unsupervised (or supervised) PU. The disclosed ANNs, with these Hebbian-type learning rules, can learn large numbers of large input vectors with temporally/spatially hierarchical causes with ease and recognize such causes with maximal generalization despite corruption, distortion and occlusion. An ANN with a network of unsupervised PUs (called clusterer) and offshoot supervised PUs (called interpreter) is an architecture for many applications.',\n",
       " 'Artificial neural networks include a plurality of artificial neurons and a plurality of Boolean-complete compartments, a respective one of which couples a respective pair of artificial neurons. By providing Boolean-complete compartments, spurious complement memories can be avoided. A Boolean-complete compartment includes a collection of at least four Boolean functions that represent input vectors to the respective pair of artificial neurons. The collection of at least four Boolean functions are selected from sixteen possible Boolean functions that can represent input vectors to the respective pair of artificial neurons. A count for each of the at least four Boolean functions is also provided. The count represents a number of occurrences of each of the at least four Boolean functions in input vectors to the respective pair of artificial neurons. In order to read the artificial neural network, the network also includes a collection of transfer functions, a respective one of which is associated with a respective one the sixteen possible Boolean functions.',\n",
       " 'An artificial neural system has input operational amplifiers providing differential voltage input signals to a neuron including a voltage divider network having a plurality of substantially equal resistances selectably connectable to the components of the input signals so as to define the bits of binary weights for each of the input signals and to generate unweighted network output voltage signals corresponding to each bit position of the weights and representing the sums of the products of each input signal and the bit at each bit position. The unweighted bit position signals are provided to a bit position weighting device which is common to all of the weights of a neuron and which weights the unweighted signals by the binary positional values of the bit positions. The unweighted bit position signals are differential signals having one component generated by reference resistances of the network, and the sign of each weight may be selected by connection of the reference resistances to one or the other of the input signal components. A preferred embodiment has only one reference resistance for each weight. This reference resistance corresponds to a sign bit position, and the reference resistances for all of the weights are connected to provide a common reference voltage component for all of the unweighted bit position signals. Differential voltage output signals from a system utilized as one artificial neural layer may be directly connected as differential voltage input signals for the voltage divider network of a system utilized as a second layer.',\n",
       " 'A neuron element with electrically programmable synaptic weight for an artificial neural network features an excitatory-connection floating-gate transistor and an inhibitory-connection floating-gate transistor. The control gate electrodes of the two transistors are connected together, and the drain electrode of the inhibitory-connection transistor is connected to the source electrode of the excitatory-connection transistor. Both of the excitatory-connection and inhibitory-connection transistors have programming electrodes. The control gate electrodes and the programming electrodes can be utilized to program the threshold voltages of the transistors and thus the synaptic weight of the neuron element.',\n",
       " 'An artificial neuron for use in a neural processing network comprises a plurality of input signal lines, an arrangement for computing a nonlinear function of the sum of the inputs multiplied by associated weights, and a saturating delta-sigma modulator which oversamples the computed value and produces an encoded neuron output signal. Conversion of signals for use by these neurons preferably is performed by delta-sigma modulators at the inputs to the neurons, which may be incorporated directly into sensors. Processing of the output signals from the neuron includes low-pass filtering and decimation. The present invention may be used in many diverse areas. For example, arrays of sensors with delta signal modulators may be coupled with a network of the neurons to form an intelligent vision system. Linear signal processing, both conventional and adaptive, can be done by a simple neuronal system that operates linearly.',\n",
       " 'An artificial neuron for use in a neural processing network comprises a plurality of input signal lines, an arrangement for computing a nonlinear function of the sum of the inputs multiplied by associated weights, and a saturating delta-sigma modulator which oversamples the computed value and produces an encoded neuron output signal. Conversion of signals for use by these neurons preferably is performed by delta-sigma modulators at the inputs to the neurons, which may be incorporated directly into sensors. Processing of the output signals from the neuron includes low-pass filtering and decimation. The present invention may be used in many diverse areas. For example, arrays of sensors with delta signal modulators may be coupled with a network of the neurons to form an intelligent vision system. Linear signal processing, both conventional and adaptive, can be done by a simple neuronal system that operates linearly.',\n",
       " 'The present invention relates to an artificial olfactory system (100), comprising of an inlet (101); a gas chamber (110) having a detector means, connected to a data acquisition system (104); a heater (112) and a plurality of fans (115); a humidity absorber (111); an outlet (102); a vacuum pump (103); characterized by the detector means having a plurality of sensors (121) in each of a plurality of clusters (120), wherein the plurality of sensors (121) in each of the plurality of clusters (120) comprises identical sensors capable of responding to a particular gas or vapor. The present invention also relates to a method for detecting a gas or a vapor from the artificial olfactory system (100), comprising the step of exposing the gas or vapor to the plurality of sensors (121) to produce a plurality of output signals from the plurality of sensors (121); transferring the plurality of output signals to the data acquisition system (104); extracting median data from the plurality of output signals; applying a principal component analysis (PCA), neural network, and least square regression analysis on the median data from all of the plurality of clusters (120).',\n",
       " 'An artificial retina cell effectively used to recognize a plurality of objects from an image containing them with ease and at high speed. Also disclosed are an artificial retina and an artificial visual apparatus employing the same. The artificial visual apparatus includes an artificial eyeball (3) having a focusing means (2) and an artificial retina (1) including a first artificial retina cell disposed in a central visual field (1a) to detect a bright-dark boundary by optical filtering and a second artificial retina cell disposed in a peripheral visual field (1b) to detect an object position by optical filtering, and a neural network (4) for executing pattern recognition of an object on the basis of information detected by the first artificial retina cell. The apparatus further includes a means for determining an object to be recognized subsequently from information detected by the second artificial retina cell of the artificial retina (1), and a means (5) for moving the artificial eyeball (3) toward the object to be recognized. Thus, a specific object in an image containing a plurality of objects of recognition is selectively recognized with ease and at high speed.',\n",
       " 'Aspects of the disclosure generally relate to computing devices and/or systems, and may be generally directed to devices, systems, methods, and/or applications for learning operation of an application or an object of an application in various visual surroundings, storing this knowledge in a knowledgebase (i.e. neural network, graph, sequences, etc.), and enabling autonomous operation of the application or the object of the application.',\n",
       " 'A system for allocating hall calls in a group of elevators includes a plurality of neural network modules to model, learn and predict passenger arrival rates and passenger destination probabilities. The models learn the traffic occurring in a building by inputting to the neural networks traffic data previously stored. The neural networks then adjust their internal structure to make historic predictions based on data of the previous day and real time predictions based on data of the last ten minutes. The predictions of arrival rates are combined to provide optimum predictions. From every set of historic car calls and the optimum arrival rates, a matrix is constructed which stores entries representing the number of passengers with the same intended destination for each hall call. The traffic predictions are used separately or in combination by a group control to improve operating cost computations and car allocation, thereby reducing the travelling and waiting times of current and future passengers.',\n",
       " 'Transponders capable of providing identification information and possibly additional information are detected from wireless access points of a computer network as a substitute for closed radio frequency identification (RFID) systems while providing numerous additional functionalities and applications. Total asset visibility or responses to more limited queries are provided by inclusion of a geographic information system software application. Location reporting of proximity of devices/transponders to access points can be enhanced to a fine-grained level by triangulation or other algorithms including neural networks.',\n",
       " '\" An associative memory that finds the location of at least one string of characters in the associative memory that matches a string of characters presented sequentially as an input to the associative memory. The string of characters in the associative memory, the input string of characters, or both may include a specially marked characters, or set of characters, that acts as a \"\"variable indicator.\"\" The specially marked character, or set of characters, will \"\"match\"\" a portion of the other string. A flag is set in the associative memory at either the starting locations or the ending locations of the matching strings. Flags are provided only at locations of stored matching strings of characters found within a selected addressable area or areas. Each flag can be moved from a first byte to a second byte in the associative memory that has a predetermined location relative to the first byte. A selection circuit selects one of the matching stored strings of characters by enabling a test signal which selects one of the flags to propagate through the associative memory circuit in a daisy-chain manner. The daisy-chain path is segmented in order to decrease the propagation time of the test signal. A summation circuit, useful in neural network applications, adds a number presented as at least one input byte to the associative memory to a number stored as at least one byte in the associative memory at the location of a stored string of characters that matches the input string. \"',\n",
       " 'An associative artificial neuron and method of forming output signals of an associative artificial neuron includes receiving a number of auxiliary input signals; forming from the auxiliary input signals a sum weighted by coefficients and applying a non-linear function to the weighted sum to generate a non-linear signal. The neuron and method further include receiving a main input signal and forming, based on the main signal and the non-linear signal, the function S OR V, which is used to generate a main output signal, and at lest one of three logical functions S AND V, NOT S AND V, and S AND NOT V. The at least one logical function is used to generate an additional output signal for the associative artificial neuron.',\n",
       " 'An associative pattern conversion system is disclosed which may be used for image recognition. The system includes an image input portion, an image processing portion and a recognition portion. The image processing portion includes a process unit for extracting characteristics and a frame memory for holding image data. The recognition portion, which includes a component for the learning of data to be associated, obtains the extracted characteristics from the image processing portion and performs associative pattern conversion from the image input portion. The system of the present invention may be applied to any neutral network, preferably a matrix calculation type neural network.',\n",
       " 'An associative pattern conversion system is disclosed which may be used for image recognition. The system includes an image input portion, an image processing portion and a recognition portion. The image processing portion includes a process unit for extracting characteristics and a frame memory for holding image data. The recognition portion, which includes a component for the learning of data to be associated, obtains the extracted characteristics from the image processing portion and performs associative pattern conversion from the image input portion. The system of the present invention may be applied to any neural network, preferably a matrix calculation type neural network.',\n",
       " 'An asynchronous control system for a neuro computer, includes an inter-connected type neural network composed of a plurality of neurons for multiplying a plurality of input signals with corresponding weights, calculating a total sum-of-products of the input signals and weight, thereby providing the sum-of product signals, and converting the sum-of-product signal using a non-linear function. A weight memory is provided for storing data of the weights for said neurons, and a controller is provided for generating a control pattern which controls the neural network. A selector randomly selects one of the neurons which performs signal processing during one processing cycle.',\n",
       " \"A method for testing an audio device with a trained neural network includes a loopback connector connecting the output port of the audio device to the input port of the audio device. A test signal is transmitted through the audio port and received at the input port. The test signal is converted into a frequency spectrum for analysis. The frequency spectrum is provided as input to a trained neural network, the neural network being previously trained to recognize the frequency spectrum pattern created by a properly working, or ideal, audio device. The neural network is trained by connecting the input port to the output port of an audio device from which the training is to occur. Prior to converting signals to a frequency spectrum, the waveform characteristics of the signal may be iteratively evaluated and recording levels adjusted so that the signal received has characteristics that can be tested by the neural network. The analyzed signal may be a portion of the signal received after analog to digital converters in the audio device have stabilized. The neural network generates a confidence level based on comparing the pattern of the tested audio device's frequency spectrum to the frequency spectrum of a working audio device. A pass value may be predetermined so that the tested audio device is reported as passing or failing the test by comparing the confidence level value generated by the system with the predetermined pass value.\",\n",
       " 'The invention relates to an automated system for monitoring wildlife auditory data and recording same for subsequent analysis and identification. The system comprises one or more microphones coupled to a recording apparatus for recording wildlife vocalizations in digital format. The resultant recorded data is preprocessed, segmented, and analyzed by means of a neural network to identify the respective species. The system minimizes the need for human intervention and subjective interpretation of the recorded sounds.',\n",
       " 'Aspects described herein are directed towards methods, computing devices, systems, and computer-readable media that apply scattering operations to extracted visual features of audiovisual input to generate predictions regarding the speech status of a subject. Visual scattering coefficients generated according to one or more aspects described herein may be used as input to a neural network operative to generate the predictions regarding the speech status of the subject. Predictions generated based on the visual features may be combined with predictions based on audio input associated with the visual features. In some embodiments, the extracted visual features may be combined with the audio input to generate a combined feature vector for use in generating predictions.',\n",
       " 'A method of audio source segregation includes selecting an audio attribute of an audio signal. The method also includes representing a portion of the audio attribute that is dominated by a single source as a source spiking event. In addition, the method includes representing a remaining portion of the audio signal as an audio signal spiking event. The method further includes determining whether the remaining portion coincides with the single source based on coincidence of the source spiking event and audio signal spiking event.',\n",
       " 'By way of example, the technology disclosed by this document receives image data; extracts a depth image and a color image from the image data; creates a mask image by segmenting the depth image; determines a first likelihood score from the depth image and the mask image using a layered classifier; determines a second likelihood score from the color image and the mask image using a deep convolutional neural network; and determines a class of at least a portion of the image data based on the first likelihood score and the second likelihood score. Further, the technology can pre-filter the mask image using the layered classifier and then use the pre-filtered mask image and the color image to calculate a second likelihood score using the deep convolutional neural network to speed up processing.',\n",
       " 'A method for the detection and treatment of disordered breathing during sleep employs an artificial neural network (ANN) in which data related to breathing gas flow are analyzed. A respiratory circuit is established by connecting the patient to a continuous positive airway pressure (CPAP) system with pressurized breathing gas supply, the gas flow in the circuit is periodically sampled, one or several cepstrum parameters distinctive of various breathing patterns are periodically calculated; the parameter values are periodically fed to an ANN trained to recognize breathing patterns characteristic of sleep disordered breathing and are analyzed in the network, the CPAP pressurized breathing gas supply is controlled in response to the ANN output. Also disclosed is a corresponding apparatus.',\n",
       " 'An auto-focusing device for a camera according to the present invention comprises many different systems. Included is a focus detection section which intermittently calculates focus detection information corresponding to the distance to the photographic subject. Also included is a photographic subject position prediction section which predicts a future position of the photographic subject based on the focus detection information. Finally, a lens driving section then drives a photographic lens based on a predicted result of the photographic subject position predicting section. The photographic subject position predicting section includes a neural network that predicts the future position of the photographic subject with an input parameter that has values regarding focusing positions of the photographic lens. These values correspond to focus detection data calculated by the focus detection section. The neural network makes it possible to predict the future focusing position of the photographic lens accurately.',\n",
       " 'An efficient neural network computing technique capable of synthesizing two sets of output signal data from a single input signal data set. The method and device of the invention involves a unique integration of autoassociative and heteroassociative neural network mappings, the autoassociative neural network mapping enabling a quality metric for assessing the generalization or prediction accuracy of the heteroassociative neural network mapping.',\n",
       " 'A system for obtaining optimum performance and optimum graceful degradation from Lie algebra descriptions of a spectrum of reconfigurable network architectures, including, neural nets and cellular automata comprised of interconnected nodes. The dynamic performance of the computational process is monitored by continued extraction of Liapounov exponent indicators, reconfiguring said reconfigurable network architecture when said indicators predict non-optimum performance. The reconfigurable networks are reconfigured and compensatory adjustments are made of signal sampling performance and operating system performance of said reconfigurable network architecture, and the operating system architecture is optimized to the computational task by reconfiguration of nodal capabilities and degree of interconnectedness between nodes to obtain any Lie algebra description architectural form between ideal neural net with maximum interconnectedness and ideal cellular automata with maximum nodal capability.',\n",
       " 'An automated method for analyzing a nodule and a computer storage medium storing computer instructions by which the method can be implemented when the instructions are loaded into a computer to program the computer. The method includes obtaining a digital image including the nodule; segmenting the nodule to obtain an outline of the nodule, including generating a difference image from chest image, identifying image intensity contour lines representative of respective image intensities in a region of interest including the nodule, and obtaining an outline of the nodule based on the image intensity contours; extracting features of the nodule based on the outline; applying features including the extracted features to at least one image classifier; and determining a likelihood of malignancy of the nodule based on the output of the at least one classifier. In one embodiment, extracted features are applied to a linear discriminant analyzer and/or an artificial neural network analyzer, the outputs of which are thresholded and the nodule determined to be non-malignant if each classifier output is below the threshold. In another embodiment, a common nodule appearing in an x-ray chest image and a CT image is segmented in each image, features extracted based on the outlines of each segmented nodule in the respective x-ray chest and CT images, and the extracted features from the x-ray chest image and CT images merged as inputs to a common classifier, with the output of the common classifier indicating the likelihood of malignancy.',\n",
       " 'An automated screening system and method for cytological specimen classification in which a neural network is utilized in performance of the classification function. Also included is an automated microscope and associated image processing circuitry.',\n",
       " 'An automated screening system and method for cytological specimen classification in which a neural network is utilized in performance of the classification function. Also included is an automated microscope and associated image processing circuitry.',\n",
       " 'Embodiments of the present invention provide digital watermarking methods that embed a digital watermark in both the low and high frequencies of an image or other production, providing a digital watermark that is resistant to a variety of attacks. The digital watermarking methods of the present invention optimize the strength of the embedded digital watermark such that it is as powerful as possible without being perceptible to the human eye. The digital watermarking methods of the present invention do this relatively quickly, in real-time, and in an automated fashion using an intelligent system, such as a neural network. The digital watermarking methods of the present invention may also be used in a variety of new applications, such as the digital watermarking of sensitive aircraft parts and military equipment.',\n",
       " \"A method for legal knowledge modeling and automated legal evaluation, such as for online, questionnaire-based legal analysis, is provided. Information, such as facts and characteristics of a legal situation, as it relates to a legal conclusion, are modeled in an artificial neural network. The artificial neural network may comprise a plurality of nodes, wherein each node is associated with one or more weights and a function that calculates a legal conclusion based on one or more input values and the weights. The artificial neural network is automatically updated on a periodic basis to reflect new legislation or court decisions. Using the artificial neural network, a legal conclusion based on the user's answers to a questionnaire may be determined. The legal conclusion is modified upon the input of evidence, which is in the form of answers to a set of questions designed to identify a legal conclusion.\",\n",
       " 'An automated method and system for digital imaging processing of radiologic images, wherein digital image data is acquired and subjected to multiple phases of digital imaging processing. During the Pre-Processing stage, simultaneous box-rim filtering and k-nearest neighbor processing and subsequent global thresholding are performed on the image data to enhance object-to-background contrast, merge subclusters and determine gray scale thresholds for further processing. Next, during the Preliminary Selection phase, body part segmentation, morphological erosion processing, connected component analysis and image block segmentation occurs to subtract unwanted image data preliminarily identify potentials areas including abnormalities. During the Pattern Classification phase, feature patterns are developed for each area of interest, a supervised, back propagation neural network is trained, a feed forward neural network is developed and employed to detect true and several false positive categories, and two types of pruned neural networks are utilized in connection with a heuristic decision tree to finally determine whether the regions of interest are abnormalities or false positives.',\n",
       " '\" An automated method for identifying those claims of a raw claims insurance claims database for which reinsurance is applicable. The method develops a database of uniquely clustered catastrophic events such as storm reports. This \"\"CatNodes\"\" database may be developed manually or automatically through the use of a neural network approach. A fuzzy degree of belonging is employed to quantify the likelihood that a given insurance claim is properly associated with a given catastrophic event or storm. The assignment of a degree of belonging is derived by approaches which consider four factors: the date of the loss; the location of the loss; the type of the loss; and the presence of special keywords in the claim description. \"',\n",
       " 'A method for spectral signature interpretation. The method includes the creation of a mathematical model of a system or process. A neural network training set is then developed based upon the mathematical model. The neural network training set is developed by using the mathematical model to generate measurable phenomena of the system or process based upon model input parameter that correspond to the physical condition of the system or process. The neural network training set is then used to adjust internal parameters of a neural network. The physical condition of an actual system or process represented by the mathematical model is then monitored by extracting spectral features from measured spectra of the actual process or system. The spectral features are then input into said neural network to determine the physical condition of the system or process represented by the mathematical. More specifically, the neural network correlates the spectral features (i.e. measurable phenomena) of the actual process or system with the corresponding model input parameters. The model input parameters relate to specific components of the system or process, and, consequently, correspond to the physical condition of the process or system.',\n",
       " 'A method and apparatus is described for recognition of hand printed characters using maximum uncertainty--minimum variance (MUMV) functions, such as Gabor functions, implemented by optical elements. A set of optical elements having varying optical density corresponding to a set of two-dimensional MUMV functions is generated. A pattern of illumination responsive to the image of the character to be identified is simultaneously transmitted through each of the optical elements implementing the MUMV functions. The amount of light transmitted through each of the elements is measured, providing a transmission coefficient. Such transmission coefficients are used as a set of inputs to a neural network, such that the inputs to the neural network are a set of transmission coefficients resulting from transmission of light corresponding to a character to be identified through a complete set of optical elements implementing a set of two-dimensional MUMV functions. The neural network calculates weighted sums of the transmission coefficients. The neural network may be implemented as a network of resistors connected between input nodes, intermediate nodes, and output nodes. The output node having the highest voltage identifies the character to be identified.',\n",
       " 'A method and apparatus is described for recognition of hand printed characters using pairs of positive and negative correlative functions (PNCFs), the PNCFs including both pattern and relevance information, implemented by optical elements. A set of optical elements having varying optical density corresponding to a set of two-dimensional PNCFs is generated. A pattern of illumination responsive to the image of the character to be identified is simultaneously transmitted through each of the optical elements implementing the PNCFs. The amount of light transmitted through each of the elements is measured, providing a transmission coefficient. The transmission coefficients are the inputs to a neural network, such that the inputs to the neural network are a set of transmission coefficients resulting from transmission of light corresponding to a character to be identified through a complete set of optical elements implementing a set of PNCFs. The neural network calculates weighted sums of the transmission coefficients. The neural network may be implemented as a network of resistors connected between input nodes, intermediate nodes, and output nodes. The output node having the highest voltage identifies the character to be identified.',\n",
       " 'A system substitutes digitized camera images for human vision, in determining the presence or absence of rip tides among sea water wave patterns at a public swimming beach. Computer analysis of these images involves image pre-filtering that enhances the telltale signs of rip tides, before the digital data is processed for classification as NORMAL or RIP TIDE. The classification itself can proceed along by expert systems which mimic the manner in which a human observer performs the detection; or by building a neural network, that determines its own classification criteria for identifying rip tides.',\n",
       " 'Methods and apparatus for monitoring an arc welding process are disclosed. In a preferred embodiment, the present invention creates a digital representation of the arc created during welding and, using a neural network computer, determines if the arc is representative of normal or abnormal welding conditions. The neural network disclosed is trained to identify abnormal conditions and normal conditions and may be adaptively retrained to classify images that are not in the initial set of normal and abnormal images. In certain embodiments, other data, such as current, weld wire emission spectra, or shielding gas flow rate are also collected and the neural network is trained to monitor these data. Also, in certain embodiments, an audio signal is collected from the vicinity of the welding process and is used by the neural network computer to further classify the arc as normal or abnormal. The present invention is most preferably implemented in repetitive and continuous welding operations, such as those encountered in the manufacture and rebuilding of steam turbines.',\n",
       " 'A method and an apparatus for utilizing a central neural network and a central data bank to perform automatic interpretation of the visual function test parameters obtained in a plurality of visual field testing systems, for a plurality of patients, with control and response signals being transmitted via the Internet. The data produced by the testing systems are automatically analyzed and compared with patterns on which the neural network was previously trained, and clinical diagnoses for pathological conditions are thereby suggested to the respective clinician for each patient.',\n",
       " 'An automatic brake control system brakes a driving vehicle according to a target brake control amount calculated by a neural network. The system detects vehicle speed of the driving vehicle, and detects the actual distance between the driving vehicle and a vehicle ahead of the driving vehicle. The system calculates a reference distance defined as a physically preferred distance between the driving vehicle and the vehicle ahead of the driving vehicle according to the vehicle speed, and normalizes the actual distance with the reference distance in order to obtain a normalized distance in a dimensionless quantity. The neural network calculates target brake control amount according to the vehicle speed and the normalized distance, and the automatic brake control system brakes the driving vehicle according to the target brake control amount.',\n",
       " 'In a focus detection device for a camera, a plurality of distance sensors each for detecting a distance to an object in a plurality of areas of a photographing image plane are provided and distance data obtained by the distance sensors for each object in each area is supplied to a main object detection circuit and a normalizing circuit. The normalizing circuit normalizes the distance data into a real number ranging from 0 to 1 and then supplies the same to a neural network. The neural network formed of a single-layered neuron units of which the synapse connection weighting factors are previously obtained by the learning process, calculates a vector difference between the distance data and the synapse connection weighting factors of each neuron unit, detects the minimum vector difference, and outputs position data of a main object corresponding to a neuron unit which gives the minimum vector difference. The position data of the main object is input to a main object detection circuit. One of the outputs from the distance sensors corresponding to the main object is selected by the main object detection circuit and is supplied to a focus detection circuit for effecting the calculation to detect the focus. An output of the focus detection circuit is supplied to a lens driving mechanism so as to adjust the focus.',\n",
       " 'A cooking appliance controls a cooking device on the basis of temperature information of an object to be cooked that is estimated from changes in physical characteristics. A neural network is taught, for a number of categories of food that are classified according to the temperature of the cooked and completed food, the relationship between changes in the physical characteristic, such as the temperature and humidity, generated during heating of the object to be cooked during cooking, and changes of temperature of the object at the center of the object and the surface of the object in order to provide for an automatic cooking operation.',\n",
       " \"A method for automatic generation of a Neuro-Fuzzy Expert System (Fuzzy Logic Expert System implemented as a Neural Network) from data. The method comprising a Data Interface allowing description of location, type, and structure of the Data. The Interface also allows designation of input attributes and output attributes in the Data Structure; automatic Neuro-Fuzzy Expert System generation driven by the Data; Training of the Expert System's Neural Network on the Data and the presentation of results which include new knowledge embedded in the parameters and structure of the trained Neuro-Fuzzy Expert System to a user.\",\n",
       " \"A &#8220;Rapid Learner Client Service&#8221; (RLCS) system that allows a large number of end-users to obtain the benefits of a sophisticated neural-network forecasting system. Rather than purchasing or developing a forecasting system of their own, RLCS clients subscribe to a forecasting service performed by forecasting equipment located at a remote site. This allows a single highly sophisticated forecasting system to meet the forecasting needs of a large number of subscribers. This forecasting service is performed by an RLCS server that periodically and automatically accesses the subscriber's computer to obtain a fresh set of input data. Alternatively, the subscriber's computer may contact the RLCS server to initiate the process. This input data is then downloaded to the RLCS server, where it is checked and corrected for errors by imputing values for missing or deviant input values. The error-corrected input data is then used to compute a forecast of output values, which are downloaded to the client's computer. The RLCS server also computes and downloads a set accuracy statistics for the client's review.\",\n",
       " 'One example apparatus associated with detecting mitosis in breast cancer pathology images by combining handcrafted (HC) and convolutional neural network (CNN) features in a cascaded architecture includes a set of logics that acquires an image of a region of tissue, partitions the image into candidate patches, generates a first probability that the patch is mitotic using an HC feature set and a second probability that the patch is mitotic using a CNN-learned feature set, and classifies the patch based on the first probability and the second probability. If the first and second probabilities do not agree, the apparatus trains a cascaded classifier on the CNN-learned feature set and the HC feature set, generates a third probability that the patch is mitotic, and classifies the patch based on a weighted average of the first probability, the second probability, and the third probability.',\n",
       " 'An automatic document classification system is described that uses lexical and physical features to assign a class ciεC{c1, c2, . . . , ci} to a document d. The primary lexical features are the result of a feature selection method known as Orthogonal Centroid Feature Selection (OCFS). Additional information may be gathered on character type frequencies (digits, letters, and symbols) within d. Physical information is assembled through image analysis to yield physical attributes such as document dimensionality, text alignment, and color distribution. The resulting lexical and physical information is combined into an input vector X and is used to train a supervised neural network to perform the classification.',\n",
       " 'Automatic energy management is provided, in even the most complex multi-building system. The necessity of a human operator for managing energy in a complex, multi-building system is reduced and even eliminated. Computer-based monitoring and computer-based recognition of adverse energy events (such as the approach of a new energy peak) is highly advantageous in energy management. Immediate automatic querying of energy users within a system of buildings for energy curtailment possibilities is provided. Such immediate, automatic querying may be answered by the energy users through artificial intelligence and/or neural network technology provided to or programmed into the energy users, and the queried energy users may respond in real-time. Those real-time computerized responses with energy curtailment possibilities may be received automatically by a data processing facility, and processed in real-time. Advantageously, the responses from queried energy users with energy curtailment possibilities may be automatically processed into a round-robin curtailment rotation which may be implemented by a computer-based control system. Thus, impact on occupants is minimized, and energy use and energy cost may be beneficially reduced in an intelligent, real-time manner. The invention also provides for early-recognition of impending adverse energy events, optimal response to a particular energy situation, real-time analysis of energy-related data, etc.',\n",
       " \"In an automatic external defibrillator (AED) having a ventricular fibrillation detector, the ventricular fibrillation detector may generally be defined as a filter containing both an adaptive non-linear section and a linear section. The non-linear section is preferably a complex-domain neural network that can be trained to differentiate between various rhythm patterns and produce linear data for input to the linear section. The linear section is preferably an ongoing, continuous operation based on a sliding window of a predetermined time period, e.g., a tapped time-delay filter. In combination the non-linear section and linear section of the filter operate to detect and extract artifacts from a patient's ECG signal in a substantially accurate fashion so that the determination to deliver a defibrillation pulse may be accurately made.\",\n",
       " 'A method of automatically extracting metadata from a document. The method of the invention provides a computer readable document that includes blocks comprised of words, an authority list that includes common uses of a set of words, and a neural network trained to extract metadata from groupings of data called compounds. Compounds are created with one compound describing each of the blocks. Each compound includes the words making up the block, descriptive information about the blocks, and authority information associated with some of the words. The descriptive information may include such items as bounding box information, describing the size and position of the block, and font information, describing the size and type of font the words of the block use. The authority information is located by comparing each the words from the block to the authority list. The compounds are processed through the neural network to generate metadata guesses including word guesses, compound guesses and document guesses along with confidence factors associated with the guesses indicating the likelihood that each of the guesses is correct. The method may additionally include providing a document knowledge base of positioning information and size information for metadata in known documents. If the document knowledge base is provided, then the method includes deriving analysis data from the metadata guess and comparing the analysis data to the document knowledge base to determine metadata output.',\n",
       " 'Design of a neural network for automatic detection of incidents on a freeway is described. A neural network is trained using a combination of both back-propagation and genetic algorithm-based methods for optimizing the design of the neural network. The back-propagation and genetic algorithm work together in a collaborative manner in the neural network design. The training starts with incremental learning based on the instantaneous error and the global total error is accumulated for batch updating at the end of the training data being presented to the neural network. The genetic algorithm directly evaluates the performance of multiple sets of neural networks in parallel and then use the analyzed results to breed new neural networks that tend to be better suited to the problems at hand.',\n",
       " 'An apparatus and method for automatically generating radiation treatment planning parameters are disclosed. In accordance with the illustrative embodiment, a database is constructed that stores: (i) patient data and past treatment plans by expert human planners for these patients, and (ii) optimal treatment plans that are generated using multi-objective optimization and Pareto front search and that represent the best tradeoff opportunities of the patient case, and a predictive model (e.g., a neural network, a decision tree, a support vector machine [SVM], etc.) is then trained via a learning algorithm on a plurality of input/output mappings derived from the contents of the database. During training, the predictive model is trained to identify and infer patterns in the treatment plan data through a process of generalization. Once trained, the predictive model can then be used to automatically generate radiation treatment planning parameters for new patients.',\n",
       " 'An analysis system automatically analyzes and counts fluorescence signals present in biopsy tissue marked using Fluorescence in situ Hybridization (FISH). The user of the system specifies classes of a class network and process steps of a process hierarchy. Then pixel values in image slices of biopsy tissue are acquired in three dimensions. A computer-implemented network structure is generated by linking pixel values to objects of a data network according to the class network and process hierarchy. Objects associated with pixel values at different depths of the biopsy tissue are used to determine the number, volume and distance between cell components. In one application, fluorescence signals that mark Her2/neural genes and centromeres of chromosome seventeen are counted to diagnose breast cancer. Her2/neural genes that overlap one another or that are covered by centromeres can be accurately counted. Signal artifacts that do not mark genes can be identified by their excessive volume.',\n",
       " 'An analysis system automatically analyzes and counts fluorescence signals present in biopsy tissue marked using Fluorescence in situ Hybridization (FISH). The user of the system specifies classes of a class network and process steps of a process hierarchy. Then pixel values in image slices of biopsy tissue are acquired in three dimensions. A computer-implemented network structure is generated by linking pixel values to objects of a data network according to the class network and process hierarchy. Objects associated with pixel values at different depths of the biopsy tissue are used to determine the number, volume and distance between cell components. In one application, fluorescence signals that mark Her2/neural genes and centromeres of chromosome seventeen are counted to diagnose breast cancer. Her2/neural genes that overlap one another or that are covered by centromeres can be accurately counted. Signal artifacts that do not mark genes can be identified by their excessive volume.',\n",
       " 'An analysis system automatically analyzes and counts fluorescence signals present in biopsy tissue marked using Fluorescence in situ Hybridization (FISH). The user of the system specifies classes of a class network and process steps of a process hierarchy. Then pixel values in image slices of biopsy tissue are acquired in three dimensions. A computer-implemented network structure is generated by linking pixel values to objects of a data network according to the class network and process hierarchy. Objects associated with pixel values at different depths of the biopsy tissue are used to determine the number, volume and distance between cell components. In one application, fluorescence signals that mark Her2/neural genes and centromeres of chromosome seventeen are counted to diagnose breast cancer. Her2/neural genes that overlap one another or that are covered by centromeres can be accurately counted. Signal artifacts that do not mark genes can be identified by their excessive volume.',\n",
       " 'This invention consists of three enhancements to HMM-based automatic language identification systems. The three enhancements are: (i) language-discriminant acoustic model training and recognition, (ii) an acoustic model pruning procedure that picks only those phonetic models which are considered useful for language identification, and (iii) a neural network-based language classification method that uses knowledge-based features derived from phone sequences output by the HMM phonetic recognizers.',\n",
       " 'A language identification and verification system is described whereby language identification is determined by finding the closest match of a speech utterance to multiple speaker sets. The language identification and verification system is implemented through use of a speaker identification/verification system as a baseline to find a set of well matched speakers in each of a plurality of languages. A comparison of unknown speech to speech features from such well-matched speakers is then made and a language decision is arrived on based on a closest match between the unknown speech features and speech features for such well matched reference speakers in a particular language. To avoid a problem associated with prior-art language identification systems, wherein speech feature are based on short-term spectral features determined at a system frame rate--thereby seriously limiting the resolution and accuracy of such prior-art systems, the invention uses speech features derived from vocalic or syllabic nuclei, from which related phonetic speech features may then be extracted. Detection of such vocalic centers or syllabic nuclei is accomplished using a trained back-error propagation multi-level neural network.',\n",
       " 'Provided content is determined to contain an asset represented by reference content by comparing digital fingerprints of the provided content and the reference content. The fingerprints of the reference content and the provided content are generated using a convolutional neural network (CNN). The CNN is trained using a plurality of frame triplets including an anchor frame representing the reference content, a positive frame which is a transformation of the anchor frame, and a negative frame representing content that is not the reference content. The provided content is determined to contain the asset represented by the reference content based on a similarity measure between the generated fingerprints. If the provided content is determined to contain the asset represented by the reference content, a policy associated with the asset is enforced on the provided content.',\n",
       " 'An automatic load measuring device includes an actual load calculating device. The actual load calculating device includes a multi-layer feed-forward type neural network having an input layer, an intermediate layer and an output layer arranged in a hierarchial manner. Also, the actual load calculating device, by use of the multi-layer feed-forward type neural network, can previously execute learning relating to the correction of a carrying load of a vehicle to be measured by automatic load measuring sensors respectively used to measure the carrying loads of the vehicle using measured load information measured by the automatic load measuring sensors, and, based on the result of the learning, can correct the carrying loads measured by the automatic load measuring sensors so as to find the actual load of the vehicle.',\n",
       " 'Method of incrementally forming and adaptively updating a neural net model are provided. A function approximation node is incrementally added to the neural net model. Function parameters for the function approximation node are determined and function parameters of other nodes in the neural network model are updated, by using the function parameters of the other nodes prior to addition of the function approximation node to the neural network model.',\n",
       " \"A set of payment card transactions including a sparse set of fraudulent transactions is normalized, such that continuously valued literals in each of the set of transactions are transformed to discrete literals. The normalized transactions are used to train a classifier, such as a neural network, such that the classifier is trained to classify transactions as fraudulent or genuine. The fraudulent transactions in the set of payment card transactions are clustered to form a set of prototype transactions. Each of the discrete literals in each of the prototype transactions is expanded using sensitivity analysis using the trained classifier as an oracle, and a rule for identifying fraudulent transactions is generated for each prototype transaction based on the transaction's respective expanded literals.\",\n",
       " 'An automated sales promotion selection system uses neural networks to identify promising sales promotions based on recent customer purchases. The system includes a customer information device that receives customer data relating to customer purchases of items from an inventory of items, a central processing unit having a sales promotion neural network and a storage unit containing a plurality of item identifiers comprising potential customer purchases of additional items from the inventory, wherein the sales opportunity neural network responds to customer data received from the customer information device by determining if one or more of the item identifiers in the storage unit corresponds to an item likely to be purchased by one of the customers, and an output device that receives the item identifiers of the likely purchases determined by the sales promotion neural network and produces a sales promotion relating to at least one of the item identifiers.',\n",
       " 'An automated sales promotion selection system uses neural networks to identify promising sales promotions based on recent customer purchases. The system includes a customer information device that receives customer data relating to customer purchases of items from an inventory of items, a central processing unit having a sales promotion neural network and a storage unit containing a plurality of item identifiers comprising potential customer purchases of additional items from the inventory, wherein the sales opportunity neural network responds to customer data received from the customer information device by determining if one or more of the item identifiers in the storage unit corresponds to an item likely to be purchased by one of the customers, and an output device that receives the item identifiers of the likely purchases determined by the sales promotion neural network and produces a sales promotion relating to at least one of the item identifiers.',\n",
       " 'An automated sales promotion selection system uses neural networks to identify promising sales promotions based on recent customer purchases. The system includes a customer information device that receives customer data relating to customer purchases of items from an inventory of items, a central processing unit having a sales promotion neural network and a storage unit containing a plurality of item identifiers comprising potential customer purchases of additional items from the inventory, wherein the sales opportunity neural network responds to customer data received from the customer information device by determining if one or more of the item identifiers in the storage unit corresponds to an item likely to be purchased by one of the customers, and an output device that receives the item identifiers of the likely purchases determined by the sales promotion neural network and produces a sales promotion relating to at least one of the item identifiers.',\n",
       " 'An automatic seismic pattern recognition method includes the steps of: determining a given number of seismic patterns to be recognized; providing a set of seismic trace portions for the region; defining a pattern recognition parameter common to all the trace portions, and determining the value of the parameters for each of the traces portions of the set. The method also includes the steps of: selecting trace portions of the set; selecting a one-dimensional neural network containing as many cells as there are patterns to be recognized where each cell is assigned a value of the recognition parameter; and submitting the neural network to a learning process with the selected trace portions so that at the end of the process each cell matches a pattern to be recognized and so that the patterns are progressively ordered. The method also includes the steps of: presenting each trace portion of the set to be processed to the classified and ordered neural network and attributing to each trace portion presented to the network the number of the cell closest to it.',\n",
       " 'A scheme for recognizing speech represented by a sequence of frames of acoustic events separated by boundaries, according to which the frames of speech are processed to assign to received frames respective boundary probabilities representative of the degree to which the frames of speech correspond to stored representations of boundaries between acoustic events. The assigned boundary probabilities are used in subsequent processing steps to enhance recognition of speech. The assignment of boundary probabilities and further adjustments of the assigned probabilities are preferably conducted by an artificial neural network (ANN).',\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for automatic speech recognition using multi-dimensional models. In some implementations, audio data that describes an utterance is received. A transcription for the utterance is determined using an acoustic model that includes a neural network having first memory blocks for time information and second memory blocks for frequency information. The transcription for the utterance is provided as output of an automated speech recognizer.',\n",
       " 'A method and apparatus for real-time target recognition within a multispectral image includes generating radiance signatures from reflectance signatures, sensor information and environment information and detecting targets in the multispectral image with a sparsity-driven target recognition algorithm utilizing set of parameters tuned with a deep neural network.',\n",
       " 'An automatic train operation apparatus capable of realizing an optimal train operation with an improved reliability. The apparatus includes: an ATO/C system including a plurality of ATO/C units redundantly provided, each ATO/C unit having a fail safe configuration formed by a plurality of execution processors and a supervisor processor for monitoring normal operations of the execution processors, each execution processor being capable of executing an automatic train operation program, and all of the execution processors in the plurality of ATO/C units executing an identical automatic train operation program simultaneously; and a majority logic circuit for selecting an output obtained by a majority of the execution processors in the ATO/C units of the ATO/C system as a control command output for controlling a train operation. Each execution processor in the ATO/C system operates as a neural network with a learning function.',\n",
       " 'A method for determining when in the course of a shift event an on-coming clutch gains torque capacity is provided. The method includes closed-loop controlling an off-going clutch to maintain a predetermined slip threshold by generating an off-going clutch pressure command, causing the on-coming clutch to engage during the closed loop control of the off-going clutch, generating a first derivative with respect to time of the off-going clutch pressure command, and using the first derivative to determine when the on-coming clutch gained torque capacity. A neural network method is preferably employed in analyzing the first derivative to locate a transition in the rate of commanded pressure indicative of off-going clutch release. A corresponding apparatus is also provided.',\n",
       " 'Automatic white balancing and/or autoexposure as useful in a digital camera extracts color channel gains from comparisons of image colors with reference colors under various color temperature illuminants and/or extracts exposure settings from illuminance mean, illuminance variance, illuminance minimum, and illuminance maximum in areas of an image with a trained neural network.',\n",
       " 'Automatic white balancing and/or autoexposure as useful in a digital camera extracts color channel gains from comparisons of image colors with reference colors under various color temperature illuminants and/or extracts exposure settings from illuminance mean, illuminance variance, illuminance minimum, and illuminance maximum in areas of an image with a trained neural network.',\n",
       " 'Training data for training a neural network usable for electronic sentiment analysis can be automatically constructed. For example, an electronic communication usable for training the neural network and including multiple characters can be received. A sentiment dictionary including multiple expressions mapped to multiple sentiment values representing different sentiments can be received. Each expression in the sentiment dictionary can be mapped to a corresponding sentiment value. An overall sentiment for the electronic communication can be determined using the sentiment dictionary. Training data usable for training the neural network can be automatically constructed based on the overall sentiment of the electronic communication. The neural network can be trained using the training data. A second electronic communication including an unknown sentiment can be received. At least one sentiment associated with the second electronic communication can be determined using the neural network.',\n",
       " 'Systems and methods are disclosed that optimize the combustion process in various reactors, furnaces, and internal combustion engines. Video cameras are used to evaluate the combustion flame grade. Depending on the desired form, standard or special video devices, or beam scanning devices, are used to image the combustion flame and by-products. The video device generates and outputs image signals during various phases of, and at various locations in, the combustion process. Other forms of sensors monitor and generate data signals defining selected parameters of the combustion process, such as air flow, fuel flow, turbulence, exhaust and inlet valve openings, etc. In a preferred form, a neural networks initially processes the image data and characterizes the combustion flame. A fuzzy logic controller and associated fuzzy logic rule base analyzes the image data from the neural network, along with other sensor information. The fuzzy logic controller determines and generates control signals defining adjustments necessary to optimize the combustion process.',\n",
       " 'Systems and methods are disclosed that optimize the combustion process in various reactors, furnaces, and internal combustion engines. Video cameras are used to evaluate the combustion flame grade. Depending on the desired form, standard or special video devices, or beam scanning devices, are used to image the combustion flame and by-products. The video device generates and outputs image signals during various phases of, and at various locations in, the combustion process. Other forms of sensors monitor and generate data signals defining selected parameters of the combustion process, such as air flow, fuel flow, turbulence, exhaust and inlet valve openings, etc. In a preferred form, a neural networks initially processes the image data and characterizes the combustion flame. A fuzzy logic controller and associated fuzzy logic rule base analyzes the image data from the neural network, along with other sensor information. The fuzzy logic controller determines and generates control signals defining adjustments necessary to optimize the combustion process.',\n",
       " 'Systems and methods are disclosed that optimize the combustion process in various reactors, furnaces, and internal combustion engines. Video cameras are used to evaluate the combustion flame grade. Depending on the desired form, standard or special video devices, or beam scanning devices, are used to image the combustion flame and by-products. The video device generates and outputs image signals during various phases of, and at various locations in, the combustion process. Other forms of sensors monitor and generate data signals defining selected parameters of the combustion process, such as air flow, fuel flow, turbulence, exhaust and inlet valve openings, etc. In a preferred form, a neural networks initially processes the image data and characterizes the combustion flame. A fuzzy logic controller and associated fuzzy logic rule base analyzes the image data from the neural network, along with other sensor information. The fuzzy logic controller determines and generates control signals defining adjustments necessary to optimize the combustion process.',\n",
       " 'Systems and methods are disclosed that optimize the combustion process in various reactors, furnaces, and internal combustion engines. Video cameras are used to evaluate the combustion flame grade. Depending on the desired form, standard or special video devices, or beam scanning devices, are used to image the combustion flame and by-products. The video device generates and outputs image signals during various phases of, and at various locations in, the combustion process. Other forms of sensors monitor and generate data signals defining selected parameters of the combustion process, such as air flow, fuel flow, turbulence, exhaust and inlet valve openings, etc. In a preferred form, a neural networks initially processes the image data and characterizes the combustion flame. A fuzzy logic controller and associated fuzzy logic rule base analyzes the image data from the neural network, along with other sensor information. The fuzzy logic controller determines and generates control signals defining adjustments necessary to optimize the combustion process.',\n",
       " 'Network node modules within a vehicle are arranged to form a reconfigurable automotive neural network. Each network node module includes one or more subsystems for performing one or more operations and a local processing module for communicating with the one or more subsystems. A switch coupled between the one or more subsystems and the processing module re-routes traffic from the one or more subsystems to an external processing module upon failure of the local processing module.',\n",
       " 'Network node modules within a vehicle are arranged to form a reconfigurable automotive neural network. Each network node module includes one or more subsystems for performing one or more operations and a local processing module for communicating with the one or more subsystems. A management system enables traffic from the one or more subsystems of a particular network node module to be re-routed to an external processing module upon failure of the local processing module of that particular network node module.',\n",
       " 'Network node modules within a vehicle are arranged to form a reconfigurable automotive neural network. Each network node module includes one or more subsystems for performing one or more operations and a local processing module for communicating with the one or more subsystems. A management system enables traffic from the one or more subsystems of a particular network node module to be re-routed to an external processing module upon failure of the local processing module of that particular network node module.',\n",
       " 'An autonomic system for updating a fuzzy neural network includes a process of calculating an estimated value based on fuzzy inference by using a neural network structure, wherein a parameter to be adjusted or identified by fuzzy inference and outputted from the neural network is made to correspond to coupling loads which are updated by learning, i.e., fuzzy rules and membership functions are adjusted by learning. This system is characterized in that the addition and deletion of fuzzy rules are conducted based on changes in output errors in an autonomic manner, thereby effectively obtaining appropriate numbers of fuzzy rules optimal for an object such as a vehicle engine having strong non-linearity. Fuzzy rules are formed by a combination of membership functions representing variables such as an engine speed and a throttle angle.',\n",
       " 'A knowlege discovery system (10) is provided for autonomously discovering knowlege from a database. The system includes a data reduction module (50) which reduces data into one or more clusters. This is accomplished by the use of one or more functions including a genetic clustering function, a hierarchical valley formation function, a symbolic exspansion reduction function, a fuzzy case clustering function, a relational clustering function, a K-means clustering function, a Kohonen neural network clustering function, and a minimum distance classifier clustering function. A data analysis modual (60) autonomously determines one or more correlations among the clusters. The corrolations represent knowlege.',\n",
       " 'An autonomous navigation system for a mobile vehicle arranged to move within an environment includes a plurality of sensors arranged on the vehicle and at least one neural network including an input layer coupled to the sensors, a hidden layer coupled to the input layer, and an output layer coupled to the hidden layer. The neural network produces output signals representing respective positions of the vehicle, such as the X coordinate, the Y coordinate, and the angular orientation of the vehicle. A plurality of patch locations within the environment are used to train the neural networks to produce the correct outputs in response to the distances sensed.',\n",
       " \"The invention provides an unmanned, autonomous, undersea platform which ends the sphere of influence of a host vessel from which it is launched. The platform is hydrodynamically and stealth shaped to minimize noise, wake and detectability of the platform. The platform includes advanced active and passive sensors for monitoring the undersea environment, high data rate RF and satellite communications capabilities for communication with the host vessel when necessary, forward deployed offensive and defensive weapons systems and sophisticated data processing to coordinate the sensing, communications and weapons systems with minimal direction from the host vessel. Prior to launch, mission directives are input to the data processors. Using artificial intelligence and neural network programming for decision making, the processors constantly update the platform's operating parameters to conform with changing environmental and threat conditions and to successfully complete the mission.\",\n",
       " 'A feedback operated DC bridge circuit for monitoring the voltage variations in a voltage divider circuit using a voltage controlled resistance component to reach a null balance across the bridge. Amplification is provided at higher accuracy near the null point when the voltage difference across the bridge is zero. The feedback bridge circuit includes an integrator which directly drives the controlling component to the value of the resistance in an unknown branch to force the null condition. The voltage controlled component (configured as a discrete metal oxide semiconductor device or bipolar junction transistor) and the balancing scheme are suitable for microfabrication and provides noise-rejection enhancement. The interconnected integral feedback of the autonulling DC bridge enables both a neural network for pre-processing sensor input in a spatial domain as well as general analog computation that mimics a first order differential equation in the form of the system state equation.',\n",
       " 'Technical solutions are described for implementing a neural network. An example system includes a crosspoint array including a plurality of nodes, each node representing a weight assigned to a neuron of the neural network. The system also includes a capacitor associated with a set of nodes from the plurality of nodes, where the capacitor is configured to store a current value corresponding to a sum of outputs from each respective node from the set of nodes. The system also includes a clocking circuit that initiates a forward pass to propagate the current value stored in the capacitor to a subsequent layer of the neural network. The clocking circuit further initiates a backward pass to propagate the current value stored in the capacitor to a preceding layer of the neural network. The clocking circuit further initiates a weight-update pass to update the weights in the neural network.',\n",
       " 'A neural network system includes a feedforward network comprising at least one neuron circuit for producing an activation function and a first derivative of the activation function and a weight updating circuit for producing updated weights to the feedforward network. The system also includes an error back-propagation network for receiving the first derivative of the activation function and to provide weight change data information to the weight updating circuit.',\n",
       " 'Methods and systems for backlash compensation. Restrictive assumptions on the backlash nonlinearity (e.g. the same slopes of the lines, etc.) are not required. The compensator scheme has dynamic inversion structure, with a neural network in the feedforward path that approximates the backlash inversion error plus filter dynamics needed for backstepping design. The neural network controller does not require preliminary off-line training. Neural network tuning is based on a modified Hebbian tuning law, which requires less computation than backpropagation. The backstepping controller uses a practical filtered derivative, unlike the usual differentiation required by earlier backstepping routines. Rigorous stability proofs are given using Lyapunov theory. Simulation results show that the proposed compensation scheme is an efficient way of improving the tracking performance of a vast array of nonlinear systems with backlash.',\n",
       " 'Methods and apparatuses for backlash compensation. A dynamics inversion compensation scheme is designed for control of nonlinear discrete-time systems with input backlash. The techniques of this disclosure extend the dynamic inversion technique to discrete-time systems by using a filtered prediction, and shows how to use a neural network (NN) for inverting the backlash nonlinearity in the feedforward path. The techniques provide a general procedure for using NN to determine the dynamics preinverse of an invertible discrete time dynamical system. A discrete-time tuning algorithm is given for the NN weights so that the backlash compensation scheme guarantees bounded tracking and backlash errors, and also bounded parameter estimates. A rigorous proof of stability and performance is given and a simulation example verifies performance. Unlike standard discrete-time adaptive control techniques, no certainty equivalence (CE) or linear-in-the-parameters (LIP) assumptions are needed.',\n",
       " 'A bandwidth compression and expansion system is provided in which analog data is processed in real time using a sub-sampling technique in which pixels or other data values within a sub-sampling region determine the value of a corresponding signal which also denotes trends or patterns in accordance with the other pixels or signal values within a sampling region encompassing the sub-sampling region. Neural networks are used to implement the sub-sampling process both during bandwidth compression and during bandwidth expansion in which interpolation and extrapolation are employed to reverse the sub-sampling process used during compression. The neural network forms part of an arrangement in which analog input signals are converted to digital signals that are then stored in a random access memory which operates in conjunction with an address generator for identifying a succession of sampling and sub-sampling regions within the memory. The output of the memory is converted to an analog signal before being held in a sample and hold memory for use in the neural network.',\n",
       " 'The invention concerns a bank note scanner (2) for assessing the authenticity of a bank note, which includes a vacuum pump (4), an olfactory sensor (8), an authentication means (28) for producing an electrical output indicative of the authenticity of a bank note, and suction means (10) connected to the vacuum pump (4) via the olfactory sensor (8). In operation, a bank note is fed through an entry slot (50) in the scanner (2) into co-operative relationship with the suction means (10) such that the bank note covers, and is sucked against, the suction means (10), thus enabling the sensor (8) to test the note. The authentication means (28) comprises a neural network (26) which can be taught the olfactory characteristics of an authentic bank note. The authentication means (28) is arranged to make a determination of the authenticity of the bank note based on the comparison of the electrical output of the olfactory sensor (8) and the olfactory characteristics of one or more authentic bank notes.',\n",
       " 'A method for predicting properties of lubricant base oil blends, comprising the steps of generating an NMR spectrum, HPLC-UV spectrum, and FIMS spectrum of a sample of a blend of at least two lubricant base oils and determining at least one composite structural molecular parameter of the sample from said spectrums. SIMDIST and HPO analyses of the sample are then generated in order to determine a composite boiling point distribution and molecular weight of the sample from such analysis. A composite structural molecular parameter is applied, and the composite boiling point distribution and the composite molecular weight to a trained neural network is trained to correlate with the composite structural molecular parameter composite boiling point distribution and the composite molecular weight so as to predict composite properties of the sample. The properties comprise Kinematic Viscosity at 40 C, Kinematic Viscosity at 100 C, Viscosity Index, Cloud Point, and Oxidation Performance.',\n",
       " 'The present invention relates to a BDPD-based method for improving efficiency of RF power amplifier, comprising: first, choose key neural network architecture and scale and input initial values of modeling data and network parameters necessary for establishing the neural network model for RF power amplifier; second, correct network parameters with back propagation method and output the neural network model for RF power amplifier when the error meets the criterion; next, solve the pre-distortion algorithm of the RF power amplifier with said model and then carry out pre-distortion processing for the input with the pre-distortion algorithm and feed the input to the RF power amplifier. The present invention can be used to establish a neural network model with adequate accuracy and easy to solve corresponding pre-distortion algorithm for RF power amplifier, in order to improve RF power amplifier efficiency, reduce costs, and suppress out-of-band spectrum leakage effectively through base-band digital pre-distortion technology.',\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating a respective neural network output for each of a plurality of inputs, the method comprising, for each of the neural network layers: receiving a plurality of inputs to be processed at the neural network layer; forming one or more batches of inputs from the plurality of inputs, each batch having a number of inputs up to the respective batch size for the neural network layer; selecting a number of the one or more batches of inputs to process, where a count of the inputs in the number of the one or more batches is greater than or equal to the respective associated batch size of a subsequent layer in the sequence; and processing the number of the one or more batches of inputs to generate the respective neural network layer output.',\n",
       " 'Method and apparatus for battery evaluation and classification applies transient microcharge and/or microload pulses to an automotive battery. Classification is made on the basis of analysis of the resultant voltage profile or portions or dimensions thereof. In one embodiment the analysis utilizes a neural network or algorithm to assess a microcycle sequence of microload/microcharge tests utilizing one of a series of battery parameters including impedance as well as voltage characteristics to effect classification. Another embodiment adopts an optimized (not maximum) level of prior test-based data-training for a self-organizing neural network. A third embodiment utilizes prior test data correlation to enable algorithm-based classification without use of a neural network.',\n",
       " 'An optimization system is provided utilizing a Bayesian neural network calculation of a derivative wherein an output is optimized with respect to an input utilizing a stochastical method that averages over many regression models. This is done such that constraints from first principal models are incorporated in terms of prior art distributions.',\n",
       " 'Described herein are techniques for operating a security server to determine behavioral profiles for entities in a network and to detect attacks or unauthorized traffic in a network based on those behavioral profiles. In one technique, a behavioral profile may be generated based on requests for security operations to be performed that are received at a security server from an entity in a network. The behavioral profile may be generated using learning techniques, including artificial intelligence techniques such as neural networks. When the security server receives from an entity one or more requests for security operations to be performed, the security server may compare properties of the requests to the behavioral profile for the entity and properties of requests commonly sent by the entity. The security server may determine a similarity score indicating how similar the request are to the behavioral profile and to requests commonly received from the entity.',\n",
       " 'Digital data processing unit includes two SLMs assembled back-to-back with a common photoreceptor, to form a bidirectional spatial light modulator (BSLM) which facilitates the flow of data in the forward and reverse directions. An image can be written from the left side of the BSLM and read from the left or right side of the unit. An image can also be written from the right side and read from the right or left or both sides of the unit. The photoreceptor sums the light image intensities when data is concurrently written from both sides into the photoreceptor.',\n",
       " 'Use is made of a neural network in order to restore a binary image to an original multi-level image, by way of example. Using the neural network makes it possible to raise the accuracy of restoration and the speed of processing.',\n",
       " 'A system with applications in pattern recognition, or classification, of DNA assay samples. Because DNA reference and sample material in wells of an assay may be caused to fluoresce depending upon dye added to the material, the resulting light may be imaged onto an embodiment comprising an array of photodetectors and an adaptive neural network, with applications to DNA analysis. Other embodiments are described and claimed.',\n",
       " 'The method and system described herein use a biologically-based signal processing system for noise removal for signal extraction. A wavelet transform may be used in conjunction with a neural network to imitate a biological system. The neural network may be trained using ideal data derived from physical principles or noiseless signals to determine to remove noise from the signal.',\n",
       " 'A biometric identification apparatus and method using bio signals and an artificial neural network, are provided. The biometric identification apparatus includes: a periodic signal extraction unit which extracts one or more periodic signals from an input bio signal; a template calculation unit which calculates a template value using the extracted periodic signals; a template storage unit which stores a plurality of template values corresponding to a plurality of living bodies; and a reading unit which reads the template value that is most approximate to the template value calculated by the template calculation unit from the template storage unit. Accordingly, it is possible to identify a living body by taking into consideration all of the characteristics of bio signals detected from the living body.',\n",
       " \"A method and apparatus for providing biometric authentication of a user uses a registration process in which a reference data sample representative of a biometric attribute of a reference user is used to train a statistical classifier such as a neural network to achieve a target output. The set of parameters of the statistical classifier, e.g. the weights that achieve this in the neural network, are stored on a user's device as a first data set. For subsequent authentication of a user to be tested at an access point, the first data set is retrieved from the user device and a second data set representative of the biometric attribute of the test user is generated directly from the test user. The first data set is used as a set of parameters in a statistical classifier, e.g. as weights in an artificial neural network, to generate a trained classifier or neural network and the second data set is then used as input to the trained classifier or neural network. The output of the trained classifier or neural network is then used to determine a degree of correlation between the biometric attribute of the reference user and the biometric attribute of the test user to be authenticated.\",\n",
       " '\" A biometric recognition system involves two phases: creation of a master pattern set of authorized users biometric indicia and authentication using a classification neural network. To create the master pattern set, an image of an authorized biometric user\\'s indicia is divided into a plurality of regions of interest or \"\"features\"\". The system determines which features are the most useful for identification purposes. Master patterns are then created from these master features, thus creating a master pattern set. During authentication, a sample pattern set of a user to be authenticated is similarly created. A neural network is used to compare the sample pattern set with the master pattern set to determine whether the user should be authenticated. \"',\n",
       " 'A system, method and program product for providing biometric security using neuroplastic fidelity. A method is disclosed that includes: receiving biometric data; analyzing the biometric data with a probabilistic neural network and outputting a chromosome containing a binary string; mapping the binary string to a selected extractor and a selected matcher; apply the selected extractor to the biometric data to generate a template; using the selected matcher to compare the template to a set of stored templates to identify a match; and outputting a result.',\n",
       " 'A system and method enrolls a speaker with an enrollment utterance and authenticates a user with a biometric analysis of an authentication utterance, without the need for a PIN (Personal Identification Number). During authentication, the system uses the same authentication utterance to identify who a speaker claims to be with speaker recognition, and verify whether is the speaker is actually the claimed person. Thus, it is not necessary for the speaker to identify biometric data using a PIN. The biometric analysis includes a neural tree network to determine unique aspects of the authentication utterances for comparison to the enrollment authentication. The biometric analysis leverages a statistical analysis using Hidden Markov Models to before authorizing the speaker.',\n",
       " 'The subject invention includes a biomimetic integrated optical sensor system, based on the integration of a wide field-of-view (WFOV) miniature staring multi-aperture compound eye with a high-speed, low-cost, polarization and spectral selective liquid crystal (LC) filter array, a MWIR focal plane array (FPA), and a neural network processor.',\n",
       " \"A device for voice identification including a receiver, a segmenter, a resolver, two advancers, a buffer, and a plurality of IIR resonator digital filters where each IIR filter comprises a set of memory locations or functional equivalent to hold filter specifications, a memory location or functional equivalent to hold the arithmetic reciprocal of the filter's gain, a five cell controller array, several multipliers, an adder, a subtractor, and a logical non-shift register. Each cell of the five cell controller array has five logical states, each acting as a five-position single-pole rotating switch that operates in unison with the four others. Additionally, the device also includes an artificial neural network and a display means.\",\n",
       " 'An artificial multiped is constructed (either in simulation or embodied) in such a way that its natural body dynamics allow the lower part of each leg to swing naturally under the influence of gravity. The upper part of each leg is actively actuated in the sagittal plane. The necessary input to drive the above-mentioned actuators is derived from a neural network controller. The latter is arranged as two bi-directionally coupled chains of neural oscillators, the number of which equals twice that of the legs to be actuated. Parameter optimisation of the controllers is achieved by evolutionary computation in the form of a genetic algorithm.',\n",
       " 'A neuroprocessor architecture employs a combination of bit-serial and serial-parallel techniques for implementing the neurons of the neuroprocessor. The neuroprocessor architecture includes a neural module containing a pool of neurons, a global controller, a sigmoid activation ROM look-up-table, a plurality of neuron state registers, and a synaptic weight RAM. The neuroprocessor reduces the number of neurons required to perform the task by time multiplexing groups of neurons from a fixed pool of neurons to achieve the successive hidden layers of a recurrent network topology.',\n",
       " 'A neural network system and unsupervised learning process for separating unknown source signals from their received mixtures by solving the Independent Components Analysis (ICA) problem. The unsupervised learning procedure solves the general blind signal processing problem by maximizing joint output entropy through gradient ascent to minimize mutual information in the outputs. The neural network system can separate a multiplicity of unknown source signals from measured mixture signals where the mixture characteristics and the original source signals are both unknown. The system can be easily adapted to solve the related blind deconvolution problem that extracts an unknown source signal from the output of an unknown reverberating channel.',\n",
       " 'A method of optimizing a drilling operating parameter or a drilling system parameter for a drilling assembly employing at least first and second distinct cutting structures includes entering at least one design parameter for each of the cutting structures into a trained artificial neural network. At least one of the design parameters of the first cutting structure may be optionally combined with at least one of the design parameters of the second cutting structure. The combined design parameter may also be entered into the artificial neural network.',\n",
       " 'This disclosure provide a bottom sediment determining device, which is inputted with an echo signal corresponding to an ultrasonic wave outputted underwater, and determines water bottom sediment using a neural network. The device includes a memory for storing two or more parameters to be used in the neural network so as to be associated with positional information, a receiver for receiving the positional information, an acquisition module for acquiring the parameters corresponding to the positional information, and a setting module for setting the parameters to the neural network.',\n",
       " 'The present invention extracts boundaries from a sentence with no need for linguistic knowledge or complicated grammatical rules. Upon extracting a clause/phrase boundary, words are classified according to part-of-speech numbers of words which form inputted sentence information. Then, an input pattern representing part-of-speech numbers of a target word is checked to determine whether a clause/phrase boundary exists before or after the target word; a plurality of words before and after the target words is then applied to a neural network. Among units in the output layer of the neural network, a unit having the output larger than a threshold is determined to refer to a clause/phrase boundary of the target word. Upon extracting a subject-predicate boundary, words are classified in word number, and an input pattern corresponding to a plurality of words are applied to the neural network. The neural network comprises output units for a subject and a predicate, and a boundary is extracted by an inputted pattern which changes the output of these units.',\n",
       " 'Methods and systems for controlling a prosthesis using a brain imager that images a localized portion of the brain are provided according to one embodiment of the invention. The brain imager provides motor cortex activation data by illuminating the motor cortex with near infrared light (NIR) and detecting the spectral changes of the NIR light as passes through the brain. These spectral changes can be correlated with brain activity related to limbic control and may be provided to a neural network, for example, a fuzzy neural network that maps brain activity data to limbic control data. The limbic control data may then be used to control a prosthetic limb. Other embodiments of the invention include fiber optics that provide light to and receive light from the surface of the scalp through hair.',\n",
       " 'Methods and systems for controlling a prosthesis using a brain imager that images a localized portion of the brain are provided according to one embodiment of the invention. For example, the brain imager can provide motor cortex activation data using near infrared imaging techniques and EEG techniques among others. EEG and near infrared signals can be correlated with brain activity related to limbic control and may be provided to a neural network, for example, a fuzzy neural network that maps brain activity data to limbic control data. The limbic control data may then be used to control a prosthetic limb. Other embodiments of the invention include fiber optics that provide light to and receive light from the surface of the scalp through hair.',\n",
       " \"A system for automated geospatial image analysis comprising a deep learning model module and a convolutional neural network serving as an automated image analysis software module. The deep learning module receives a plurality of orthorectified geospatial images, pre-labeled to demarcate objects of interest, and optimized for the purpose of training the neural network of the image analysis software module. The module presents marked geospatial images and a second set of unmarked, optimized, training geospatial images to the convolutional neural network. This process may be repeated so that an image analysis software module can detect multiple object types or categories. The image analysis software module receives a plurality of orthorectified geospatial images from one or more geospatial image caches. Using multi-scale sliding window submodule, image analysis modules scan geospatial images, detect objects present and locate them on the geographical latitude-longitude system. The system reports the results in the requestor's preferred format.\",\n",
       " 'A building management set value decision support apparatus includes a thermal environment index calculation/display section, and a pseudo-thermal environment index calculation/display section. The thermal environment index calculation/display section calculates/displays the current value of a thermal environment index on the basis of the measured value of an air-conditioning control target and the measured or preset values of other predetermined parameters. The pseudo-thermal environment index calculation/display section calculates/displays a pseudo-thermal environment index on the basis of a supplied building management set value and the measured or preset values of the other predetermined parameters. A set value learning apparatus, a set value determining apparatus, and a neural network operation apparatus are also disclosed.',\n",
       " 'Aspects of the present disclosure relate to a method includes training a deep neural network using training images and data identifying one or more business storefront locations in the training images. The deep neural network outputs tight bounding boxes on each image. At the deep neural network, a first image may be received. The first image may be evaluated using the deep neural network. Bounding boxes may then be generated identifying business storefront locations in the first image.',\n",
       " 'A computer-aided diagnosis (CAD) method for the automated detection of lung nodules in a digital chest image, a computer programmed to implement the method, and a storage medium which stores a program for implementing the method, wherein nodule candidates are first automatically selected by thresholding the difference image and then classified in six groups. A large number of false positives are eliminated by adaptive rule-based tests applied to the original chest image and in the difference image and an artificial neural network (ANN) applied to remaining candidate nodule locations in the original chest image. Using two hundred PA chest radiographs, 100 normal and 100 abnormal, as the database, the presence of nodules in the 100 abnormal cases was confirmed by two experienced radiologists on the basis of CT scans or radiographic follow-up. The CAD method achieves, on average, the sensitivity of 70% at 1.7 false positives per chest image.',\n",
       " 'Systems and methods are disclosed for routing callers to agents in a contact center, along with an intelligent routing system. An exemplary method includes combining multiple output variables of a pattern matching algorithm (for matching callers and agents) into a single metric for use in the routing system. The pattern matching algorithm may include a neural network architecture, where the exemplary method combines output variables from multiple neural networks. The method may include determining a Z-score of the variable outputs and determining a linear combination of the determined Z-scores for a desired output. Callers may be routed to agents via the pattern matching algorithm to maximize the output value or score of the linear combination. The output variables may include revenue generation, cost, customer satisfaction performance, first call resolution, cancellation, or other variable outputs from the pattern matching algorithm of the system.',\n",
       " 'A camera system has a neural network for calibration of image distortion. The neural network learns the conversion from image coordinates with distortion to image coordinates with substantially reduced distortion, whereby the neural network provides image coordinates having substantially reduced distortion. In a learning process of the neural network, a relatively simple camera model is used to provide an instruction signal to the neural network according to sample data provided from the real camera.',\n",
       " '\" The present invention is directed to a shoe of the type described wherein the shoe has a card scanner which scans indicia on a playing card as the card moves along and out of a chute by manual direction by the dealer in the normal fashion. The scanner can be one of several different types of devices which will sense each card as it is moved downwardly and out of the shoe. A feed forward neural-network which is trained using error back-propagation to recognize all possible card suits and card values sensed by the scanner. Such a neural-network becomes a part of a scanning system which provides a proper reading of the cards to determine the progress of the play of the game including how the game might suffer if the game players are allowed to count cards using a card count system and perform other acts which would limit the profit margin of the casino. The shoe of the present invention is also provided with additional devices which make it simple and easy to record data relevant to the play of the game. For instance, the shoe has means for accommodating a \"\"customer-tracking-card\"\" or preferred customer card which reads the personal information of a card holder from a magnetic stripe on the card and this information travels with the preferred customer from game to game, throughout a casino, which the customer likes to play. An LCD display can also be part of the shoe and this display can be used to enter and retrieve vital player information as deemed necessary or desirable to the customer file opened when the magnetic stripe reader reads the preferred customer card with the customer name and account number embedded within the cards magnetic stripe. \"',\n",
       " '\" The present invention is directed to a playing card dispensing shoe apparatus, system and method wherein the shoe has a card scanner which scans the indicia on a playing card as the card moves along and out of a chute of the shoe by operation of the dealer. The scanner comprises an optical-sensor used in combination with a neural network which is trained using error back-propagation to recognize the card suits and card values of the playing cards as they are moved past the scanner. The scanning process in combination with a central processing unit (CPU) determines the progress of the play of the game and, by identifying card counting systems or basic playing strategies in use by the players of the game, provides means to limit or prevent casino losses and calculate the Theoretical Win of the casino, thus also providing an accurate quality method of the amount of comps to be given a particular player. The shoe is also provided with additional devices which make it simple and easy to access, record and display other data relevant to the play of the game. These include means for accommodating a \"\"customer-tracking-card\"\" which reads each player\\'s account information from a magnetic stripe on the card, thus providing access to the player\\'s customer data file stored on the casino\\'s computer system and one or more alpha-numeric keyboards and LCD displays used to enter and retrieve player and game information. Also included are keyboards on the game table so that each player can individually select various playing or wagering options using their own keyboard. \"',\n",
       " '\" The present invention is directed to a playing card dispensing shoe apparatus, system and method wherein the shoe has a card scanner which scans the indicia on a playing card as the card moves along and out of a chute of the shoe by operation of the dealer. The scanner comprises an optical-sensor used in combination with a neural network which is trained using error back-propagation to recognize the card suits and card values of the playing cards as they are moved past the scanner. The scanning process in combination with a central processing unit (CPU) determines the progress of the play of the game and, by identifying card counting systems or basic playing strategies in use by the players of the game, provides means to limit or prevent casino losses and calculate the Theoretical Win of the casino, thus also providing an accurate quality method of the amount of comps to be given a particular player. The shoe is also provided with additional devices which make it simple and easy to access, record and display other data relevant to the play of the game. These include means for acconunodating a \"\"customer-tracking card\"\" which reads each player\\'s account information from a magnetic stripe on the card, thus providing access to the player\\'s customer data file stored on the casino\\'s computer system, and one or more alpha-numeric keyboards and LCD displays used to enter and retrieve player and game information. Also included are keyboards on the game table so that each player can individually select various playing or wagering options using their own keyboard. \"',\n",
       " 'High-speed, analog, fully-parallel and asynchronous building blocks are cascaded for larger sizes and enhanced resolution. A hardware-compatible algorithm permits hardware-in-the-loop learning despite limited weight resolution. A computation-intensive feature classification application has been demonstrated with this flexible hardware and new algorithm at high speed. This result indicates that these building block chips can be embedded as application-specific-coprocessors for solving real-world problems at extremely high data rates.',\n",
       " 'A process and apparatus for monitoring catalyst conversion activity includes a predictor of feedgas emissions and a predictor of tailpipe emissions, each predictor providing an output for generating a ratio of conversion activity. Each predictor comprises a trained neural network receiving at least one of, and preferably a plurality of, the engine operating condition signals available from an electronic engine control. Preferably, each neural network is trained by inputting accumulated data acquired from performance evaluation of a plurality of vehicles having consistent powertrains but with different degrees of deterioration.',\n",
       " 'A compact disc (CD) read sensor apparatus for reading data from a CD track uses multiple laser beams for performing both tracking and reading data. In one embodiment, two laser beams are used to track by controlling the radial position of the two beams that are nominally radially disposed towards opposite edges of the recorded track. A differential signal is used to obtain tracking information and a sum signal is used to produce a read signal. In another embodiment, three laser beams are used corresponding to prior art three beam systems using two beams nominally disposed towards opposite edges for tracking and a center beam for reading. The three beams are combined to form an enhanced read signal with an improved signal-to-noise ratio over that obtained by any one beam. The combining operation includes adjusting for any relative delays between the multiple beam signals detected by the photocells to produce synchronous laser beam signals followed by a summing operation that may optionally include optimal combining operations such as weighted summing, filtering, and neural network processing.',\n",
       " 'A cellular automata neural network method for process modeling of film-substrate interactions utilizes a cellular automaton system having variable rules for each cell. The variable rules describe a state change algorithm for atoms or other objects near a substrate. The state change algorithm is used to create a training set of solutions for training a neural network. The cellular automaton system is run to model the film-substrate interactions with the neural network providing the state change solutions in place of the more computationally complex state change algorithm to achieve real-time or near real-time simulations.',\n",
       " \"A cellular network assignment processor (10) for solving optimization problems utilizing a neural network architecture having a matrix of simple processing cells (12) that are highly interconnected in a regular structure. The cells (12) accept as input, costs in an assignment problem. The position of each cell (12) corresponds to the position of the cost in the associated constraint space of the assignment problem. Each cell (12) is capable of receiving, storing and transmitting cost values and is also capable of determining if it is the maximum or the minimum of cells (12) to which it's connected. Operating on one row of cells (12) at a time the processor (10) determines if a conflict exists between selected connected cells (12) until a cell (12) with no conflict is found in each row. The end result is a chosen cell (12), in each row, the chosen cells (12) together representing a valid solution to the assignment problem.\",\n",
       " 'A novel class of information-processing systems called a cellular neural network is discussed. Like a neural network, it is a large-scale nonlinear analog circuit which processes signals in real time. Like cellular automata, it is made of a massive aggregate of regularly spaced circuit clones, called cells, which communicate with each other directly only through its nearest neighbors. Each cell is made of a linear capacitor, a nonlinear voltage-controlled current source, and a few resistive linear circuit elements. Cellular neural networks share the best features of both worlds; its continuous time feature allows real-time signal processing found within the digital domain and its local interconnection feature makes it tailor made for VLSI implementation. Cellular neural networks are uniquely suited for high-speed parallel signal processing.',\n",
       " \"A neural cellular network for implementing a so-called Chua's circuit, and comprising at least first, second and third cells having respective first and second input terminals and respective state terminals, the first and second input terminals being to receive a first and a second reference signal, respectively, and the first cell, and the second and third cells being of mutually different types.\",\n",
       " 'The invention relates to a neural network centering scheme for translation-invariant pattern recognition. The scheme involves the centering of a pattern about its centroid to prepare it for subsequent subjugation to an associative match. The scheme is utilized in a camera assembly of the type used for image acquisition. Movement of the camera assembly is controlled in accordance with the scheme to effect the centering of a pattern in the field of view window of the camera assembly.',\n",
       " '\"A method of training a biological neural network using a controller, comprising:    \"',\n",
       " 'A mapping circuit includes a linear circuit for outputting a signal which is linearly changed with respect to its input, a non-linear circuit for outputting a signal which is non-linearly changed with respect to its input, and an adder for summing the output signals of the linear and non-linear circuits and an external input signal. A chaotic neuron circuit using the mapping circuit has a simple structure and more precise chaos characteristics. A chaotic neural network can thus be formed by the serial and/or parallel interconnection of a plurality of chaotic neuron circuits, wherein the weight of each neuron is controlled.',\n",
       " '\" A chaotic recurrent neural network includes N chaotic neural networks for receiving an external input and the outputs of N-1 chaotic neural networks among said N chaotic neural networks and performing an operation according to the following dynamic equation ##EQU1## wherein W.sub.ij is a synapse connection coefficient of the feedback input from the \"\"j\"\"th neuron to the \"\"i\"\"th neuron, X.sub.i (t) is the output of the \"\"i\"\"th neuron at time t, and .gamma..sub.i, .alpha. and and k are a time-delaying constant, a non-negative parameter and a refractory time attenuation constant, respectively, and wherein Z.sub.i (t) represents X.sub.i (t) when i belongs to the neuron group I and represents a.sub.i (t) when i belongs to the external input group E. Also, a learning algorithm for the chaotic recurrent neural network increases its learning efficiency. \"',\n",
       " 'A character recognition apparatus and method based on a character orientation are provided, in which an input image is binarized, at least one character area is extracted from the binarized image, a slope value of the extracted at least one character area is calculated, the calculated slope value is set as a character feature value, and a character is recognized by using a neural network for recognizing a plurality of characters by receiving the set character feature value. Accordingly, the probability of wrongly recognizing a similar character decreases, and a recognition ratio of each character increases.',\n",
       " 'A method for recognition of an unconstrained written character image employs at least one non-character recognizer in addition to character recognizers for each candidate character. The input image is rejected if any of the non-character recognizers produces a match. The input image is recognized only if a) a character recognizer produces a match, and b) none of the non-character recognizers produces a match. The non-character recognizers are preferably trained on a) images which are not recognized by the set of character recognizers, B) images which are misclassified by at least one of the set of character recognizers result, and c) incorrectly segmented images. In the preferred embodiment of this invention individual segmented digit images are recognized for automatic sorting of mail by ZIP code. In the preferred embodiment plural character recognizers and at least one non-character recognizer are embodied in a neural network using a place encoding output. The preferred embodiment includes window encoding of the normalized image and plural cavity feature images derived from the normalized image. A set of encoded values is computed from the ratio of the number of stroke pixels within the overlapping windows divided by the size of the window.',\n",
       " 'A character recognition system based on a neural network determines activation patterns in an input layer and output layer, increases weights of synapses in a middle layer so that neurons activate with more than a certain rate among those corresponding to neurons in the input layer and the output layer and repeats the same process for each neuron in the middle layer. The input layer and output layer possess a plurality of neurons which activate and output certain data according to a specific result and the middle layer is between the input layer and output layer. The middle layer also possesses a plurality of neurons which are connected to each neuron in the input layer and output layer.',\n",
       " 'In a process control data base, intermediate characteristics, processing condition for controlling a characteristic and a final characteristic in a process of manufacturing products are stored as a set of data for each product lot. In Process 1, a set of data for each product lot are prepared. Next, in Process 2, cluster processing is conducted on each set of data obtained in Process 1. In Process 3, using the set of data obtained in Process 2, the intermediate characteristics and the processing condition for controlling a characteristic are inputted and the final characteristic is outputted, and a causal relation between the input and output is quantified by a neural network so as to make a learning model. In a model applying stage, the most appropriate processing condition for controlling a characteristic is retrieved by using the learning model and the intermediate characteristics in the previous steps.',\n",
       " 'An excitation event in an oil, gas or geothermal well creates a responsive signal having lower and higher frequency components, which higher frequency component provides information about one or more characteristics of the well. Examples of such characteristics pertaining to a subterranean fracture include: breakdown pressure at fracture initiation, time it takes proppant to reach and to screenout the tip of the fracture, fracture geometry and fracture growth, fracture closure pressure, relative fluid flow through respective perforations, and horsepower requirements to perform a fracture treatment. One excitation event includes creating an excitation signal having a maximum amplitude change occurring within a time t1, which is less than a period t2 of the higher frequency component. Wavelet processing may be used to separate or distinguish the higher frequency waveform from the lower frequency waveform. The information can be used to control a process (for example, a fracturing process) applied to the respective well or one or more other wells. In another aspect, an unidentified signature waveform is compared to identified signature waveforms in a neural network computer database to create an identity for the unidentified signature waveform relative to an identified signature waveform in the database. A system to determine a characteristic of an oil, gas or geothermal well is also disclosed.',\n",
       " 'For digital pathology imaging, intelligent processing, such as automatic recognition or content-based retrieval, is one significant benefit that drives the wide application of this technology. Before any intelligent processing on pathology images, every image is converted into a feature vector which quantitatively capture its visual characteristics. An algorithm characterizing pathology images with statistical analysis of local responses of neural networks is described herein. The algorithm framework enables extracting sophisticated textural features that are well adapted to the image data of interest.',\n",
       " \"A charge domain bit serial vector matrix multiplier for real time signal processing of mixed digital/analog signals for implementing opto-electronic neural networks and other signal processing functions. A combination of CCD and DCSD arrays permits vector/matrix multiplication with better than 10.sup.11 multiply accumulates per second on a one square centimeter chip. The CCD array portion of the invention is used to load and move charge packets into the DCSD array for processing therein. The CCD array is also used to empty the matrix of unwanted charge. The DCSD array is designed to store a plurality of charge packets representing the respective matrix values such as the synaptic interaction matrix of a neural network. The vector multiplicand may be applied in bit serial format. The row or sensor lines of the DCSD array are used to accumulate the results of the multiply operation. Each such row output line is provided with a divide-by-two/accumulate CCD circuit which automatically compensates for the increasing value of the input vector element's bits from least significant bit to most significant bit. In a similar fashion each row output line can be provided with a multiply-by-two/accumulate CCD circuit which automatically accounts for the decreasing value of the input vector element's bits from most significant bit to least significant bit. The accumulated charge packet output of the array may be preferably converted to a digital signal compatible with the input vector configuration by utilizing a plurality of analog-to-digital converters.\",\n",
       " 'A charging system has an alternator, a battery, and a controlled rectifier bridge between the alternator and the battery. The controlled rectifier bridge has controllable elements. A controller is provided wherein the controller controls (a) the duty cycle of the alternator field winding and (b) the switching in the controllable elements to control the phase advance angle. By utilizing a half-wave controlled rectifier bridge and three controllable elements, power output can be increased at a low overall cost. In another embodiment, the controller determines switching points for the controllable elements through a third harmonic extraction device which employs a neural network for determining the zero crossings of the third harmonic voltage obtained from a single phase voltage.',\n",
       " 'A device and method for a pattern recognition system using a self-training neural network classifier with automated outlier detection for use in chemical sensor array systems. The pattern recognition system uses a Probabilistic Neural Network (PNN) training computer system to develop automated classification algorithms for field-portable chemical sensor array systems. The PNN training computer system uses a pattern extraction unit to determine pattern vectors for chemical analytes. These pattern vectors form the initial hidden layer of the PNN. The hidden layer of the PNN is reduced in size by a learning vector quantization (LVQ) classifier unit. The hidden layer neurons are further reduced in number by checking them against the pattern vectors and further eliminating dead neurons using a dead neuron elimination device. Using the remaining neurons in the hidden layer of the PNN, a global, .sigma. value is calculated and a threshold rejection value is determined. The hidden layer, .sigma. value and the threshold value are then downloaded into a PNN module for use in a chemical sensor field unit. Based on the threshold value, outliers seen in the real world environment may be rejected and a predicted chemical analyte identification with a measure of uncertainty will be provided to the user.',\n",
       " 'An artificial neural network performs error correction on an input signal vector. The input signal vector is process in a forward direction through synapses in each of a plurality of neurons for providing an output signal from each of the neurons. The output signals from the neurons are monitored until the one having the greatest activity level is identified. A reverse flow signal having a predetermined magnitude is processed in the reverse direction through the neuron having the greatest activity level for updating the input signal vector. Alternately, the output signals of competing neurons may be applied through synapses weighted to favor the neuron having the greatest output signal activity. Thus, the neuron with synapses most closely matched to the elements of the input signal vector overpowers the remaining neurons and wins the competition. Once the winning neuron is identified, its output signal is reverse processed through the respective neuron for providing an improved input signal vector with reduced noise and error. The improved signal is reprocessed in the forward direction through the neural network for providing higher confidence output signals.',\n",
       " 'Motor vehicle sensor signals are evaluated by a fuzzy system, which generates control signals for a system device of the motor vehicle--for example an automatic transmission, active suspension, speed stabilization, power-steering assistance, or traction control. The fuzzy system is connected to a neural network, which evaluates the sensor signals and reference data from a recording of driving data of the motor vehicle. The neural network optimizes the rule base of the fuzzy system. During a driving operation, the fuzzy system generates on-line signals categorizing the respective driving situation, and thus makes possible intelligent, time-adaptive, driving-situation-dependent control. The fuzzy system and the neural network each contain a classification system which can be reciprocally converted by a correspondence-maintaining bidirectional transformation.',\n",
       " 'In each neuron in a neural network of a plurality of neuron circuits either in an engaged or a free state, a pre-charge circuit, that allows loading the components of an input vector (A) only into a determined free neuron circuit during a recognition phase as a potential prototype vector (B) attached to the determined neuron circuit. The pre-charge circuit is a weight memory (251) controlled by a memory control signal (RS) and the circuit generating the memory control signal. The memory control signal identifies the determined free neuron circuit. During the recognition phase, the memory control signal is active only for the determined free neuron circuit. When the neural network is a chain of neuron circuits, the determined free neuron circuit is the first free neuron in the chain. The input vector components on an input data bus (DATA-BUS) are connected to the weight memory of all neuron circuits. The data therefrom are available in each neuron on an output data bus (RAM-BUS). The pre-charge circuit may further include an address counter (252) for addressing the weight memory and a register (253) to latch the data output on the output data bus. After the determined neuron circuit has been engaged, the contents of its weight memory cannot be modified. Pre-charging the input vector during the recognition phase makes the engagement process more efficient and significantly reduces learning time in learning the input vector.',\n",
       " \"In a neural network of N neuron circuits, having an engaged neuron's calculated p bit wide distance between an input vector and a prototype vector and stored in the weight memory thereof, an aggregate search/sort circuit (517) of N engaged neurons' search/sort circuits. The aggregate search/sort circuit determines the minimum distance among the calculated distances. Each search/sort circuit (502-1) has p elementary search/sort units connected in series to form a column, such that the aggregate circuit is a matrix of elementary search/sort units. The distance bit signals of the same bit rank are applied to search/sort units in each row. A feedback signal is generated by ORing in an OR gate (12.1) all local search/sort output signals from the elementary search/sort units of the same row. The search process is based on identifying zeroes in the distance bit signals, from the MSB's to the LSB's. As a zero is found in a row, all the columns with a one in that row are excluded from the subsequent row search. The search process continues until only one distance, the minimum distance, remains and is available at the output of the OR circuit. The above described search/sort circuit may further include a latch allowing the aggregate circuit to sort remaining distances in increasing order.\",\n",
       " 'The improved neural network of the present invention results from the combination of a dedicated logic block with a conventional neural network based upon a mapping of the input space usually employed to classify an input data by computing the distance between said input data and prototypes memorized therein. The improved neural network is able to classify an input data, for instance, represented by a vector A even when some of its components are noisy or unknown during either the learning or the recognition phase. To that end, influence fields of various and different shapes are created for each neuron of the conventional neural network. The logic block transforms at least some of the n components (A1, . . . , An) of the input vector A into the m components (V1, . . . , Vm) of a network input vector V according to a linear or non-linear transform function F. In turn, vector V is applied as the input data to said conventional neural network. The transform function F is such that certain components of vector V are not modified, e.g. Vk=Aj, while other components are transformed as mentioned above, e.g. Vi=Fi(A1, . . . , An). In addition, one (or more) component of vector V can be used to compensate an offset that is present in the distance evaluation of vector V. Because, the logic block is placed in front of the said conventional neural network any modification thereof is avoided.',\n",
       " 'A boosting and pruning system and method for utilizing a plurality of neural networks, preferably those based on adaptive resonance theory (ART), in order to increase pattern classification accuracy is presented. The method utilizes a plurality of N randomly ordered copies of the input data, which is passed to a plurality of sets of booster networks. Each of the plurality of N randomly ordered copies of the input data is divided into a plurality of portions, preferably with an equal allocation of the data corresponding to each class for which recognition is desired. The plurality of portions is used to train the set of booster networks. The rules generated by the set of booster networks are then pruned in an intra-booster pruning step, which uses a pair-wise Fuzzy AND operation to determine rule overlap and to eliminate rules which are sufficiently similar. This process results in a set of intra-booster pruned booster networks. A similar pruning process is applied in an inter-booster pruning process, which eliminates rules from the intra-booster pruned networks with sufficient overlap. The final, derivative booster network captures the essence of the plurality of sets of booster networks and provides for higher classification accuracy than available using a single network.',\n",
       " 'Classification method implemented in a layered neural network, comprising learning steps during which at least one layer is constructed by the addition of the successive neurons necessary for operating, by successive dichotomies, a classification of examples distributed over classes. In order to create at least one layer starting with a group of examples distributed over more than two classes, each successive neuron tends to distinguish its input data according to two predetermined sub-groups of classes peculiar to the said neuron according to a principal components analysis of the distribution of the said input data subjected to the learning of the neuron of the layer in question.',\n",
       " 'The classification system represents a detected object with a feature vector derived from the return signals acquired by an array of N transceivers operating in multistatic mode. The classification system generates the feature vector by transforming the real-valued return signals into complex-valued spectra, using, for example, a Fast Fourier Transform. The classification system then generates a feature vector of singular values for each user-designated spectral sub-band by applying a singular value decomposition (SVD) to the N×N square complex-valued matrix formed from sub-band samples associated with all possible transmitter-receiver pairs. The resulting feature vector of singular values may be transformed into a feature vector of singular value likelihoods and then subjected to a multi-category linear or neural network classifier for object classification.',\n",
       " 'Classification procedure implemented in a tree-like neural network which, in the course of learning steps, determines with the aid of a tree-like structure the number of neurons and their synaptic coefficients required for the processing of problems of classification of multi-class examples. Each neuron tends to distinguish, from the examples, two groups of examples approximating as well as possible to a division into two predetermined groups of classes. This division can be obtained through a principal component analysis of the distribution of examples. The neural network comprises a directory of addresses of successor neurons which is loaded in learning mode then read in exploitation mode. A memory stores example classes associated with the ends of the branches of the tree.',\n",
       " 'A method for analyzing the use of a work machine is disclosed. In one embodiment, the method may include providing a computer with a neural network on the work machine. Further, the method may include inputting data to the computer, at least a portion of the data associated with a load experienced by one of the components of the work machine. The neural network, when executed by the computer may then classify a current operation of the work machine into one of a plurality of types of operations.',\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on computer storage media, for scoring concept terms using a deep network. One of the methods includes receiving an input comprising a plurality of features of a resource, wherein each feature is a value of a respective attribute of the resource; processing each of the features using a respective embedding function to generate one or more numeric values; processing the numeric values using one or more neural network layers to generate an alternative representation of the features, wherein processing the floating point values comprises applying one or more non-linear transformations to the floating point values; and processing the alternative representation of the input using a classifier to generate a respective category score for each category in a pre-determined set of categories, wherein each of the respective category scores measure a predicted likelihood that the resource belongs to the corresponding category.',\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on computer storage media, for scoring concept terms using a deep network. One of the methods includes receiving an input comprising a plurality of features of a resource, wherein each feature is a value of a respective attribute of the resource; processing each of the features using a respective embedding function to generate one or more numeric values; processing the numeric values using one or more neural network layers to generate an alternative representation of the features, wherein processing the floating point values comprises applying one or more non-linear transformations to the floating point values; and processing the alternative representation of the input using a classifier to generate a respective category score for each category in a pre-determined set of categories, wherein each of the respective category scores measure a predicted likelihood that the resource belongs to the corresponding category.',\n",
       " 'A classification system is provided for combining multiple input representations by a single neural network architecture. In such a classification system having a single neural network architecture, classification channels corresponding to various input representations may be integrated through their own and shared hidden layers of the network to produce highly accurate classification. The classification system is particularly applicable to character classifying applications which use stroke and character image features as the main classification criteria, along with scalar features such as stroke count and aspect ratio features as secondary classification. The classification channels corresponding to the scalar features may be cross wired to the classification channels corresponding to the main input representations for further improving the accuracy of the classification output. Because a single neural network architecture is used, only one, standard training technique is needed for this classification system, special data handling is minimized, and the training time can be reduced, while highly accurate classification is achieved.',\n",
       " 'Characteristics of the plasma in a plasma-based manufacturing process step are monitored directly and in real time by observing the spectrum which it produces. An artificial neural network analyzes the plasma spectrum and generates control signals to control one or more of the process input parameters in response to any deviation of the spectrum beyond a narrow range. In an embodiment, a plasma reaction chamber forms a plasma in response to input parameters such as gas flow, pressure and power. The chamber includes a window through which the electromagnetic spectrum produced by a plasma in the chamber, just above the subject surface, may be viewed. The spectrum is conducted to an optical spectrometer which measures the intensity of the incoming optical spectrum at different wavelengths. The output of optical spectrometer is provided to an analyzer which produces a plurality of error signals, each indicating whether a respective one of the input parameters to the chamber is to be increased or decreased. The microcontroller provides signals to control respective controls, but these lines are intercepted and first added to the error signals, before being provided to the controls for the chamber. The analyzer can include a neural network and an optional spectrum preprocessor to reduce background noise, as well as a comparator which compares the parameter values predicted by the neural network with a set of desired values provided by the microcontroller.',\n",
       " 'A closed loop neural network based autotuner develops optimized proportional, integral and/or derivative parameters based on the outputs of other elements in the loop. Adjustments are initiated by making a step change in the setpoint which may be done by a user or automatically. A Smith predictor may also be employed.',\n",
       " 'A clothes dryer of the dehumidification type is disclosed in which hot air induced by a heater is circulated from a drying compartment through a heat exchanger. A volume, wetness, wetness unevenness, temperature, temperature unevenness of clothes to be dried and the temperature of the hot air blown out of the drying compartment are detected by respective detectors. Results of detection are input to a control device incorporating a neural network. The control device operates in the manner of neurocontrol to control a volume of outside air supplied to the heat exchanger and a heating value of the heater.',\n",
       " \"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for receiving data representing acoustic characteristics of a user's voice; selecting a cluster for the data from among a plurality of clusters, where each cluster includes a plurality of vectors, and where each cluster is associated with a speech model trained by a neural network using at least one or more vectors of the plurality of vectors in the respective cluster; and in response to receiving one or more utterances of the user, providing the speech model associated with the cluster for transcribing the one or more utterances.\",\n",
       " '\" A plurality of neural networks are coupled to an output neural network, or judge network, to form a clustered neural network. Each of the plurality of clustered networks comprises a supervised learning rule back-propagated neural network. Each of the clustered neural networks are trained to perform substantially the same mapping function before they are clustered. Following training, the clustered neural network computes its output by taking an \"\"average\"\" of the outputs of the individual neural networks that make up the cluster. The judge network combines the outputs of the plurality of individual neural networks to provide the output from the entire clustered network. In addition, the output of the judge network may be fed back to each of the individual neural networks and used as a training input thereto, in order to provide for continuous training. The use of the clustered network increases the speed of learning and results in better generalization. In addition, clustering multiple back-propagation networks provides for increased performance and fault tolerance when compared to a single unclustered network having substantially the same computational complexity. The present invention may be used in applications that are amenable to neural network solutions, including control and image processing applications. Clustering of the networks also permits the use of smaller networks and provides for improved performance. The clustering of multiple back-propagation networks provides for synergy that improves the properties of the clustered network over a comparably complex non-clustered network. \"',\n",
       " 'A computer numerical control unit with learning ability solves the problem of automatic and intelligent generating of numerical control programs for computer numerical control machining centers for milling, drilling and similar operations. The key module of the computer numerical control unit is a neural network (NN) device that learns to generate the numerical control programs through an neural network teaching module. Upon completion of learning process the neural network device can generate automatically, without any intervention of the operator, merely on the basis of the CAD 2D, 2,5D or 3D part models, taken from a conventional CAD/CAM system, various new numerical control programs for different parts, which have not been in the machining process before. The computer numerical control control unit with learning ability is suitable especially for machining centers intended for milling, including face milling (rough), contour milling (rough), final milling following the contour and in Z-plane, final contour 3D milling, contour final milling, milling in Z-plane, final contour milling on the equidistant, and milling of pockets; drilling, including normal drilling, deep drilling, and center drilling; and reaming, sinking and threading.',\n",
       " '\" The main design components underlying the implementation of physiologically faithful retina and other topographic sensory organ models on Cellular Neural Network (CNN) universal chips is discussed. If the various retinas are implemented on a CNN universal chip, in a programmable way, it can be called a \"\"CNN bionic eye\"\", a device capable of performing a broad range of image processing functions similar to those performed by biological retinas. The CNN universal machine has the special properties that it is 1) programmable and 2) includes local memory. Programming is stored in analog and logical form (the analogic program) generated by an analogic programming and control unit, so the functions of the CNN universal machine can be modified as a function of complex internal and external constraints. Further, several CNN bionic eyes and other topographic sensory modalities can be combined on a single CNN universal chip, and, for more complex sensory tasks, the necessary physical microsensors to provide the input signals can be implemented on the chip, in most instances. \"',\n",
       " 'Methods and systems for license plate recognition utilizing a trained neural network. In an example embodiment, a neural network can be subject to operations involving iteratively training and adapting the neural network for a particular task such as, for example, text recognition in the context of a license plate recognition application. The neural network can be trained to perform generic text recognition utilizing a plurality of training samples. The neural network can be applied to a cropped image of a license plate in order to recognize text and produce a license plate transcription with respect to the license plate. An example of such a neural network is a CNN (Convolutional Neural. Network).',\n",
       " 'A method for ordering electrofacies to assist in identification of mineral deposits is disclosed. Automated ordering of electrofacies allows geologists to draw inferences about the geological settings in which sediment deposit occurred without directly examining core samples or outcrops. The electrofacies order is determined by (a) training a one-dimensional linear self-organizing map to form an initial neural network that includes a plurality of neurons. The number of neurons is small in comparison to the number of electrofacies kernels (i.e., not greater than one-third the number of electrofacies kernels). (b1) A neuron is selected from the initial neural network. In the next step (b2), the processor determines if more than one electrofacies kernel is attached to the neuron. (b3) If more than one electrofacies kernel is attached to the neuron, then the neuron is split into the number of electrofacies kernels attached to the neuron. (c) Steps (b1)-(b3) are repeated until all neurons in the initial neural network have been processed. In the next step, (d) a self-organizing map is trained to form a final neural network using the split neurons in the initial neural network as initial state. (e) Steps (b1)-(d) are repeated if more than one electrofacies kernel is attached to a neuron with the initial neural network equal to the final neural network. In the last step (f), each electrofacies kernel corresponding to a neuron in the final neural network is correlated to an order number.',\n",
       " 'The subject invention provides a method of creating a database for searching for a paint color having a desired texture, a search method using the database, and systems, programs, and recording mediums for carrying out the method and the search. The method for creating a database includes a step (S11) for storing spectral reflectance data and micro-brilliance data of a plurality of paint colors after associating each spectral reflectance data and each micro-brilliance data with a paint color code; a step (S13) for storing texture evaluation values of sample paint colors after associating the each texture evaluation value with the paint color code; a step (S14) for calculating characteristic quantities of the paint colors expressing textures using the spectral reflectance data and the micro-brilliance data, and storing the characteristic quantities after associating the each characteristic quantity with the paint color code; a step (S15) for carrying out a process for training a neural network using the characteristic quantities and the texture evaluation values of the sample paint colors as training data; and a step (S16) for inputting characteristic quantities of the paint colors other than the sample paint colors into the neural network after the training process, and storing output data after associating the each output data with the paint color code.',\n",
       " 'A method for creating a database for paint colors having a desired texture includes storing spectral reflectance data and micro-brilliance data of paint colors after associating each spectral reflectance data and each micro-brilliance data with a paint color code; storing texture evaluation values of sample paint colors after associating the each texture evaluation value with the paint color code; calculating characteristic quantities of the paint colors expressing textures using the spectral reflectance data and the micro-brilliance data, and storing the characteristic quantities after associating the each characteristic quantity with the paint color code; training a neural network using the characteristic quantities and the texture evaluation values of the sample paint colors as training data; and inputting characteristic quantities of the paint colors other than the sample paint colors into the neural network after the training, and storing output data after associating each output data with the paint color code.',\n",
       " 'A method for estimating a quality of code coverage of a test is described. The method includes training a neural network, using the neural network to generate a risk factor for each code element, and determining a coverage quality based on risk factors of executed code elements and risk factors of unexecuted code elements. The neural network is trained by inputting suggestive data as input and error severity data as output. Suggestive data may be data that correlates to a likelihood that a code element contains an error, and the error severity data is an evaluation of a severity of any error that was present in the code element. A coverage quality can be determined based on the risk factors of the code elements tested during the test and the risk factors of the code elements not tested during the test.',\n",
       " \"Designs for cognitive memory systems storing input data, images, or patterns, and retrieving it without knowledge of where stored when cognitive memory is prompted by query pattern that is related to sought stored pattern. Retrieval system of cognitive memory uses autoassociative neural networks and techniques for pre-processing query pattern to establish relationship between query pattern and sought stored pattern, to locate sought pattern, and to retrieve it and ancillary data. Cognitive memory, when connected to computer or information appliance introduces computational architecture that applies to systems and methods for navigation, location and recognition of objects in images, character recognition, facial recognition, medical analysis and diagnosis, video image analysis, and to photographic search engines that when prompted with a query photograph containing faces and objects will retrieve related photographs stored in computer or other information appliance, and will identify URL's of related photographs and documents stored on the World Wide Web.\",\n",
       " \"Designs for cognitive memory systems storing input data, images, or patterns, and retrieving it without knowledge of where stored when cognitive memory is prompted by query pattern that is related to sought stored pattern. Retrieval system of cognitive memory uses autoassociative neural networks and techniques for pre-processing query pattern to establish relationship between query pattern and sought stored pattern, to locate sought pattern, and to retrieve it and ancillary data. Cognitive memory, when connected to computer or information appliance introduces computational architecture that applies to systems and methods for navigation, location and recognition of objects in images, character recognition, facial recognition, medical analysis and diagnosis, video image analysis, and to photographic search engines that when prompted with a query photograph containing faces and objects will retrieve related photographs stored in computer or other information appliance, and will identify URL's of related photographs and documents stored on the World Wide Web.\",\n",
       " 'A color balance adjusting apparatus for adjusting color imbalance due to the difference in color temperature between a preferable standard illuminant and an illuminant under which a color image is obtained, thereby making the colors of the image substantially identical to those obtained under the preferable standard illuminant. This apparatus comprises a decorrelating neural network for receiving three color component signals correlating with one another and indicative of an image, and minimizing the correlation thereamong, the network having learned so as to minimize the correlation among signals indicative of an image obtained under an illuminant, and a converter for mapping the output of the decorrelating means, into a space of the input image signals, with the use of the inverse matrix of a transfer matrix of the neural network having learned under the preferable standard illuminant. The output of the converter is generated as a signal obtained after white balance adjusting.',\n",
       " 'A color correcting unit receives color separation values such as CMY values from an image input unit. Under the control of a control portion, inputs to a first conversion portion constituted by a neural network which has been trained in advance on the basis of the spectral distribution of an arbitrary illuminant are corrected so that outputs from the first conversion portion satisfy the color separation values and a predetermined requirement. The input values to the first conversion portion, which satisfy the predetermined requirement, are sent to an image output unit. The image output unit outputs an image in accordance with these input values.',\n",
       " 'A color correction apparatus for use in an apparatus such as a color copier for operating on data obtained by scanning and color analysis of a source image to obtain color density data for use in printing a copy of the source image, the correction apparatus containing a neural network. Parameter values of the neural network are established by repetitive computations based on amounts of difference between color density data previously used to print a plurality of color samples and color density data produced by the neural network in response to color analysis data obtained by analyzing these color samples.',\n",
       " 'A data compression and recovery apparatus compresses picture element data of a color image by expressing two primary color values of each picture element as a set of parameter values of a neural network in conjunction with reference color data values of a corresponding block of picture elements. Date recovery is achieved by inputting each block of reference color values to a neural network while establishing the corresponding set of parameter values in the network, to thereby obtain the original pair of encoded primary color values for each of successive picture elements. The third primary color can be used as the reference color.',\n",
       " 'The improved color image forming apparatus is so designed that the image forming condition computing means having a learning capability, such as a neural network having a back propagation learning algorithm, is caused to learn preliminarily those image forming conditions which are appropriate for the specific type of a documents (e.g. a reflection-type original or a transmission-type original such as a negative film or a reversal film) or the original image carried on the documents such as sea, mountains or a snow scene, examples of such image forming conditions being exposing conditions (e.g. the balance of three primary colors and their densities) and the conditions of developing, fixing and otherwise processing light-sensitive materials, and image is formed on a particular light-sensitive material under the image forming conditions computed by the computing means which has learned said appropriate conditions. The visible image reproduced with this apparatus always has a good color balance, is free from deterioration of image quality, has none of the unwanted color shades and is optimum for the particular document or original image. As a further advantage, even unskilled users can easily operate this apparatus to reproduce an image that meets the specific preference of the laboratory or the user.',\n",
       " 'A color image processing apparatus including a read device for reading an original image, a color correcting device for color-correcting input image data using a color-correcting neural network, and an output device for outputting color-corrected image data. The neural network with teacher data, which are in effect learning color data reflecting the visual characteristics of human eyes, using learning data produced by reading a copy image produced based on the learning color data. Accordingly, the neural network can correct colors accurately in a manner to fully reflect the visual characteristics of human eyes, thereby making the color difference between the original image and a copy of the same less noticeable.',\n",
       " 'A color separation section for converting colorimetric values into color separation values adopts a neural network. When a color image output device for outputting a color image on the basis of color separation value signals is used, the color image output device to be used outputs a standard color sample having known color separation values. The color sample is colorimetrically measured by a colorimetry device to obtain colorimetric values of the color sample. The neural network executes learning to have conversion characteristics for converting the colorimetric values into corresponding color separation values. An object to be reproduced which has a required color is colorimetrically measured by the colorimetry device. Colorimetric values obtained by the colorimetry processing are converted into color separation values using the neural network of the color separation section. The color image output device outputs a target color based on the converted color separation values.',\n",
       " 'Colorimetric values such as L*a*b* values are transformed into color separation values such as CMYK values dependent on the characteristics of a color output device by using a multilayered feedforward neural network. The neural network learns in advance the relationships between a multiplicity of colorimetric values under different illuminants and color separation values. When colorimetric values of a standard illuminant and one of the color temperature of an observational illuminant, the spectral distribution of the observational illuminant, and colorimetric values at the time of illumination by the observational illuminant are inputted to the neural network, color separation values corresponding to one of the color temperature of the observational illuminant, the spectral distribution of the observational illuminant, and the colorimetric values obtained when illumination is provided by the observational illuminant are outputted. Consequently, colorimetric values are transformed into color separation values such that the color reproduced under the observational illuminant will visually assume the same color as that under the standard illuminant.',\n",
       " 'A color management method/apparatus generates image color matching and International Color Consortium (ICC) color printer profiles using a reduced number of color patch measurements. Color printer characterization, and the generation of ICC profiles usually require a large number of measured data points or color patches and complex interpolation techniques. This invention provides an optimization method/apparatus for performing LAB to CMYK color space conversion, gamut mapping, and gray component replacement. A gamut trained network architecture performs LAB to CMYK color space conversion to generate a color profile lookup table for a color printer, or alternatively, to directly control the color printer in accordance with the a plurality of color patches that accurately. represent the gamut of the color printer. More specifically, a feed forward neural network is trained using an ANSI/IT-8 basic data set consisting of 182 data points or color patches, or using a lesser number of data points such as 150 or 101 data points when redundant data points within linear regions of the 182 data point set are removed. A 5-to-7 neuron neural network architecture is preferred to perform the LAB to CMYK color space conversion as the profile lookup table is built, or as the printer is directly controlled. For each CMYK signal, an ink optimization criteria is applied, to thereby control ink parameters such as the total quantity of ink in each CMYK ink printed pixel, and/or to control the total quantity of black ink in each CMYK ink printed pixel.',\n",
       " 'A color-recognition camera comprises a red-green-blue CCD-imaging device that provides an analog RGB-video signal. A set of three analog-to-digital converters convert the analog RGB-video signal into a digital RGB-video signal. A digital comparator tests the digital RGB-video signal pixel-by-pixel for a match against a color setpoint. If a match occurs, a pixel with a particular color represented by the color setpoint has been recognized and a &#8220;hit&#8221; is output. A pixel address counter provides a pixel address output each time a &#8220;hit&#8221; is registered. The number of hits per video frame are accumulated, and a color-match area magnitude value is output for each frame. Alternatively, neural networks are used to indicate hits when a pixel in the video image comes close enough to the color setpoint value. Just how close can be &#8220;learned&#8221; by the neural network.',\n",
       " 'To practice a method of transforming color sensation informations such that multidimensional physical informations and color sensation informations sensed by living bodies in response to the physical informations are non-linearly transformed therebetween, a multilayer feedforward type neural network is used for the purpose of accomplishing the foregoing transformation. The physical informations are provided in the form of data derived from multidimensional spectral distribution of light and the color sensation informations are provided in the form of sensitive colors each sensed by the living bodies as a psychological quantity relative to a certain color. An apparatus for carrying out the method includes an input section into which a physical quantity is inputted as an electrical signal, an information transforming section in which the inputted signal is transformed into a color sensation information representing psychological quantity of color and an output section from which the transformed color information is outputted. The information transforming section includes a multilayer feedforward type neural network.',\n",
       " 'A coloring device includes an image sampling device for sampling an input signal block representing a group of n.times.m pixels of a monochromatic image and for outputting first signals representing the sampled pixels of the input signal block of the monochromatic image; and artificial neural network, a connection for providing to the artificial neural network, substantially simultaneously, pattern information on patterns to be contained in the monochromatic image and color information on first data indicating colors given to the patterns indicated by the pattern information prior to generation of a color image signal, the artificial neural network having internal state parameters which are adaptively optimized by using a learning algorithm prior to the generation of a color image, the artificial neural network operating for receiving data representing the first signal, for determining which of colors preliminarily and respectively assigned to patterns to be contained in the group of pixels of the monochromatic image represented by the input signal block is given to a pattern actually contained in the group of pixels represented by the input signal block and for outputting second signals representing second data on three primary colors which are used to represent the determined colors given to the patterns actually contained in the group of pixels represented by the input signal block; and a color image storing device for receiving the second signals outputted from the artificial neural network, for storing the received second signals in locations thereof corresponding to the positions of the pixels represented by the input signal block and for outputting third signals representing the three primary color component images of the pixels represented by the input signal block; wherein the image sampling device further functions for scanning the whole of the monochromatic image by generating successive input signal blocks representing successive groups n.times.m pixels to be sampled, thereby outputting third signals for all pixels of the monochromatic image.',\n",
       " 'A combat pilot system for an aircraft comprises corresponding combat pilot devices 12, 12&#8242; provided in a runtime module 14 on board the aircraft and a ground-based system training module 16 respectively. The run-time module 12&#8242; is trained using model data generated simulation model 18 as well as feedback data from actual missile firings. The matrix of weights derived from the training routines are then programmed into the neural network in the corresponding combat pilot aid system 12 on board the aircraft so that the runtime module is capable of processing the input data producing the four parameters required for launch of a missile and also a FIRE/NO FIRE indication to the pilot.',\n",
       " 'By using the state transition of a highly interconnected neural network, in order to solve a combination problem, an energy function is set by the following procedure: (i) the energy function is set in correspondence to the size of the combination problem; (ii) the energy function is set for a combination problem to be solved by using an energy function which solved another combination problem of a different size from the combination problem to be solved. Also, in order to solve a problem involving the cutting out a specific image from a whole image, as a combination problem when obtaining pixels representing a contour of an object, the energy function is set by either (i) or (ii) above.',\n",
       " 'A technique for machine learning, such as supervised artificial neural network learning includes receiving data and checking the dimensionality of the read data and reducing the dimensionality to enhance machine learning performance using Principal Component Analysis methodology. The technique further includes specifying the neural network architecture and initializing weights to establish a connection between read data including the reduced dimensionality and the predicted values. The technique also includes performing supervised machine learning using the specified neural network architecture, initialized weights, and the read data including the reduced dimensionality to predict values. Predicted values are then compared to a normalized system error threshold value and the initialized weights are revised based on the outcome of the comparison to generate a learnt neural network having a reduced error in weight space. The learnt neural network is validated using known values and is then used for predicting values.',\n",
       " 'An analog-to-digital converter employs both flash and neural converters for converting an analog input voltage. The flash converter converts the higher-order bits in a single clock cycle. Values of the lower-order bits are determined by outputs from comparators with reference voltages provided by digital-to-analog converters. The D/A converters receive inputs from the flash converter as well as from those comparators which provide output results for higher-order bits. This interconnection of D/A converters and comparators thus forms a neural network for determining the value of the lower-order bits.',\n",
       " 'A neural network controller in parallel with a proportional-plus-integral (PI) feedback controller in a control system. At least one input port of the neural network for receiving an input signal representing a condition of a process is included. A first set of data is obtained that includes a plurality of output values of the neural network obtained during a training period thereof using a plurality of first inputs representing a plurality of conditions of the process. The process/plant condition signals generally define the process/plant, and may include one set-point as well as signals generated using measured systems variables/parameters. In operation, the neural network contributes to an output of the PI controller only upon detection of at least one triggering event, at which time a value of the first set of data corresponding with the condition deviation is added-in thus, contributing to the proportional-plus-integral feedback controller. The triggering event can be characterized as (a) a change in any one of the input signals greater-than a preselected amount, or (b) a detectable process condition deviation greater-than a preselected magnitude, for which an adjustment is needed to the process/plant being controlled. Also a method for controlling a process with a neural network controller operating in parallel with a IP controller is included.',\n",
       " 'A neural network has an array of interconnected processors, at least a first processor in the array operating in a pulse domain and at least a second processor in the array operating in a spike domain, and each said processor having: first inputs selectively coupled to other processors in the array of interconnected processors, each first input having an associated VCCS (a 1 bit DAC) coupled to a summing node, second inputs selectively coupled to inputs of the neural network, the second inputs having current generators associated therewith coupled to said summing node, a filter/integrator for generating an analog signal corresponding to current arriving at the summing node, and for processors operating in the pulse domain, an analog-to-pulse converter for converting an analog signal derived either directly from the filter/integrator or via a non-linear element, to the pulse domain, and providing the converted analog signal as an unquantized pulse domain signal at an output of each processor operating in the pulse domain and for processors operating in the spike domain, an analog-to-spike converter for converting an analog signal derived either directly from the filter/integrator or via a non-linear element, to the spike domain, and providing the converted analog signal as an unquantized spike domain signal at an output of each processor operating in the spike domain; wherein the array of interconnected processors are selectively interconnected with unquantized pulse domain and spike domain signals.',\n",
       " 'Various technologies and techniques are disclosed that improve handwriting recognition operations. Handwritten input is received in training mode and run through several base recognizers to generate several alternate lists. The alternate lists are unioned together into a combined alternate list. If the correct result is in the combined list, each correct/incorrect alternate pair is used to generate training patterns. The weights associated with the alternate pairs are stored. At runtime, the combined alternate list is generated just as training time. The trained comparator-net can be used to compare any two alternates in the combined list. A template matching base recognizer is used with one or more neural network base recognizers to improve recognition operations. The system provides comparator-net and reorder-net processes trained on print and cursive data, and ones that have been trained on cursive-only data. The respective comparator-net and reorder-net processes are used accordingly.',\n",
       " 'Various technologies and techniques are disclosed that improve handwriting recognition operations. Handwritten input is received in training mode and run through several base recognizers to generate several alternate lists. The alternate lists are unioned together into a combined alternate list. If the correct result is in the combined list, each correct/incorrect alternate pair is used to generate training patterns. The weights associated with the alternate pairs are stored. At runtime, the combined alternate list is generated just as training time. The trained comparator-net can be used to compare any two alternates in the combined list. A template matching base recognizer is used with one or more neural network base recognizers to improve recognition operations. The system provides comparator-net and reorder-net processes trained on print and cursive data, and ones that have been trained on cursive-only data. The respective comparator-net and reorder-net processes are used accordingly.',\n",
       " 'Described is a technology by which online recognition of handwritten input data is combined with offline recognition and processing to obtain a combined recognition result. In general, the combination improves overall recognition accuracy. In one aspect, online and offline recognition is separately performed to obtain online and offline character-level recognition scores for candidates (hypotheses). A statistical analysis-based combination algorithm, an AdaBoost algorithm, and/or a neural network-based combination may determine a combination function to combine the scores to produce a result set of one or more results. Online and offline radical-level recognition may be performed. For example, a HMM recognizer may generate online radical scores used to build a radical graph, which is then rescored using the offline radical recognition scores. Paths in the rescored graph are then searched to provide the combined recognition result, e.g., corresponding to the path with the highest score.',\n",
       " 'Described is a technology by which online recognition of handwritten input data is combined with offline recognition and processing to obtain a combined recognition result. In general, the combination improves overall recognition accuracy. In one aspect, online and offline recognition is separately performed to obtain online and offline character-level recognition scores for candidates (hypotheses). A statistical analysis-based combination algorithm, an AdaBoost algorithm, and/or a neural network-based combination may determine a combination function to combine the scores to produce a result set of one or more results. Online and offline radical-level recognition may be performed. For example, a HMM recognizer may generate online radical scores used to build a radical graph, which is then rescored using the offline radical recognition scores. Paths in the rescored graph are then searched to provide the combined recognition result, e.g., corresponding to the path with the highest score.',\n",
       " 'Described is a technology by which online recognition of handwritten input data is combined with offline recognition and processing to obtain a combined recognition result. In general, the combination improves overall recognition accuracy. In one aspect, online and offline recognition is separately performed to obtain online and offline character-level recognition scores for candidates (hypotheses). A statistical analysis-based combination algorithm, an AdaBoost algorithm, and/or a neural network-based combination may determine a combination function to combine the scores to produce a result set of one or more results. Online and offline radical-level recognition may be performed. For example, a HMM recognizer may generate online radical scores used to build a radical graph, which is then rescored using the offline radical recognition scores. Paths in the rescored graph are then searched to provide the combined recognition result, e.g., corresponding to the path with the highest score.',\n",
       " 'An apparatus for predicting and discriminating whether or not misfire, knocking and the like will occur from the cylinder pressure before the occurrence of the misfire, the knocking and the like by the use of a three layered neural network. The cylinder pressure signal detected by a cylinder pressure sensor is sampled and input to each of the elements of the input layer. The signal then is modulated corresponding to the strength (weight) of the connection between each of the elements, and transmitted to the hidden and output layers. The magnitude of signal from the elements of the output layer represents the prediction and discrimination results. The weight is learned and determined by a back propagation method.',\n",
       " \"The neural computing paradigm is characterized as a dynamic and highly computationally intensive system typically consisting of input weight multiplications, product summation, neural state calculations, and complete connectivity among the neurons. Herein is described neural network architecture for a Scalable Neural Array Process (SNAP) which uses a unique intercommunication scheme within an array structure that provides high performance for completely connected network models such as the Hopfield model. SNAP's packaging and expansion capabilities are addressed, demonstrating SNAP's scalability to larger networks. The array processor uses a special type of adder tree which computes in a first direction and communicates in a second direction. The adder tree is thus responsive to a compute state and a communication state. The adder tree has the ability to provide a first driver responsive to a compute state for communicating an adder output to a data path and a second driver responsive to the communication state for connecting the data path to the neuron inputs.\",\n",
       " \"To deal with user network communication activity which cannot easily and clearly be determined as problematic behavior, a behavior analysis apparatus 14 monitors communication between each user PC 16 in a domain 10 and Internet 20 via a gateway apparatus 12. For example, when there is a monitored item related to information leakage of the user in the detected communication, a weight value corresponding to the monitored item is added to a score concerning a possibility of the user leaking information. Subsequently, the scores are totaled and recorded for each unit of time. The behavior analysis apparatus 14 inputs data of time-series transition of the total value to a neural network which has performed learning for prediction processing, and predicts the possibility of the user's information leak at a time in the near future. When an increasing risk of leakage is predicted, the behavior analysis apparatus 14 communicates an alarm to a security manager.\",\n",
       " 'A compact dual function Random Number Generator and Stream Cipher Generator includes a Crypto-engine has a controller for controlling the engine to operate in one or other of its functions. The Crypto-engine incorporates a plurality of clipped Hopfield Neural Network pairs.',\n",
       " 'Disclosed are systems, apparatuses, and methods for implementing a competitive BCM learning rule used in a neural network. Such a method includes identifying a maximally responding neuron with respect to a feature of an input signal. The maximally responding neuron is the neuron in a group that has a response with respect to the feature of the input signal that is greater than a response of each other neuron in the group. Such a method also includes applying a learning rule to weaken the response of each other neuron with respect to the feature of the input signal. The learning rule may also strengthen the response of the maximally responding neuron with respect to the feature of the input signal.',\n",
       " 'A method of generating executable code for a target platform in a neural network includes receiving a spiking neural network description. The method also includes receiving platform-specific instructions for one or more target platforms. Further, the method includes, generating executable code for the target platform(s) based on the platform-specific instructions and the network description.',\n",
       " 'A component machine testing technique is provided that performs diagnostic analysis on a vibration signal of the component machine that has been separated from power and load machine background noise in a first neural network. The diagnostic analysis, with operator direction through an interactive interface, uses a second neural network in performing a series of diagnostic operations followed by archival of any experience acquired in the testing operation being performed. In the diagnostic analysis, both time based and frequency based vibration signal information from the component machine under test are used together through a simultaneous multiple display interactive interface under operator direction.',\n",
       " 'Disclosed are a component recognizing apparatus and a component recognizing method. The component recognizing apparatus includes: an image preprocessing unit configured to extract component edges from an input component image by using a plurality of edge detecting techniques, and detect a component region by using the extracted component edges; a feature extracting unit configured to extract a component feature from the detected component region, and create a feature vector by using the component feature; and a component recognizing unit configured to input the created feature vector to an artificial neural network which has learned in advance to recognize a component category through a plurality of component image samples, and recognize the component category according to a result.',\n",
       " 'Channel access delays and reception uncertainty are modeled as protocol-independent generic processes that are optimized for improved simulation performance. The generic process components are designed such that each different protocol can be modeled using an arrangement of these components that is specific to the protocol. In this way, speed and/or accuracy improvements to the generic process components are reflected in each of such protocol models. If an accurate analytic model is not available for the generic process component, a prediction engine, such as a neural network, is preferably used. The prediction engine is trained using the existing detailed models of network devices. Once trained, the prediction engine is used to model the generic process, and the protocol model that includes the generic component is used in lieu of the detailed models, thereby saving substantial processing time.',\n",
       " 'A method and apparatus for analysing a sample, in which a neural network is trained to correct for measurement drift of a given analytical instrument (e.g., a mass spectrometer). The training is carried out using first and second sets of data obtained by the instrument from samples of known compositions at initial and subsequent instants of time, respectively. The trained neural network is used to transform data, obtained by the instrument from a sample of unknown composition at said subsequent instant of time, to an estimate of the data which would have been obtained by the instrument from that sample at the initial instant of time. The transformed dasta is then analysed to analyse the sample of unknown composition.',\n",
       " \"A system and method for protecting identity fraud are disclosed. A system includes a detection subsystem to identify applications and/or accounts at risk of identity fraud, and a disposition subsystem to process data provided by the detection system and to determine whether identity fraud exists in the applications and/or accounts. According to an implementation, one or more neural network models are defined, each neural network model being configured to handle a class of cases related to the subject and a specific data configuration describing a case of the class. The one or more neural network models are run to generate data requests about the subject's identity, and the data requests are passed to a detection system that monitor transactions associated with the subject. Additional data associated with the transactions is requested until a threshold certainty is achieved or until available data or models are exhausted.\",\n",
       " \"A system and method for protecting identity fraud are disclosed. A system includes a detection subsystem to identify applications and/or accounts at risk of identity fraud, and a disposition subsystem to process data provided by the detection system and to determine whether identity fraud exists in the applications and/or accounts. According to an implementation, one or more neural network models are defined, each neural network model being configured to handle a class of cases related to the subject and a specific data configuration describing a case of the class. The one or more neural network models are run to generate data requests about the subject's identity, and the data requests are passed to a detection system that monitor transactions associated with the subject. Additional data associated with the transactions is requested until a threshold certainty is achieved or until available data or models are exhausted.\",\n",
       " \"A system and method for protecting identity fraud are disclosed. A system includes a detection subsystem to identify applications and/or accounts at risk of identity fraud, and a disposition subsystem to process data provided by the detection system and to determine whether identity fraud exists in the applications and/or accounts. According to an implementation, one or more neural network models are defined, each neural network model being configured to handle a class of cases related to the subject and a specific data configuration describing a case of the class. The one or more neural network models are run to generate data requests about the subject's identity, and the data requests are passed to a detection system that monitor transactions associated with the subject. Additional data associated with the transactions is requested until a threshold certainty is achieved or until available data or models are exhausted.\",\n",
       " 'A method is described for compressing the storage space required by HMM prototypes in an electronic memory. For this purpose prescribed HMM prototypes are mapped onto compressed HMM prototypes with the aid of a neural network (encoder). These can be stored with a smaller storage space than the uncompressed HMM prototypes. A second neural network (decoder) serves to reconstruct the HMM prototypes.',\n",
       " 'Preferred embodiments include systems with neural network processors (58) having input encoders (56) that encode integers as binary vectors so that close integers encode as close binary vectors by requiring adjacent integers have encoded binary vectors that differ in a fixed fraction of their bits.',\n",
       " 'A computational method for identifying adhesin and adhesin-like proteins, said method comprising steps of computing the sequence-based attributes of a neural network software wherein the attributes are (i) amino acid frequencies, (ii) multiplet frequency, (iii) dipeptide frequencies, (iv),charge composition, and (v) hydrophobic composition, training the artificial neural Network (ANN) for each of the computed five attributes, and identifying the adhesin and adhesin-like proteins having probability of being an adhesin (Pad) as ≧0.51; a computer system for performing the method; and genes and proteins encoding adhesin and adhesin-like proteins.',\n",
       " \"Computer aided diagnosis techniques in medical imaging are developed for the automated differentiation between benign and malignant lesions and go beyond computer aided detection by providing cancer likelihood for a detected lesion given image and/or patient characteristics. A computer aided detection and diagnosis algorithm for mammographic calcification clusters is developed and evaluated. The emphasis is on the diagnostic component although the algorithm includes automated detection, segmentation, and classification steps based on wavelet filters and artificial neural networks. Classification features are selected primarily from descriptors of the morphology of the individual calcifications and the distribution of the cluster as well as patient's demographics as input to the network. Te selected features are robust morphological and distributional descriptors, relatively insensitive to segmentation and detection errors such as false positive signals and variations among imaging sources or imaging equipment.\",\n",
       " 'The simultaneous multi access reasoning technology system of the present invention utilizes both existing knowledge and implicit information that can be numerically extracted from training data to provide a method and apparatus for diagnosing disease and treating a patient. This technology further comprises a system for receiving patient data from another location, analyzing the data in a trained neural network, producing a diagnostic value, and optionally transmitting the diagnostic value to another location.',\n",
       " 'The simultaneous multi access reasoning technology system of the present invention utilizes both existing knowledge and implicit information that can be numerically extracted from training data to provide a method and apparatus for diagnosing disease and treating a patient. This technology further comprises a system for receiving patient data from another location, analyzing the data in a trained neural network, producing a diagnostic value, and optionally transmitting the diagnostic value to another location.',\n",
       " 'The simultaneous multi access reasoning technology system of the present invention utilizes both existing knowledge and implicit information that can be numerically extracted from training data to provide a method and apparatus for diagnosing disease and treating a patient. This technology further comprises a system for receiving patient data from another location, analyzing the data in a trained neural network, producing a diagnostic value, and optionally transmitting the diagnostic value to another location.',\n",
       " 'An intrusion detection system (IDS) that uses application monitors for detecting application-based attacks against computer systems. The IDS implements application monitors in the form of a software program to learn and monitor the behavior of system programs in order to detect attacks against computer hosts. The application monitors implement machine learning algorithms to provide a mechanism for learning from previously observed behavior in order to recognize future attacks that it has not seen before. The application monitors include temporal locality algorithms to increased the accuracy of the IDS. The IDS of the present invention may comprise a string-matching program, a neural network, or a time series prediction algorithm for learning normal application behavior and for detecting anomalies.',\n",
       " 'The present invention relates to automatic modeling of a physical scene. At least two images (I1, I2) of the scene are received, which are taken from different angles and/or positions. A matching module (130) matches image objects in the first image (I1) against image objects in the second image (I2), by first loading pixel values for at least one first portion of the first image (I1) into an artificial neural network (133). Then, the artificial neural network (133) scans the second image (I2) in search of pixels representing a respective second portion corresponding to each of the at least one first portion; determines a position of the respective second portion upon fulfillment of a match criterion; and produces a representative matching result (M12). Based on the matching result (M12), a first calculation module (140) calculates a fundamental matrix (F12), which defines a relationship between the first and second images (I1, I2). Based on the fundamental matrix (F12), in turn, a second calculation module (150) calculates a depth map (D12), which describes distance differences between a set of image points in the first image (I1) and a corresponding set of image points in the second image (I2). Finally, the depth map (D12) constitutes a basis for a synthetic model of the scene.',\n",
       " 'A computer neural network regulatory process control system and method allows for the elimination of a human operator from real time control of the process. The present invention operates in three modes: training, operation (prediction), and retraining. In the training mode, training input data is produced by the control adjustment made to the process by the human operator. The neural network of the present invention is trained by producing output data using input data for prediction. The output data is compared with the training input data to produce error data, which is used to adjust the weight(s) of the neural network. When the error data is less than a preselected criterion, training has been completed. In the operation mode, the neutral network of the present invention provides output data based upon predictions using the input data. The output data is used to control a state of the process via an actuator. In the retraining mode, retraining data is supplied by monitoring the supplemental actions of the human operator. The retraining data is used by the neural network for adjusting the weight(s) of the neural network.',\n",
       " 'A neural network for adjusting a setpoint in process control replaces a human operator. The neural network operates in three modes: training, operation, and retraining. In operation, the neural network is trained using training input data along with input data. The input data is from the sensor(s) monitoring the process. The input data is used by the neural network to develop output data. The training input data are the setpoint adjustments made by a human operator. The output data is compared with the training input data to produce error data, which is used to adjust the weights of the neural network so as to train it. After training has been completed, the neural network enters the operation mode. In this mode, the present invention uses the input data to predict output data used to adjust the setpoint supplied to the regulatory controller. Thus, the operator is effectively replaced. The present invention in the retraining mode utilizes new training input data to retrain the neural network by adjusting the weight(s).',\n",
       " \"A computer system splits a data space to partition data between processors or processes. The data space may be split into sub-regions which need not be orthogonal to the axes defined by the data space's parameters, using a decision tree. The decision tree can have neural networks in each of its non-terminal nodes that are trained on, and are used to partition, training data. Each terminal, or leaf, node can have a hidden layer neural network trained on the training data that reaches the terminal node. The training of the non-terminal nodes' neural networks can be performed on one processor and the training of the leaf nodes' neural networks can be run on separate processors. Different target values can be used for the training of the networks of different non-terminal nodes. The non-terminal node networks may be hidden layer neural networks. Each non-terminal node automatically may send a desired ratio of the training records it receives to each of its child nodes, so the leaf node networks each receives approximately the same number of training records. The system may automatically configures the tree to have a number of leaf nodes equal to the number of separate processors available to train leaf node networks. After the non-terminal and leaf node networks have been trained, the records of a large data base can be passed through the tree for classification or for estimation of certain parameter values.\",\n",
       " \"A computer system splits a data space to partition data between processors or processes. The data space may be split into sub-regions which need not be orthogonal to the axes defined the data space's parameters, using a decision tree. The decision tree can have neural networks in each of its non-terminal nodes that are trained on, and are used to partition, training data. Each terminal, or leaf, node can have a hidden layer neural network trained on the training data that reaches the terminal node. The training of the non-terminal nodes' neural networks can be performed on one processor and the training of the leaf nodes' neural networks can be run on separate processors. Different target values can be used for the training of the networks of different non-terminal nodes. The non-terminal node networks may be hidden layer neural networks. Each non-terminal node automatically may send a desired ratio of the training records it receives to each of its child nodes, so the leaf node networks each receives approximately the same number of training records. The system may automatically configures the tree to have a number of leaf nodes equal to the number of separate processors available to train leaf node networks. After the non-terminal and leaf node networks have been trained, the records of a large data base can be passed through the tree for classification or for estimation of certain parameter values.\",\n",
       " 'A neural network based data comparison system compares data stored within a database against each other to determine duplicative, fraudulent, defective and/or irregular data. The system includes a database storing data therein, and a pattern database storing pattern data therein. The system further includes a data pattern build system, responsively connected to the database and to the pattern database. The data pattern build system retrieves the data from the database and generates the pattern data formatted in accordance a predetermined patten. The predetermined pattern includes an array having array locations corresponding to each character in a defined character set. The data pattern build system increments a value in each of the array locations responsive to the number of occurrences of each character in the data and stores the array as the pattern data in the pattern database. The comparison system also includes a neural network, responsively connected to the pattern database, which retrieves the pattern data stored therein and compares the pattern data to each other and determines responsive to the comparing when different pattern data match in accordance with predetermined criteria indicating that the different pattern data are duplicative, fraudulent, defective and/or irregular.',\n",
       " 'A neural network based data comparison system compares data stored within a database against each other to determine duplicative, fraudulent, defective and/or irregular data. The system includes a database storing data therein, and a pattern database storing pattern data therein. The system further includes a data pattern build system, responsively connected to the database and to the pattern database. The data pattern build system retrieves the data from the database and generates the pattern data formatted in accordance a predetermined patten. The predetermined pattern includes an array having array locations corresponding to each character in a defined character set. The data pattern build system increments a value in each of the array locations responsive to the number of occurrences of each character in the data and stores the array as the pattern data in the pattern database. The comparison system also includes a neural network, responsively connected to the pattern database, which retrieves the pattern data stored therein and compares the pattern data to each other and determines responsive to the comparing when different pattern data match in accordance with predetermined criteria indicating that the different pattern data are duplicative, fraudulent, defective and/or irregular.',\n",
       " 'A computing device, which may be implemented as an integrated circuit, is constructed of a microprocessor and one or more neural network co-processors. The microprocessor normally executes programs which transfer data to the neural network co-processors, which are used to compute complicated mathematical functions. Direct Memory Access (DMA) is also used to transfer data. Each neural network co-processor interfaces to the microprocessor in a manner substantially similar to that of a conventional memory device. The co-processor does not require any instructions and is configured to execute mathematical operations simply by being pre-loaded with gating functions and weight values. In addition, the co-processor executes a plurality of arithmetic operations in parallel, and the results of such operations are simply read from the co-processor.',\n",
       " 'A computing device, which may be implemented as an integrated circuit, is constructed of a microprocessor and one or more neural network co-processors. The microprocessor normally executes programs which transfer data to the neural network co-processors, which are used to compute complicated mathematical functions. Direct Memory Access (DMA) is also used to transfer data. Each neural network co-processor interfaces to the microprocessor in a manner substantially similar to that of a conventional memory device. The co-processor does not require any instructions and is configured to execute mathematical operations simply by being pre-loaded with gating functions and weight values. In addition, the co-processor executes a plurality of arithmetic operations in parallel, and the results of such operations are simply read from the co-processor.',\n",
       " 'A computerized method for the detection and characterization of disease in an image derived from a chest radiograph, wherein an image in the chest radiograph is processed to determine the ribcage boundary, including lung top edges, right and left ribcage edges, and right and left hemidiaphragm edges. Texture measures including RMS variations of pixel values within regions of interest are converted to relative exposures and corrected for system noise existing in the system used to produce the image. Texture and/or geometric pattern indices are produced. A histogram(s) of the produced index (indices) is produced and values of the histograms) are applied as inputs to a trained artificial neural network, which classifies the image as normal or abnormal. In one embodiment, obviously normal and obviously abnormal images are determined based on the ratio of abnormal regions of interest to the total number of regions of interest in a rule-based method, so that only difficult cases to diagnose are applied to the artificial neural network.',\n",
       " 'A computerized method for the detection and characterization of disease in an image derived from a chest radiograph, wherein an image in the chest radiograph is processed to determine the ribcage boundary, including lung top edges, right and left ribcage edges, and right and left hemidiaphragm edges. Texture measures including RMS variations of pixel values within regions of interest are converted to relative exposures and corrected for system noise existing in the system used to produce the image. Texture and/or geometric pattern indices are produced. A histogram(s) of the produced index (indices) is produced and values of the histogram(s) are applied as inputs to a trained artificial neural network, which classifies the image as normal or abnormal. In one embodiment, obviously normal and obviously abnormal images are determined based on the ratio of abnormal regions of interest to the total number of regions of interest in a rule-based method, so that only difficult cases to diagnose are applied to the artificial neural network.',\n",
       " \"A computer-based method and apparatus for classifying statement types using intonation analysis. The method and apparatus identify a user's potential query when the user responds to information during dialog with an automated dialog system. Pitch information is extracted, via a cepstrum, from the speech signal. In one embodiment, the pitch intonation is processed to form a smoothed pitch or intonation contour. Then the smoothed pitch contour is processed by a set of shape detectors and this output, together with statistical information, is sent to a rule-based algorithm which attempts to classify the statement type. In another embodiment, the smoothed pitch contour is processed by a pattern recognition system such as a neural network trained with a back-propagation learning algorithm.\",\n",
       " '\" A neural network system and method for diagnosing patients\\' medical conditions provide an efficient aid in identifying and interpreting factors which are significant in the medical diagnosis. The neural network is trained to recognize medical conditions by being provided with input data that is available for a number of patients, and diagnosis made by physicians in each case. Upon completion of the training period the neural network system uses input measurement and interview data to produce a score, or a graded classification, of a patient\\'s medical condition that is accompanied with a diagnosis interpretation. The interpretation is a sorted catalogue of individual factors and interactions that influenced the score. The interpretive facility of the present invention is based on comparison with a set of nominal values for each input factor or interaction. It can assist the physician in making a diagnosis of the patient\\'s condition and can further provide a \"\"second opinion\"\" that may confirm the physician\\'s findings or point to ambiguities that call for a more detailed analysis. \"',\n",
       " 'A deep tensor neural network (DTNN) is described herein, wherein the DTNN is suitable for employment in a computer-implemented recognition/classification system. Hidden layers in the DTNN comprise at least one projection layer, which includes a first subspace of hidden units and a second subspace of hidden units. The first subspace of hidden units receives a first nonlinear projection of input data to a projection layer and generates the first set of output data based at least in part thereon, and the second subspace of hidden units receives a second nonlinear projection of the input data to the projection layer and generates the second set of output data based at least in part thereon. A tensor layer, which can converted into a conventional layer of a DNN, generates the third set of output data based upon the first set of output data and the second set of output data.',\n",
       " \"A method and apparatus for color matching are provided, in which paint recipe neural networks are utilized. The color of a standard is expressed as color values. The neural network includes an input layer having nodes for receiving input data related to paint bases. Weighted connections connect to the nodes of the input layer and have coefficients for weighting the input data. An output layer having nodes are either directly or indirectly connected to the weighted connections and generates output data related to color values. The data to the input layer and the data from the output layer are interrelated through the neural network's nonlinear relationship. The paint color matching neural network can be used for, but not limited to, color formula correction, matching from scratch, effect pigment identification, selection of targets for color tools, searching existing formulas for the closest match, identification of formula mistakes, development of color tolerances and enhancing conversion routines.\",\n",
       " \"A method and apparatus for color matching are provided, in which paint recipe neural networks are utilized. The color of a standard is expressed as color values. The neural network includes an input layer having nodes for receiving input data related to paint bases. Weighted connections connect to the nodes of the input layer and have coefficients for weighting the input data. An output layer having nodes are either directly or indirectly connected to the weighted connections and generates output data related to color values. The data to the input layer and the data from the output layer are interrelated through the neural network's nonlinear relationship. The paint color matching neural network can be used for, but not limited to, color formula correction, matching from scratch, effect pigment identification, selection of targets for color tools, searching existing formulas for the closest match, identification of formula mistakes, development of color tolerances and enhancing conversion routines.\",\n",
       " 'Computer-implemented systems and methods for determining a subset of unknown targets to investigate. For example, a method can be configured to receive a target data set, wherein the target data set includes known targets and unknown targets. A supervised model such as a neural network model is generated using the known targets. The unknown targets are used with the neural network model to generate values for the unknown targets. Analysis with an unsupervised model is performed using the target data set in order to determine which of the unknown targets are outliers. A comparison of list of outlier unknown targets is performed with the values for the unknown targets that were generated by the neural network model. The subset of unknown targets to investigate is determined based upon the comparison.',\n",
       " 'Provide automatic assessment of oral recitations during computer based language assessments using a trained neural network to automate the scoring and feedback processes without human transcription and scoring input by automatically generating a score of a language assessment. Providing an automatic speech recognition (“ASR”) scoring system. Training multiple scoring reference vectors associated with multiple possible scores of an assessment, and receiving an acoustic language assessment response to an assessment item. Based on the acoustic language assessment automatically generating a transcription, and generating an individual word vector from the transcription. Generating an input vector by concatenating an individual word vector with a transcription feature vector, and supplying an input vector as input to a neural network. Generating an output vector based on weights of a neural network; and generating a score by comparing an output vector with scoring vectors.',\n",
       " 'A computerized system and method for estimating levels of obesity in an insured population using claims data. The model uses health risk assessment data comprising age, height, and weight information as well as information about health conditions and health behaviors for a member population. Claims data is used to train a two-stage model on the member population. The first stage comprises a support vector machine, a rule-based module, and a generalized linear model that estimates the probability of obesity. The second stage comprises a regression neural network that operates on the output of the first stage and a subset of the input feature vector. Cost and utilizations in these areas, along with overall health measures as well as demographics and social factors, are inputs to a set of pattern recognition engines that perform regression. The output is the estimated body mass index of the member.',\n",
       " 'Computing apparatus (e.g., a neural network) advantageously comprises a programmable resistor body comprising typically a multiplicity of resistors R.sub.ij. The resistance of any given R.sub.ij is changeable from a relatively high resistance to a lower resistance by application of an appropriate electrical signal, and can be reset to a higher resistance by application of an appropriate signal of reverse polarity. Exemplarily, a programmable resistor body comprises a thin layer of bismuth oxide or strontium barium niobate.',\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on computer storage media, for computing a layer output for a convolutional neural network layer, the method comprising: receiving the layer input, the layer input comprising a plurality of activation inputs, the plurality of activation inputs represented as a multi-dimensional matrix comprising a plurality of depth levels, each depth level being a respective matrix of distinct activation inputs from the plurality of activation inputs; sending each respective kernel matrix structure to a distinct cell along a first dimension of the systolic array; for each depth level, sending the respective matrix of distinct activation inputs to a distinct cell along a second dimension of the systolic array; causing the systolic array to generate an accumulated output from the respective matrices sent to the cells; and generating the layer output from the accumulated output.',\n",
       " 'A computing element for use in an array in a neural network. Each computing element has K (K>1) input signal terminals, K input backpropagated signal terminals, K output backpropagated signal terminals and at least one output terminal. The input terminals of the computing element located in row i, column j of the array of computing elements receive a sequence of concurrent input signals on K parallel input lines representing a parallel input signal S.sub.ij having vector elements (s.sub.ij1, s.sub.ij2, s.sub.ij3, . . . , s.sub.ijk).sup.T. The K input backpropagated signal terminals are coupled to receive an m-dimensional (m<K) backpropagated signal vector characterized to provide a measure of the performance error of the computing element. The computing element comprises a weighting function means responsive to the concurrent input signal S.sub.ij for computing a K-dimensional weighting coefficient and a scalar activation signal u.sub.ij by computing a K-dimensional weighting-coefficient vector, W.sub.ij =(w.sub.ij1, w.sub.ij2, . . . , w.sub.ijk).sup.T, and by forming the vector inner product of the input signal S.sub.ij vector elements and the weighting-coefficient vector, W.sub.ij. Feedback signals x.sub.ijk =w.sub.ijk *p.sub.ij are provided from the output backpropagated signal terminals where p.sub.ij provides a performance error of all columns of computing elements subsequent to this computing element weighted by the gain of the computing element. A nonlinear processor maps successive values of u.sub.ij through a nonlinear mapping function, M.sub.ij to provide a single-valued output signal y.sub.ij. The nonlinear processor responds to an m-dimensional backpropagated signal vector, X.sub.ij+1 =(x.sub.1,j+1,p ; x.sub.2,j+1,p ; x.sub.3,j+1,p ; . . . x.sub.m,j+1,p).sup.T characterized to provide a measure of the performance error of all computing elements subsequent to the computing element. Vector X.sub.i,j+1 comprises the pth member of all backpropagated error vectors from the computing elements of column j+1.',\n",
       " 'Disclosed is a method of estimating a property of an earth formation penetrated by a borehole. The method includes conveying a carrier through the borehole and performing a plurality of electrical measurements on the formation using a sensor disposed at the carrier and having a plurality of electrodes disposed in a concentric arrangement wherein a standoff distance between the sensor and a wall of the borehole has an influence on each electrical measurement in the plurality of electrical measurements. The method further includes determining an impedance for each electrical measurement in the plurality of electrical measurements and inputting the determined impedances into an artificial neural network implemented by a processor. The artificial neural network outputs the property wherein the outputted property compensates for the influence of sensor standoff distance on each electrical measurement in the plurality of electrical measurements.',\n",
       " 'Real-time condition-based analysis is performed on a machine for providing diagnostic and prognostic outputs indicative of machine status includes a signal processor for receiving signals from sensors adapted for measuring machine performance parameters. The signal processor conditions and shapes at least some of the received signals into an input form for a neural network. A fuzzy adaptive resonance theory neural network receives at least some of the conditioned and shaped signals, and detects and classifies a state of the machine based upon the received conditioned and shaped signals, and upon a predetermined ontology of machine states, diagnostics, and prognostics. The neural network can also determine from the machine state a health status thereof, which can comprise an anomaly, and output a signal representative of the determined health status. A Bayesian intelligence network receives the machine state from the neural network and determines a fault probability at a future time.',\n",
       " 'Apparatus and methods for conditional plasticity in a neural network. In one approach, conditional plasticity mechanism is configured to select alternate plasticity rules when performing connection updates. The selection mechanism is adapted based on a comparison of actual connection efficiency and target efficiency. For instance, when actual efficiency is below the target value, the STDP rule may be modulated to increase long term potentiation. Similarly, when actual efficiency is above the target value, the STDP rule may be modulated to increase long term connection depression. The conditional plasticity mechanism dynamically adjusts connection efficacy, and prevents uncontrolled increase of connection weights, thereby improving network operation when processing information of a varying nature.',\n",
       " 'A method for generating an improved estimate of horizontal conductivity, dip angle, azimuth and anisotropy parameter of an earth formation penetrated by a wellbore from dual-frequency transverse electromagnetic induction measurements, comprising generating an initial estimate of the horizontal conductivity, dip angle, azimuth and anisotropy parameter from the dual-frequency transverse induction measurements made at each one of a plurality of base frequencies. The initial estimates from each of the plurality of base frequencies are input into a primary trained neural network, and the improved estimate is calculated by the trained neural network. The network is trained by generating models of earth formations each having a known value of horizontal conductivity, anisotropy parameter, dip angle and azimuth. Voltages which would be measured by the transverse electromagnetic induction instrument in response to each model are synthesized. Initial estimates from the synthesized voltages are calculated and the initial estimates and known values from each of the models are input to the neural network to cause it to learn a relationship between the initial estimates and the known values.',\n",
       " 'The present invention relates to a method, a system, a neural network and a computer program product for determining the quality of an analytical process, preferably the confidence value. The analytical process is performed in a microchannel structure of a microfluidic device, from which data information of the analytic process is acquired by scanning at least one search area of the microchannel structure for signal data. The search area comprises the result of the analytical process and the acquired data information is stored as an image, one image for each scanned search area.',\n",
       " \"A neural network IC 31 includes n dedicated processing elements (PEs) 62, an output register 66 for storing the PEs' outputs so that they are immediately accessible to all of the PEs, a number of output circuits 78 that are connected to selected PEs to provide binary outputs, and a timing circuit 74. Each of the PEs includes a weight memory 90 for storing input, output and bias weight arrays, a first in first out (FIFO) memory 88 for storing input data, a dot product circuit 92 and an activation circuit 94. The dot product circuit computes a dot product of the input weight array and the contents of the FIFO memory, a dot product of the output weight array and the contents of the output register, a dot product of the bias value and a constant, and sums the three results. The activation circuit maps the output of the dot product circuit through an activation function to produce the PE's output. The inclusion of a memory 90 that stores both input and output weight arrays in conjunction with the output register 66 allows the PEs to be configured to implement arbitrary feed-forward and recurrent neural network architectures.\",\n",
       " 'A method of adapting a neural network of an automatic speech recognition device, includes the steps of: providing a neural network including an input stage, an intermediate stage and an output stage, the output stage outputting phoneme probabilities; providing a linear stage in the neural network; and training the linear stage by means of an adaptation set; wherein the step of providing the linear stage includes the step of providing the linear stage after the intermediate stage.',\n",
       " 'Various technologies described herein pertain to conservatively adapting a deep neural network (DNN) in a recognition system for a particular user or context. A DNN is employed to output a probability distribution over models of context-dependent units responsive to receipt of captured user input. The DNN is adapted for a particular user based upon the captured user input, wherein the adaption is undertaken conservatively such that a deviation between outputs of the adapted DNN and the unadapted DNN is constrained.',\n",
       " 'Embodiments of the invention relate to a neural network circuit comprising a memory block for maintaining neuronal data for multiple neurons, a scheduler for maintaining incoming firing events targeting the neurons, and a computational logic unit for updating the neuronal data for the neurons by processing the firing events. The network circuit further comprises at least one permutation logic unit enabling data exchange between the computational logic unit and at least one of the memory block and the scheduler. The network circuit further comprises a controller for controlling the computational logic unit, the memory block, the scheduler, and each permutation logic unit.',\n",
       " 'Embodiments of the invention relate to a neural network system comprising a single memory block for multiple neurosynaptic core modules. One embodiment comprises a neural network system including a memory array that maintains information for multiple neurosynaptic core modules. Each neurosynaptic core module comprises multiple neurons. The neural network system further comprises at least one logic circuit. Each logic circuit receives neuronal firing events targeting a neurosynaptic core module of the neural network system, and said logic circuit integrates the firing events received based on information maintained in said memory for said neurosynaptic core module.',\n",
       " 'Disclosed are systems, apparatuses, and methods for implementing a phase-model neural network using a fixed amount of memory. Such a phase-model neural network includes a plurality of neurons, wherein each neuron is associated with two parameters—an activity and a phase. Example methods include (i) generating a sequence of variables associated with a probability distribution of phases and (ii) sequentially sampling the probability distribution of phases using a fixed amount of memory, regardless of a number of phases used in the phase-model neural network.',\n",
       " 'A color management module which provides color values in a destination color space by interpolation of a LUT that maps from color values in a source color space to corresponding color values in the destination color space. The LUT includes cells corresponding to color values within a spectrum locus and color values outside the spectrum locus. The LUT is populated differently for cells within the spectrum locus and for those outside the spectrum locus. For cells within the spectrum locus, color values are calculated using a color transform constructed based on device profiles for the source device and for the destination device, and corresponding cells of the LUT are populated based on the calculated values. For cells outside of the spectrum locus, an artificial neural network is trained using the calculated color values, and the corresponding cells are populated based on outputs of the trained neural network.',\n",
       " 'The contamination level estimation method for high voltage insulators collects samples of naturally contaminated insulators and builds an image data set for the collected insulators. Flashover voltages of several insulators samples are measured. ESDD levels of the collected insulators are estimated. Images are input to image processing algorithms to extract representative features. The images are segmented. Transforming the image from RGB color space into grayscale model excludes the background from the image. Subsequently, the segmented images are transferred back to RGB color space model using matrix manipulation. Since contaminants on the insulator surface affect the color of the insulator, the segmented image is transformed from RGB to HSV color space which is used for extracting statistical and linear algebraic features from the hue image. A trained artificial neural network correlates the extracted features to the contamination levels enabling testing of other contaminated insulators.',\n",
       " 'The present disclosure relates to applying techniques similar to those used in neural network language modeling systems to a content recommendation system. For example, by associating consumed media content to words of a language model, the system may provide content predictions based on an ordering. Thus, the systems and techniques described herein may produce enhanced prediction results for recommending content (e.g. word) in a given sequence of consumed content. In addition, the system may account for additional user actions by representing particular actions as punctuation in the language model.',\n",
       " 'The present disclosure relates to applying techniques similar to those used in neural network language modeling systems to a content recommendation system. For example, by associating consumed media content to words of a language model, the system may provide content predictions based on an ordering. Thus, the systems and techniques described herein may produce enhanced prediction results for recommending content (e.g. word) in a given sequence of consumed content. In addition, the system may account for additional user actions by representing particular actions as punctuation in the language model.',\n",
       " 'A system and method for generating context vectors for use in storage and retrieval of documents and other information items. Context vectors represent conceptual relationships among information items by quantitative means. A neural network operates on a training corpus of records to develop relationship-based context vectors based on word proximity and co-importance using a technique of “windowed co-occurrence”. Relationships among context vectors are deterministic, so that a context vector set has one logical solution, although it may have a plurality of physical solutions. No human knowledge, thesaurus, synonym list, knowledge base, or conceptual hierarchy, is required. Summary vectors of records may be clustered to reduce searching time, by forming a tree of clustered nodes. Once the context vectors are determined, records may be retrieved using a query interface that allows a user to specify content terms, Boolean terms, and/or document feedback. The present invention further facilitates visualization of textual information by translating context vectors into visual and graphical representations. Thus, a user can explore visual representations of meaning, and can apply human visual pattern recognition skills to document searches.',\n",
       " 'A processing system receives an audio signal encoding a portion of an utterance. The processing system receives context information associated with the utterance, wherein the context information is not derived from the audio signal or any other audio signal. The processing system provides, as input to a neural network, data corresponding to the audio signal and the context information, and generates a transcription for the utterance based on at least an output of the neural network.',\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on computer storage media for modeling phonemes. One method includes receiving an acoustic sequence, the acoustic sequence representing an utterance, and the acoustic sequence comprising a respective acoustic feature representation at each of a plurality of time steps; for each of the plurality of time steps: processing the acoustic feature representation through each of one or more recurrent neural network layers to generate a recurrent output; processing the recurrent output using a softmax output layer to generate a set of scores, the set of scores comprising a respective score for each of a plurality of context dependent vocabulary phonemes, the score for each context dependent vocabulary phoneme representing a likelihood that the context dependent vocabulary phoneme represents the utterance at the time step; and determining, from the scores for the plurality of time steps, a context dependent phoneme representation of the sequence.',\n",
       " 'The technology described herein can be embodied in a method that includes receiving an audio signal encoding a portion of an utterance, and providing, to a first neural network, data corresponding to the audio signal. The method also includes generating, by a processor, data representing a transcription for the utterance based on an output of the first neural network. The first neural network is trained using features of multiple context-dependent states, the context-dependent states being derived from a plurality of context-independent states provided by a second neural network.',\n",
       " 'A search engine is described herein for providing search results based on a context in which a query has been submitted, as expressed by context information. The search engine operates by ranking a plurality of documents based on a consideration of the query, and based, in part, on a context concept vector and a plurality of document concept vectors, both generated using a deep learning model (such as a deep neural network). The context concept vector is formed by a projection of the context information into a semantic space using the deep learning model. Each document concept vector is formed by a projection of document information, associated with a particular document, into the same semantic space using the deep learning model. The ranking operates by favoring documents that are relevant to the context within the semantic space, and disfavoring documents that are not relevant to the context.',\n",
       " 'A cardiac catheter continuously monitors cardiac output within an artery. One temperature sensor measures native blood temperature within the artery, while another temperature sensor measures the temperature of a thermal coil which is in thermal contact with the blood stream. The temperature signals are provided as inputs to a monitoring system which includes isolators, filters, and data processing circuits. A temperature difference signal over time is generated between the native blood temperature and the thermal coil temperature. First and second derivatives are taken of the temperature difference signal and selected features are extracted from the three waveforms. The extracted features are used as to calculate cardiac output. In the present case, a neural network processor is utilized to provide accurate cardiac output measurements based upon the extracted features.',\n",
       " 'Certain aspects of the present disclosure provide methods and apparatus for a continuous-time neural network event-based simulation that includes a multi-dimensional multi-schedule architecture with ordered and unordered schedules and accelerators to provide for faster event sorting; and a formulation of modeling event operations as anticipating (the future) and advancing (update/jump ahead/catch up) rules or methods to provide a continuous-time neural network model. In this manner, the advantages include faster simulation of spiking neural networks (order(s) of magnitude); and a method for describing and modeling continuous time neurons, synapses, and general neural network behaviors.',\n",
       " 'An all-optical, continuous-time, recurrent neural network is disclosed which is capable of executing a broad class of energy-minimizing neural net algorithms. The network is a resonator which contains a saturable, two-beam amplifier; two volume holograms; and a linear, two-beam amplifier. The saturable amplifier permits, through the use of a spatially patterned signal beam, the realization of a two-dimensional optical neuron array; the two volume holograms provide adaptive, global network interconnectivity; and the linear amplifier supplies sufficient resonator gain to permit convergent operation of the network.',\n",
       " 'An all-optical, continuous-time, recurrent neural network is disclosed which is capable of executing a broad class of energy-minimizing neural net algorithms. The network is a resonator which contains a saturable, two-beam amplifier; two volume holograms; and a linear, two-beam amplifier. The saturable amplifier permits, through the use of a spatially patterned signal beam, the realization of a two-dimensional optical neuron array; the two volume holograms provide adaptive, global network interconnectivity; and the linear amplifier supplies sufficient resonator gain to permit convergent operation of the network.',\n",
       " 'A computer-based multi-layer artificial network named Continuous-weight neural network (CWNN) configured to receive an input feature set wherein the input feature set comprises a variable number of features is disclosed. A method for classifying input sets based on a trained CWNN is also disclosed. Various implementation examples are also provided.',\n",
       " 'A control system is provided to enable pavement line marking apparatus to refurbish old lines on a pavement surface. The control system has at least one old line detector adapted to scan a predetermined width of the pavement surface while being carried forwardly along the pavement. The old line detector is capable of recognizing old line pattern transition points as taught by a neural network and in response to such recognition, control activation of new line material applicators to repeat accurately said line pattern changes.',\n",
       " 'An adaptive feed forward control circuit and power supply for a television comprises a circuit for supplying energy from a source to a load, the load having energy requirements which vary in response to an input signal, for example a video signal. A feedback circuit generates a first correction signal indicative of a difference between an operating voltage or current level and a reference level. A neural network generates a second correction signal indicative of anticipated energy requirement variation by processing information in present values of the input signal. A control circuit, for example a pulse width modulating circuit, is responsive to the correction signals for controlling operation of the energy supplying circuit. The first and second correction signals are combined by a summing circuit. The neural network comprises a first signal adaptive circuit for the input signal and a second signal adaptive circuit for a processed version of the input signal. The processed input signal is linearly independent of the input signal to avoid redundancy in the weight factors. The square root of the input signal, for example, is appropriate for a switched mode power supply. The combination of outputs from the first and second signal adaptive circuits defines the second correction signal. A microprocessor can embody the neural network and provide the processed version of the input signal. The microprocessor can also embody the feedback circuit. The predictive correction signal can be adjusted responsive to the size and polarity of the energy requirement variation.',\n",
       " 'A control device for controlling the learning of a neural netowrk includes a monitor for monitoring weight values of synapse connections between units of the neural netowrk during learning of the neural network so as to update these weight values. When one of the weight values satisfies a preset condition, the weight value is updated to a predetermined value such that configuration of the neural network is determined in an optimum manner.',\n",
       " 'A control method of controlling a controlled system according to the invention comprises the first step of inputting a current and future target controlled variable to a first neural network model which performs learning using a past target controlled variable for the controlled system as an input signal and a past manipulated variable as a teacher signal, thereby obtaining a current virtual manipulated variable, the second step of causing a second neural network model, which have learnt to predict a behavior of the controlled system, to receive the virtual manipulated variable obtained in the first step and a controlled variable obtained from the controlled system at a current time, thereby obtaining a predicted controlled variable, the third step of obtaining an error of the predicted controlled variable obtained in the second step with respect to the target controlled variable, the fourth step of obtaining a correction amount for the virtual manipulated variable in accordance with a back propagation calculation of the second neural network model, using the error obtained in the third step, thereby correcting the virtual manipulated variable with the correction amount, and the fifth step of outputting the virtual manipulated variable corrected in the fourth step to the controlled system.',\n",
       " 'A neural network apparatus and method for use in applications such as in a voltage/reactive-power controller in which a neuro control-object simulator and a neuro controller pre-learn so as to make input-output relations of the controller match the input-output relations of a control unit and so as to make input-output relations of the simulator match input-output relations of a control object. The controller re-learns so as to make the output of the simulator match an input corresponding to a desired output of the control object. After re-learning, the controller controls the control-object.',\n",
       " 'A system for controlling operation of engine fuel injectors that includes a feed-forward control unit responsive to signals from sensors on the engine for supplying a basic electronic control signal for the injectors. A neural network is connected in parallel with the feed-forward control unit for receiving the sensor signals and multiplying the sensor signals by associated weighting factors. The sensor signals multiplied by the weighting factors are combined to produce a network output signal, which in turn is combined with the basic control signal from the feed-forward control unit to control operation of the fuel injectors. The weighting factors in the neural network are modified as a function of inputs from the engine sensors so as to reduce any errors in the sensor output signals as compared with desired values.',\n",
       " 'A process for induction hardening a part to a desired depth with an AC signal applied to the part from a closely coupled induction coil includes measuring the voltage of the AC signal at the coil and the current passing through the coil; and controlling the depth of hardening of the part from the measured voltage and current. The control system determines parameters of the part that are functions of applied voltage and current to the induction coil, and uses a neural network to control the application of the AC signal based on the detected functions for each part.',\n",
       " 'An integrated metrology and lithography/etch system and method (10) for micro-electronics device manufacturing. A process control neural network (30) is used to develop an estimated process control parameter (32) for controlling an etching process (28). The process control neural network is responsive to a multi-parameter characterization of a patterned resist feature MPC(PR) (16) developed on a substrate. The process control parameter is used as a feed-forward control for the etching process to develop an actual final mask feature. A multi-parameter characterization of the actual final mask feature MPC(HM) (36) is used as an input to a training neural network (40) for mapping to an ideal process control parameter. The ideal process control parameter is compared to the estimated control parameter to develop an error parameter (46), which is then used to train the process control neural network.',\n",
       " 'A feedback control system for automatic on-line training of a controller for a plant, the system having a reinforcement learning agent connected in parallel with the controller. The learning agent comprises an actor network and a critic network operatively arranged to carry out at least one sequence of a stability phase followed by a learning phase. During the stability phase, a multi-dimensional boundary of values is determined. During the learning phase, a plurality of updated weight values is generated in connection with the on-line training, if and until one of the updated weight values reaches the boundary, at which time a next sequence is carried out to determine a next multi-dimensional boundary of values followed by a next learning phase. Also, a method for automatic on-line training of a feedback controller within a system comprising the controller and a plant by employing a reinforcement learning agent comprising a neural network to carry out at least one sequence comprising a stability phase followed by a learning phase. Further included, a computer executable program code on a computer readable storage medium, for on-line training of a feedback controller within a system comprising the controller and a plant.',\n",
       " \"A total control system for an automotive vehicle assures vehicular behavior precisely following to a driver's demand for variation of driving environment and provide smooth transition in variation of the driving environment. The system includes a driving environment index predicting section predicting vehicular driving environment on the basis of a driving operation indicative amount, such as an accelerator depression magnitude, a brake depression magnitude, a steering angular position and so forth and a vehicular condition indicative amount, such as an engine speed, a vehicle speed, a longitudinal acceleration and so forth. Based on the driving environment index derived by the predicting section, local control channels of the automotive vehicle are controlled. The driving environment index predicting section predicts the driving environment index by neural network or so forth to transfer to the local control channels though a vehicular local area network or a common memory. Accordingly, variable control corresponding to the driving environment in the local control channels can be realized.\",\n",
       " 'A control system for an automatic transmission, which can easily achieve a variety of shift patterns according to the taste of a driver and the road conditions. The control system includes: a neural network; and a mode switch for selecting either a teaching mode or an automatic mode. The neural network learns in the teaching mode and neuro-computes to output a gear ratio in the automatic mode. Tolerance error is computed from at least one of a propriety of a teaching gear ratio, a compatibility of an input value and a compatibility of the teaching gear ratio. A learning pattern is produced during the teaching mode for correcting load factors of the neural network which, in the automatic mode, outputs a gear ratio used to determine shifting of the transmission.',\n",
       " 'A control system for a countercurrent pulp washing process in which the pulp is formed as a pulp mat on at least one moving filter surface and the mat is supplied with rinse water to replace water in the pulp mat thereby reducing the soda loss in the mat before it is removed from the filter surface. The process is characterized by at least one predictable process variable including dissolved solids retained in the pulp mat. The system comprises a trainable neural network having a plurality of input neurons having input values applied thereto and output neurons for providing output values and means for training the neural network to provide predicted values for the predictable process variables.',\n",
       " 'An improved arc furnace regulator employs neural circuits connected in a multi-layer network configuration with various weighted relationships between the successive layers which are automatically changed over time as a function of an error signal by means of the back-propagation method so that the regulator gradually improves its control algorithm as a result of accumulated experience. The network is implemented in software which can be developed and run on a PC with extra co-computing capability for greater execution speed. A second trainable neural network which emulates the arc furnace is used to develop the error signal, and is trained in mutually exclusive time periods with the training of the regular network.',\n",
       " 'An improved arc furnace regulator employs neural circuits connected in a multi-layer network configuration with various weighted relationships between the successive layers which are automatically changed over time as a function of an error signal by means of the back-propagation method so that the regulator gradually improves its control algorithm as a result of accumulated experience. The network is implemented in software which can be developed and run on a PC with extra co-computing capability for greater execution speed. A second trainable neural network which emulates the arc furnace is used to develop the error signal, and is trained in mutually exclusive time periods with the training of the regular network.',\n",
       " 'A control system for an internal combustion engine having an exhaust gas recirculation device for recirculating a part of exhaust gases to an intake system of the engine is disclosed. An estimated exhaust gas recirculation amount is calculated using a neural network to which at least one engine operating parameter indicative of an operating condition of the engine is input. The neural network outputs an estimated value of an amount of exhaust gases recirculated by the exhaust gas recirculation device. At least one engine control parameter for controlling the engine is calculated based on the estimated exhaust gas recirculation amount.',\n",
       " 'A control system for a plant e.g. as a non-linear system, which is capable of properly suppressing interaction occurring between a plurality of control inputs and a plurality of controlled variables, thereby making it possible to properly control the controlled variables and easily design the control system. In the control system, each of a plurality of interaction suppression parameters for correcting the control inputs, respectively, such that the interaction is suppressed is calculated using a neural network constructed by using, out of the plurality of control inputs, a control input other than a control input corrected by a calculated interaction suppression parameter, as an input, and the interaction suppression parameter as an output.',\n",
       " 'A control system having four major components: a target optimizer, a path optimizer, a neural network adaptation controller and a neural network. In the target optimizer, the controlled variables are optimized to provide the most economically desirable outputs, subject to operating constraints. Various manipulated variable and disturbance values are provided for modeling purposes. The neural network receives as inputs a plurality of settings for each manipulated and disturbance variable. For target optimization all the neural network input values are set equal to produce a steady state controlled variable value. The entire process is repeated with differing manipulated variable values until an optimal solution develops. The resulting target controlled and manipulated variable values are provided to the path optimizer to allow the manipulated variables to be adjusted to obtain the target output. Various manipulated variable values are developed to model moves from current to desired values. In this case trend indicating values of the manipulated and disturbance variables are provided to produce time varying values of the controlled variables. The process is repeated until an optimal path is obtained, at which time the manipulated variable values are applied to the actual process. On a periodic basis all of the disturbance, manipulated and controlled variables are sampled to find areas where the training of the neural network is sparse or where high dynamic conditions are indicated. These values are added to the set of values used to train the neural network.',\n",
       " 'A control system having four major components: a target optimizer, a path optimizer, a neural network adaptation controller and a neural network. In the target optimizer, the controlled variables are optimized to provide the most economically desirable outputs, subject to operating constraints. Various manipulated variable and disturbance values are provided for modeling purposes. The neural network receives as inputs a plurality of settings for each manipulated and disturbance variable. For target optimization all the neural network input values are set equal to produce a steady state controlled variable value. The entire process is repeated with differing manipulated variable values until an optimal solution develops. The resulting target controlled and manipulated variable values are provided to the path optimizer to allow the manipulated variables to be adjusted to obtain the target output. Various manipulated variable values are developed to model moves from current to desired values. In this case trend indicating values of the manipulated and disturbance variables are provided to produce time varying values of the controlled variables. The process is repeated until an optimal path is obtained, at which time the manipulated variable values are applied to the actual process. On a periodic basis all of the disturbance, manipulated and controlled variables are sampled to find areas where the training of the neural network is sparse or where high dynamic conditions are indicated. These values are added to the set of values used to train the neural network.',\n",
       " 'A neural network is trained with a general set of data to function as a general model of a machine or process with local condition inputs set equal to zero. The network is then retrained or receives additional training on an extentd data set containing the general set of data, characterized by zero values for the local condition inputs, and data on specific local conditions, characterized by non-zero values for the local condition inputs. The result is a trained neural network which functions as a general model when the inputs for the local conditions inputs are set equal to zero, and which functions as a model of some specific local condition when the local condition inputs match the encoding of the some local data set contained within the training data. The neural network has an architecture and a number of neurons such that its functioning as the local model is partially dependent upon its functioning as the general model. This trained neural network is combined with sensors, actuators, a control and communications computer and with a user interface to function as combine control system.',\n",
       " 'A control unit for an internal combustion engine that compensates for variations in injection valve flow rate characteristics by detecting an operation status of the engine and then using this status information to calculate a supply air amount or supply fuel amount in accordance with the detected status. Exhaust gas constituents are detected and then used to correct the calculated supply air or supply fuel amount. The control unit compares the exhaust gas constituents with predetermined values and then uses a neural network to control the supply air amount or supply fuel amount to make any deviation between the exhaust gas constituents and the predetermined value approach zero.',\n",
       " 'A system for tuning a process control loop includes a tuner module for receiving an error signal representative of the difference between a set point and a process variable, the module generating a first process control signal for controlling the process. The system further includes a controller module for receiving the error signal and a parameter signal from a nonlinear module to generate a second process control signal for controlling the process, wherein the nonlinear module applies a nonlinear procedure to generate the parameter signal. The system further includes a switching means coupled to the tuner module and the controller module to select the appropriate process control signal for controlling the process. The system provided uses nonlinear techniques in the nonlinear module to approximate the desired controller tuning parameters. The nonlinear techniques include neural network tuning, fuzzy logic tuning and nonlinear functions, including sigmoid tuning. A system also provides that the nonlinear module use nonlinear techniques to approximate the desired process model parameters. According to an embodiment of the present invention, the nonlinear module includes a process model identification module and a controller tuning module that provides controller parameters and model identification parameters using neural networks, fuzzy logic and nonlinear functions, including sigmoid tuning.',\n",
       " 'Control-type continuous ramp converting apparatus and method therefore. The present invention provides real-time processing of neurons in the neural network, easy implementation and reduction of manufacture cost of high density neurons in the neural network. The present invention comprises a first voltage controlling part for receiving a first voltage from an outside, and for non-linearly increasing a charged voltage in accordance with a differential continuous function of an exponential function; a second voltage controlling part for receiving a second voltage from an outside, and for non-linearly reducing a charged voltage in accordance with a differential continuous function of an exponential function; a charging part for charging an input current, and for providing the charged voltage of the charging part with the second voltage controlling part and an outside; and a plurality of switches for coupling outside and the first and the second voltage controlling part to the charging part, for selectively providing a third voltage from outside, an increased voltage and a decreased voltage based on the voltage of the charging part.',\n",
       " 'A controller for a plant that controls a controlled variable for the plant in accordance with estimated values, allowing to reduce any error in the estimated values that is caused by solid variation or aging of the plant. A controller for an exhaust emission control system has an estimated Inert-EGR value calculation section (711) to calculate the estimated value IEGRHAT for the Inert-EGR amount on the basis of an input vector U through a neural network, an estimated LAF sensor output value calculation section (712) to calculate the estimated value ΦHAT for an exhaust air-fuel ratio correlating with the Inert-EGR amount on the basis of the input vector U through the neural network, an LAF sensor (34) to detect the exhaust air-fuel ratio, and a nonlinear adaptive corrector (713) to calculate the adaptive input UVNS such that the estimated error EHAT between the detected value ΦACT from the LAF sensor (34) and the estimated output value ΦHAT of the LAF sensor (34) is minimized.',\n",
       " 'A gas turbine control system includes a controller that is coupled to actuator systems that govern operation of the gas turbine. The controller includes a processor for generating respective actuator control signals in correspondence with a plurality of turbine operating condition signals; the controller includes at least one neural network estimator that is trained to generate an estimated turbine operating condition signal. The neural network estimator typically has one or more hidden neuron layers that are coupled together in a feedforward structure, a recurrent neural network architecture. The estimated turbine operating condition signal generated by the neural network estimator typically, but not necessarily, represents a turbine internal cycle operating parameter for which the turbine has no corresponding operating parameter sensor.',\n",
       " 'A method for controlling a turbine is proposed, which is characterized at any point in the control by a hidden state. The dynamic behavior of the turbine is modeled with a recurrent neural network comprising a recurrent hidden layer. In this case, the recurrent hidden layer is formed from vectors of neurons, which describe the hidden state of the turbine at the time points of the regulation, wherein two vectors are chronologically linked for each time point with a first connection bridging a time and second connection bridging at least two points in time. Short-term effects can be controlled by means of the first connections and long-term effects can be adjusted by means of the second connections. Secondly, emissions and also occurring dynamics in the turbine can be minimized. Furthermore, a regulating device and a turbine with such a regulating device are proposed.',\n",
       " 'A flow of packets is communicated through a data center including an electrical switch, an optical switch, and multiple racks each including multiple network devices. The optical switch can be controlled to receive packet traffic from a network device via a first optical link and to output that packet traffic to another network device via a second optical link. One network device includes a neural network that analyzes received packets of the flow. The optical switch is controlled to switch based on a result of the analysis performed. In one instance, the optical switch is controlled such that immediately prior to the switching no packet traffic passes from the first optical link and through the optical switch and to the second optical link but such that after the switching packet traffic does pass from the first optical link and through the optical switch and to the second optical link.',\n",
       " \"A neural model for simulating a scorecard comprises a neural network for transforming one or more inputs into an output. Each input of the neural model has a squashing function applied thereto for simulating a bin of the simulated scorecard. The squashing function includes a control variable for controlling the steepness of the response to the squashing function's input so that during training of the neural model the steepness can be controlled. The output of the neural model represents the score of the simulated scorecard. The neural network is trained to behave like a scorecard by providing plurality of example values to the inputs of the neural network. Each output score produced is compared to an expected score to produce an error value. Each error value is back-propagated to adjust the neural network transformation to reduce the error value. The steepness of each squashing function is controlled using the respective control variable to affect the response of each squashing function.\",\n",
       " 'A convolutional neural network (CNN) for an image processing system comprises an image cache responsive to a request to read a block of N×M pixels extending from a specified location within an input map to provide a block of N×M pixels at an output port. A convolution engine reads blocks of pixels from the output port, combines blocks of pixels with a corresponding set of weights to provide a product, and subjects the product to an activation function to provide an output pixel value. The image cache comprises a plurality of interleaved memories capable of simultaneously providing the N×M pixels at the output port in a single clock cycle. A controller provides a set of weights to the convolution engine before processing an input map, causes the convolution engine to scan across the input map by incrementing a specified location for successive blocks of pixels and generates an output map within the image cache by writing output pixel values to successive locations within the image cache.',\n",
       " 'A convolutional neural network is trained to analyze input data in various different manners. The convolutional neural network includes multiple layers, one of which is a convolution layer that performs a convolution, for each of one or more filters in the convolution layer, of the filter over the input data. The convolution includes generation of an inner product based on the filter and the input data. Both the filter of the convolution layer and the input data are binarized, allowing the inner product to be computed using particular operations that are typically faster than multiplication of floating point values. The possible results for the convolution layer can optionally be pre-computed and stored in a look-up table. Thus, during operation of the convolutional neural network, rather than performing the convolution on the input data, the pre-computed result can be obtained from the look-up table.',\n",
       " 'Technical solutions are described for implementing a convolutional neural network (CNN) using resistive processing unit (RPU) array. An example method includes configuring an RPU array corresponding to a convolution layer in the CNN based on convolution kernels of the layer. The method further includes performing forward pass computations via the RPU array by transmitting voltage pulses corresponding to input data to the RPU array, and storing values corresponding to output currents from the RPU arrays as output maps. The method further includes performing backward pass computations via the RPU array by transmitting voltage pulses corresponding to error of the output maps, and storing the output currents from the RPU arrays as backward error maps. The method further includes performing update pass computations via the RPU array by transmitting voltage pulses corresponding to the input data of the convolution layer and the error of the output maps to the RPU array.',\n",
       " 'The present invention relates to a convolutional-neural-network-based classifier, a classifying method by using a convolutional-neural-network-based classifier and a method for training the convolutional-neural-network-based classifier. The convolutional-neural-network-based classifier comprises: a plurality of feature map layers, at least one feature map in at least one of the plurality of feature map layers being divided into a plurality of regions; and a plurality of convolutional templates corresponding to the plurality of regions respectively, each of the convolutional templates being used for obtaining a response value of a neuron in the corresponding region.',\n",
       " 'A method includes, based on a fitness function, selecting a subset of models from a plurality of models. The plurality of models is generated based on a genetic algorithm and corresponds to a first epoch of the genetic algorithm. Each of the plurality of models includes data representative of a neural network. The method also includes performing at least one genetic operation of the genetic algorithm with respect to at least one model of the subset to generate a trainable model and sending the trainable model to an optimization trainer. The method includes adding a trained model received from the optimization trainer as input to a second epoch of the genetic algorithm that is subsequent to the first epoch.',\n",
       " 'A corneal topography analysis system includes: an input unit for inputting corneal curvature data; and an analysis unit that determines plural indexes characterizing topography of the cornea based on the input corneal curvature data, the analysis unit further judges corneal topography from features inherent in predetermined classifications of corneal topography using the determined indexes and a neural network so as to judge at least one of normal cornea, myopic refractive surgery, hyperopic refractive surgery, corneal astigmatism, penetrating keratoplasty, keratoconus, keratoconus suspect, pellucid marginal degeneration, or other classification of corneal topography.',\n",
       " 'The present invention provides an interneuron crossrelation identification technique and an interneuron connection-structure estimation technique for inferring a connection-structure and the strengths of the connectivities among a plurality of neurons required for constructing a neural network model, by obtaining crossrelations among time-course data of neurons. The interneuron crossrelation detection technique may include steps of: calculating conditional probabilities by, among other things, normalizing crosscoincidence histograms calculated from time-course data of activities of the neurons representing a train of action potentials of the neurons representing a train of action potentials of the neurons, and comparing trains of symbols representing time-course states of the activities of the neurons; distinguishing an inhibitory connectivity form an excitatory connectivity by comparing the conditional probabilities to each other; and quantitatively estimating the magnitude of crossrelation among the time-course data. The interneuron connection-structure estimation technique may include steps of: computing conditional probabilities by normalizing cross-coincidence histograms calculated from time-course data of activities of the neurons representing a train of action potentials of the neurons; computing conditional mutual information and three-point mutual information from the computed conditional probabilities; and inferring a connection structure among the neurons.',\n",
       " 'Embodiments of the invention relate to a function-level simulator for modeling a neurosynaptic chip. One embodiment comprises simulating a neural network using an object-oriented framework including a plurality of object-oriented classes. Each class corresponds to a component of a neural network. Running a simulation model of the neural network includes instantiating multiple simulation objects from the classes. Each simulation object is an instance of one of the classes.',\n",
       " 'A cortronic neural network defines connections between neurons in a number of regions using target lists, which identify the output connections of each neuron and the connection strength. Neurons are preferably sparsely interconnected between regions. Training of connection weights employs a three stage process, which involves computation of the contribution to the input intensity of each neuron by every currently active neuron, a competition process that determines the next set of active neurons based on their current input intensity, and a weight adjustment process that updates and normalizes the connection weights based on which neurons won the competition process, and their connectivity with other winning neurons.',\n",
       " 'A system and method is disclosed for a countermeasure threat emulator (CME) provided in a tubular housing that may be launched from a submarine or ship. The CME electronics include a CPU board for running software, communicating with a computer external to the housing and data recording. The external computer preferably incorporates a database having data representative of a plurality of both foreign and domestic countermeasures. The data may be downloaded to the CPU board as well as updated for reprogramming of the CPU board. A digital signal processing board utilizes a plurality of DSP processors for running software capable of producing a wide range of acoustic signal outputs. A neural network may be used for analyzing and identifying acoustic sounds from incoming threats and notifying the CPU board for selection of a preprogrammed response for transmission by a transducer stack.',\n",
       " 'A neural network device includes internal data input lines, internal data output lines, coupling elements provided at the connections of the internal data input lines and the internal data output lines, word lines each for selecting one row of coupling elements. The coupling elements couple, with specific programmable coupling strengths, the associated internal data input lines to the associated internal data output lines. In a program mode, the internal data output lines serve as signal lines for transmitting the coupling strength information. Each of the coupling elements includes memories constituted of cross-coupled inverters for storing the coupling strength information, first switching transistors responsive to signal potentials on associated word lines for connecting the memories to associated internal data output lines, second switching elements responsive to signal potentials on associated internal data input lines for transmitting the storage information in the memories to the associated internal data output lines. Each of the internal data output lines has a pair of first and second internal data output lines.',\n",
       " 'A neural network device includes internal data input lines, internal data output lines, coupling elements provided at the connections of the internal data input lines and the internal data output lines. The coupling elements couple, with specific programmable coupling strengths, the associated internal data input lines to the associated internal data output lines. In a program mode, the internal data output lines serve as signal lines for transmitting the coupling strength information. Each of the coupling elements includes storage elements, circuitry for writing a signal potential on an associated internal data output line, and circuitry for supplying a stored signal for a storage element into an associated internal data output line.',\n",
       " 'A method for facilitating the avoidance of a vehicle collision with an object includes the following steps: a) providing a neural network, b) evolving a good driver, c) evolving a crash predictor, and d) outputting a graded warning signal.',\n",
       " \"A method for automatic generation of a Neuro-Fuzzy Expert System (Fuzzy Logic Expert System implemented as a Neural Network) from data. The method comprising a Data Interface allowing description of location, type, and structure of the Data. The Interface also allows designation of input attributes and output attributes in the Data Structure; automatic Neuro-Fuzzy Expert System generation driven by the Data; Training of the Expert System's Neural Network on the Data and the presentation of results which include new knowledge embedded in the parameters and structure of the trained Neuro-Fuzzy Expert System to a user.\",\n",
       " 'Estimation sections which have beforehand learned a relationship between known connection data pertaining to connection design and unknown connection data pertaining to connection design for the known connection data estimate the unknown connection data for the known connection data in accordance wit an input of the known connection data, on the basis of the result of learning. The respective estimation sections are formed from a multilayer feedforward neural network in which layers constituted of a plurality of neurons are coupled together in a direction in which the layer runs from an input layer to an output layer by way of an intermediate layer.',\n",
       " 'A method includes receiving, at a processor, a first data stream from a first platform and a second data stream from a second platform. The first data stream includes content and the second data stream includes the content. The method also includes performing an analysis operation on the first data stream and the second data stream to interpret the content. Performing the analysis operation includes performing a statistical analysis on the first data stream and the second data stream using one or more Artificial Neural Network (ANN) nodes of an analytical network. Performing the analysis operation also includes performing a syntactic analysis on the first data stream and the second data stream using one or more Markov Logic Network (MLN) nodes of the analytical network.',\n",
       " 'Embodiments of a computer-implemented method for training a convolutional neural network (CNN) that is pre-trained using a set of color images are disclosed. The method comprises receiving a training dataset including multiple multidimensional images, each multidimensional image including a color image and a depth image; performing a fine-tuning of the pre-trained CNN using the depth image for each of the plurality of multidimensional images; obtaining a depth CNN based on the pre-trained CNN, wherein the depth CNN is associated with a first set of parameters; replicating the depth CNN to obtain a duplicate depth CNN being initialized with the first set of parameters; and obtaining a depth-enhanced color CNN based on the duplicate depth CNN being fine-tuned using the color image for each of the plurality of multidimensional images, wherein the depth-enhanced color CNN is associated with a second set of parameters.',\n",
       " 'A crystal lookup table used to define a matching relationship between a signal position of a detected event in a PET scanner and a corresponding detector pixel location is generated using a neural network-based algorithm, and is implemented by a FPGA.',\n",
       " 'A method and apparatus of correcting for saturation in a current transformer, which outputs a current measurement, is provided. A switching algorithm receives a value of the current measurement from the current transformer and determines within which of three ranges the value falls. If the value falls in a first range, the current measurement is provided to a protective device such as a relay. If the value falls in a second range, the current measurement is provided to an artificial neural network that produces an output that accounts for saturation of the current transformer. If the value falls in a third range, the current measurement is provided to another artificial neural network that produces an output that accounts for saturation of the current transformer.',\n",
       " 'A current-mode Hamming neural network is provided with N binary inputs, and has a template matching calculation subnet and a winner-take-all subnet. The template matching calculation subnet includes M first neurons in which M exemplar templates are stored respectively. Each first neuron is consisted of current mirrors connected to and controlled by the N binary inputs respectively, to generate a template matching current signal which is substantially proportional to the number of matched bits between the N binary inputs and the corresponding stored exemplar template. The winner-take-all subnet includes M second neurons, each including M transistors with their gate electrodes connected together to form a template competition node, their source electrodes connected to ground, and their drain electrodes connected to the template competition nodes respectively. The template competition nodes are coupled to and receive the template matching current signals respectively, so that the template competition node connecting with the largest template matching current signal is eventually at a relatively high voltage level, and the other template competition nodes are at a relatively low voltage level, after competition.',\n",
       " 'Methods and apparatus related to training speech recognition devices are presented. A computing device receives training samples for training a neural network to learn an acoustic speech model. A curriculum function for speech modeling can be determined. For each training sample of the training samples, a corresponding curriculum function value for the training sample can be determined using the curriculum function. The training samples can be ordered based on the corresponding curriculum function values. In some embodiments, the neural network can be trained utilizing the ordered training samples. The trained neural network can receive an input of a second plurality of samples corresponding to human speech, where the second plurality of samples differs from the training samples. In response to receiving the second plurality of samples, the trained neural network can generate a plurality of phones corresponding to the captured human speech.',\n",
       " '\" Each daisy chain circuit is serially connected to the two adjacent neuron circuits, so that all the neuron circuits form a chain. The daisy chain circuit distinguishes between the two possible states of the neuron circuit (engaged or free) and identifies the first free \"\"or ready to learn\"\" neuron circuit in the chain, based on the respective values of the input (DCI) and output (DCO) signals of the daisy chain circuit. The ready to learn neuron circuit is the only neuron circuit of the neural network having daisy chain input and output signals complementary to each other. The daisy chain circuit includes a 1-bit register (601) controlled by a store enable signal (ST) which is active at initialization or, during the learning phase when a new neuron circuit is engaged. At initialization, all the Daisy registers of the chain are forced to a first logic value. The DCI input of the first daisy chain circuit in the chain is connected to a second logic value, such that after initialization, it is the ready to learn neuron circuit. In the learning phase, the ready to learn neuron\\'s 1-bit daisy register contents are set to the second logic value by the store enable signal, it is said \"\"engaged\"\". As neurons are engaged, each subsequent neuron circuit in the chain then becomes the next ready to learn neuron circuit. \"',\n",
       " \"Surveillance platforms in airborne craft (8,10), land based vehicles (12), vessels at sea or fixed structures (14) detect dangers using conventional scanners and transmit information signals describing the dangers to a control center (2) which analyzes the data and determines the degree of danger and its geographic extent. The center generates a danger warning and emergency response including a danger index. The warning/response message identifies the degree of danger (danger index 144) and the GPS coordinates (142) of the impacted geographic area for a wide region or regions of the earth (FIGS. 2-6). A vulnerability index (FIG. 16) determined using neural networks (FIGS. 13-14) and fuzzy logic (FIGS. 15-20) enables a prioritized warning/response. The center broadcasts (18) the danger warning and emergency response (FIG. 9) to a large population of remotely located warning devices (11), such as a network of pagers each of which has a GPS receiver (6,28). The pagers compare the received danger coordinates with their own GPS coordinates and each pager determines the extent to which it is in danger. The warning device automatically issues a warning signal or signals, which may be audible, visual or vibratory, appropriate to the degree of danger. Emergency manned vehicles may also directly receive the broadcast warning/response and be immediately alerted to act appropriately relative to the degree of danger. One embodiment broadcasts (16) directly to home T.V.'s and radios (17) which have internal GPS receivers and which display/annunciate an emergency message customized to that receiver resulting from the internal comparison of the danger coordinates versus the local receiver coordinates.\",\n",
       " 'The present invention relates to the analysis of data to identify relationships between the input data and one or more conditions. One method of analyzing such data is by the use of neural networks which are non-linear statistical data modelling tools, the structure of which may be changed based on information that is passed through the network during a training phase. A known problem that affects neural networks is the issue of overtraining which arises in overcomplex or overspecified systems when the capacity of the network significantly exceeds the needed parameters. The present invention provides a method of analyzing data using a neural network with a constrained architecture that mitigates the problems associated with the prior art.',\n",
       " 'A data communication apparatus comprises: means for dividing data to be transmitted into a plurality of blocks and extracting the data from each block; a first multi-layered neural network of three or more layers which has weighting coefficients to output the same data as the input data for the data extracted from each block and which can output data from an intermediate layer; the transmission data extracted from each block being inputted to the first neural network and outputted from the intermediate layer; means for encoding the transmission data which is outputted from the intermediate layer of the first neural network and, thereafter, transmitting; means for receiving and decoding the transmitted data; a second multi-layered neural network of three or more layers which has the same weight coefficients as those of the first neural network and can input data from an intermediate layer; the decoded data of each block being inputted to the second neural network and outputted from an output layer; and means for restoring the data on the basis of the output data from the output layer of the second neural network.',\n",
       " 'The invention is embodied in an image data system including a lossy image compressor having an image compression ratio in excess of 10 for producing first compressed image data from an original image, the first compressed image data specifying a corresponding one of a set of predetermined images, apparatus for computing an difference between the original image and the predetermined image specified by the first compressed image data and a lossless image compressor for compressing at least the difference to produce second compressed image data.',\n",
       " 'A method and system for encoding an input signal for storage or transmission over a communications channel by transforming successive vectors of parameters of the input signal into a corresponding succession of index signals, each index signal being associated with a quantized vector that corresponds to an ordered set of values of the input signal parameters. Supplying the input vector and a set of distance parameters to an artificial neural network for causing the artificial neural network to produce at least one control output signal; providing a vector quantization system composed of: at least one table having a first plurality of storage locations, each storage location storing a representative vector and having an address represented by a respective index signal; and search means for comparing each representative vector with each input signal parameter value; applying the at least one control output signal to the vector quantization system for identifying a second plurality of the storage locations, which second plurality is a subset of the first plurality of storage locations; searching, in said search means, over the second plurality of storage locations to locate that storage location of the second plurality which most closely approximates the extracted features vector according to a criterion utilizing the set of distance parameters; and outputting the index of the storage location which is found to most closely approximate the input vector.',\n",
       " 'A system and method for performing Automatic Target Recognition by combining the outputs of several classifiers. In one embodiment, feature vectors are extracted from radar images and fed to three classifiers. The classifiers include a Gaussian mixture model neural network, a radial basis function neural network, and a vector quantization classifier. The class designations generated by the classifiers are combined in a weighted voting system, i.e., the mode of the weighted classification decisions is selected as the overall class designation of the target. A confidence metric may be formed from the extent to which the class designations of the several classifiers are the same. This system is also designed to handle unknown target types and subsequent re-integration at a later time, effectively, artificially and automatically increasing the training database size.',\n",
       " 'An information processing system and method forms a fast optimal or near optimal association based on satisfying global constraints expressed in an association matrix by simulating the behavior of a network of interconnected processing elements resembling neurons in a brain.',\n",
       " 'This invention provides a data processing apparatus which can store and recall more complicated time-series data than those processed in related art technologies. In the data processing apparatus, a recurrent neural network (RNN) of higher layer generates long-period parameter and supplies it to an input layer of RNN of lower layer via a computing block. The RNN uses this input as a parameter and computes short-period input.',\n",
       " 'Herein disclosed is a data processing system having a memory packaged therein for realizing a large-scale and high-speed parallel distributed processing and, especially, a data processing system for the neural network processing. The neural network processing system according to the present invention comprises: a memory circuit for storing neuron output values, connection weights, the desired values of outputs, and data necessary for learning; an input/output circuit for writing or reading data in or out of said memory circuit; a processing circuit for performing a processing for determining the neuron outputs such as the product, sum and nonlinear conversion of the data stored in said memory circuit, a comparison of the output value and its desired value, and a processing necessary for learning; and a control circuit for controlling the operations of said memory circuit, said input/output circuit and said processing circuit. The processing circuit is constructed to include at least one of an adder, a multiplier, a nonlinear transfer function circuit and a comparator so that at least a portion of the processing necessary for determining the neutron output values such as the product or sum may be accomplished in parallel. Moreover, these circuits are shared among a plurality of neutrons and are operated in a time sharing manner to determine the plural neuron output values. Still moreover, the aforementioned comparator compares the neuron output value determined and the desired value of the output in parallel.',\n",
       " 'A data processing device for selecting data words which are contained in a dictionary and which are nearest to a data word to be processed according to a correspondence criterion. The device includes: first apparatus for segmenting the space enclosing the assembly of data words of the dictionary; second apparatus for generating, for each segment, sub-dictionaries by making an arbitrary segment correspond, in accordance with the correspondence criterion, to words of a sub-dictionary; third apparatus for utilising the sub-dictionaries by determining, for an arbitrary data word to be processed, the segment with which it is associated, followed by determination, in accordance with the correspondence criterion, of that word or words among the words of the sub-dictionary associated with the segment which corresponds (correspond) best to the arbitrary data word to be processed. Segmentation can be realised by means of a layered or tree-like neural network. The device may be used for data compression or data classification.',\n",
       " 'An output layer in a layered neural network uses a linear function or a designated region (linear region) of a threshold function instead of the threshold function to convert an input signal to an analog output signal When the basic unit uses the linear function, a limiter for limiting the output to a region between 1.0 and 0. When the basic unit uses the designated linear region of the threshold function, a limiter limits the output to a region between 0.8 and 0.2. Upon a learning operation, the error propagation coefficient is determined as a constant value such as 1/6 and when the majority of the desired values are 1 or near 1, an error value regarding the opposite desired value 0 is amplified, and when the output values become equal to or more than 1, it is deemed that there is no error with regard to the output of more than 1 in case of many outputs 1, thereby speeding up an operation of updating the weight.',\n",
       " 'A data processing system of the neural network type. The system recognizes a predetermined shape by providing some connections that are inhibitory between a plurality of neurons in a neural layer of the neural network. If data is found in the inhibitory area, it makes it harder for the neurons in the correct area to fire. Only when the neurons in the correct area fire is the predetermined shape recognized.',\n",
       " 'Data processing system implementing architecture of a neural network which is subject to a learning process, wherein the data processing system includes n.times.n synapses arranged in an array of j rows and i columns. A plurality of operational amplifiers respectively corresponding to the rows of the array are provided, with each operational amplifier defining a neuron. The input terminals of all of the synapses arranged in a respective column of the array are connected together and define n inputs of the neural network. The output terminals of the synapses arranged in a respective row of the array are connected together and serve as the inputs to a corresponding one of the plurality of operational amplifiers. Each synapse includes a capacitor connected between ground potential and the input terminal for weighting the synapse by storing a weighting voltage applied thereto. A random access memory has digitally stored voltage values for weighting all of the synapses. A plurality of digital-analog converters, one for each column of the array of synapses, are connected to the random access memory for converting the digital voltage values for weighting the synapses into analog voltage values. The digital-analog converters provide respective outputs to the weighting terminals of the synapses of a column via respective electronic switches for each synapse. Each row of the array includes a bistable circuit for driving the respective electronic switches under the control of a control section which also provides function commands and data to the random access memory.',\n",
       " 'A data processing system comprising a plurality of neural layers characterized in that a part of neurons in one of the layers are connected to neurons in the following layer.',\n",
       " 'In a neural network which includes one input layer, one or more intermediate layers and one output layer, neural elements in the input layer and neural elements in the intermediate layer are divided into groups. Arithmetic operations representing the coupling between the neural elements of the input layer and the neural elements of the intermediate layer are put into table form.',\n",
       " 'In a neural network which includes one input layer, one or more intermediate layers and one output layer, neural elements in the input layer and neural elements in the intermediate layer are divided into groups. Arithmetic operations representing the coupling between the neural elements of the input layer and the neural elements of the intermediate layer are put into table form.',\n",
       " '\"A method of allocation a computer to service a request for a data set in a system having a plurality of computers. The method is implemented on a neural network having only an input layer having input nodes and an output layer having output nodes, where each output node is associated with a specific computer. Connecting the input nodes to the output nodes are weights w(j,k). The method includes the steps of receiving a request for data set “I” and inputting to the input layer a vector R(I)    \"',\n",
       " 'In a data storage system, a cache is managed by a predictive cache management engine that evaluates cache contents and purges entries unlikely to receive sufficient future cache hits. The engine includes a single output back propagation neural network that is trained in response to various event triggers. Accesses to stored datasets are logged in a data access log; conversely, log entries are removed according to a predefined expiration criteria. In response to access of a cached dataset or expiration of its log entry, the cache management engine prepares training data. This is achieved by determining characteristics of the dataset at various past times between the time of the access/expiration and a time of last access, and providing these characteristics and the times of access as input to train the neural network. As another part of training, the cache management engine provides the neural network with output representing the expiration or access of the dataset. According to a predefined schedule, the cache management engine operates the trained neural network to generate scores for cached datasets, these scores ranking the datasets relative to each other. According to this or a different schedule, the cache management engine reviews the scores, identifies one or more datasets with the least scores, and purges the identified datasets from the cache.',\n",
       " 'A synapse expressing unit includes a capacitor for storing a synapse load value information in a form of electric charges, and a refresh control circuit for remedying the change in the amount of the electric charges stored in the capacitor. The refresh control circuit includes a comparator for comparing a potential at an electrode of the capacitor and a reference potential, and a drive circuit responsive to the comparator for recovering the electric charges of the capacitor through charge pumping operation. The synapse load value information is refreshed, and therefore a neural network circuit device reliably operating for a long time duration is provided.',\n",
       " 'A data transmission method includes a step which modulates maximal-sequence codes which are phase shifted by different phase shift quantities based upon plural data for transmission, a step which then convolutes the modulated maximal-sequence codes to obtain transmission data, and afterwards, a step which receives the transmission data and obtains a cross-correlation of the transmission data with a maximal-sequence code which has been phase shifted by the same as the maximal-sequence code which corresponds to the data for transmission. A data transmission method also includes a step which modulates maximal-sequence codes which are phase shifted by different phase shift quantities based on plural data for transmission, then a step which convolutes the modulated maximal-sequence codes to obtain transmission data. The method previously obtains a time sequence code based on a weighting factor for all data and maximal-sequence codes which are phase shifted with corresponding phase shifting quantities, then obtains a cross-correlation of the transmission data and the time sequence code.',\n",
       " 'A query device scans radio frequencies for visible transmitting devices. The querying device receives at least a signal strength and identifier information associated with each of the transmitting devices. The list of visible devices is used to query a database containing location information for a plurality of visible devices. The list may be sent to a locationing system that may perform a location analysis on the resulting data to return a location to the query device. The weighted average of the locations returned in the database query may be computed to determine the location of the querying device, with the weight for each of the locations being the current signal strength detected by the querying device. Neural network analysis may also be used to determine the location of the querying device. Learning and seeding operations many also be used to populate the database with location information for transmitting devices.',\n",
       " 'A method for adapting a decision directed adaptive neural network (10). The method finds the best matches between a plurality of input data vectors (16) and an associated plurality of input portion of weight vectors. The input portion of the weight vectors are adapted. The identification codes (12) which represent the sequence of best matched weight vectors are stored in a memory (12) and the associated output portion of weight vectors (22) are output. A sequence of output portion of weight vectors (22) is matched with predetermined models (21). A sequence of labels (24) associated with the best matched model is stored which identifies the categories of match data. The labels (24) are sequentially combined with the identification codes (12) to build adaptation vectors. The adaptation vectors are then used to sequentially adapt the output portion of weight vectors (22).',\n",
       " 'A method for order prioritization includes calculating a cycle time for a product order of a plurality of product orders using an artificial neural network, determining a first order priority of the product order based on a priority index using an analytic hierarchy process, determining a second order priority of the product order based on event based simulation model, and determining a shipping date for the product order based on the second order priority. The artificial neural network calculates the cycle time based upon product order type and a plurality of component counts. The analytic hierarchy process determines a first order priority based upon a plurality of product order attributes. The simulation model determines a second order priority and completion time based upon the first order priority, product model, product type, a plurality of component counts, manufacturing capacity and inventory data, and production time data for historical product orders.',\n",
       " 'In an example embodiment, a deep convolutional neural network (DCNN) is created to assign a professionalism score to an input image. The professionalism score indicates a perceived professionalism of a subject of the input image. The DCNN is designed to automatically learn features of images relevant to the professionalism through a training process.',\n",
       " 'Automated feature construction for algorithm portfolios in machine learning is provided. A gray scale image is generated from a text representing a problem instance. The gray scale image is rescaled or reshaped to a predefined size that is smaller than an initial size of the gray scale image. The rescaled gray scale image represents features of the problem instance. The rescaled gray scale image is input as features to a machine learning-based convolutional neural network. Based on the rescaled gray scale image, the machine learning-based convolutional neural network is automatically trained to learn to automatically determine one or more problem solvers from a portfolio of problem solvers suited for solving the problem instance.',\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for providing a representation based on structured data in resources. The methods, systems, and apparatus include actions of receiving target acoustic features output from a neural network that has been trained to predict acoustic features given linguistic features. Additional actions include determining a distance between the target acoustic features and acoustic features of a stored acoustic sample. Further actions include selecting the acoustic sample to be used in speech synthesis based at least on the determined distance and synthesizing speech based on the selected acoustic sample.',\n",
       " 'Provided is a DNN learning method that can reduce DNN learning time using data belonging to a plurality of categories. The method includes the steps of training a language-independent sub-network 120 and language-dependent sub-networks 122 and 124 with training data of Japanese and English. This step includes: a first step of training a DNN obtained by connecting neurons in an output layer of the sub-network 120 with neurons in an input layer of sub-network 122 with Japanese training data; a step of forming a DNN by connecting the sub-network 124 in place of the sub-network 122 to the sub-network 120 and training it with English data; repeating these steps alternately until all training data ends; and after completion, separating the first sub-network 120 from other sub-networks and storing it as a category-independent sub-network in a storage medium.',\n",
       " 'A method and system for labeling a selected word of a sentence using a deep neural network includes, in one exemplary embodiment, determining an index term corresponding to each feature of the word, transforming the index term or terms of the word into a vector, and predicting a label for the word using the vector. The method and system, in another exemplary embodiment, includes determining, for each word in the sentence, an index term corresponding to each feature of the word, transforming the index term or terms of each word in the sentence into a vector, applying a convolution operation to the vector of the selected word and at least one of the vectors of the other words in the sentence, to transform the vectors into a matrix of vectors, each of the vectors in the matrix including a plurality of row values, constructing a single vector from the vectors in the matrix, and predicting a label for the selected word using the single vector.',\n",
       " 'The present embodiments relate to machine learning for multimodal image data. By way of introduction, the present embodiments described below include apparatuses and methods for learning a similarity metric using deep learning based techniques for multimodal medical images. A novel similarity metric for multi-modal images is provided using the corresponding states of pairs of image patches to generate a classification setting for each pair. The classification settings are used to train a deep neural network via supervised learning. A multi-modal stacked denoising auto encoder (SDAE) is used to pre-train the neural network. A continuous and smooth similarity metric is constructed based on the output of the neural network before activation in the last layer. The trained similarity metric may be used to improve the results of image fusion.',\n",
       " 'Deep-freezing apparatus for foodstuffs comprising a deep-freezing compartment, signal display means, sensor means adapted to detect the temperature inside the foodstuffs stored in said deep-freezing compartment, processing means for the signals generated by said sensor means, wherein the apparatus further comprises a neural network adapted to receive the signals issued by a temperature sensor situated inside the foodstuff being deep-frozen and by an information on the time elapsed from the beginning of the deep-freezing process, and further adapted to provide a signal representative of the residual time needed to reach a pre-set (deep-freezing) temperature, as well as processing means adapted to receive the signal output by said neural network and provide in response an information representative of the predicted time needed for a pre-determined temperature to be reached on said first temperature sensor.',\n",
       " 'A defect inspection apparatus for inspecting a presence of a defect on an object includes: a first input unit which inputs wavelength characteristics of each of a plurality of samples with wavelength variation of an illumination light for inspection; a second input unit which inputs inspection conditions which an inspector sets for each of the samples as a teaching signal; a third input unit which inputs a wavelength characteristic of the object with the wavelength variation of the illumination light; a neural network which learns and stores a relationship between the inputted wavelength characteristic of each sample and the inputted inspection condition for each sample, and determines an inspection condition for the object based on the inputted wavelength characteristic of the object and the learned relationship; and a defect detector which detects a defect of the object based on the determined inspection condition of the object.',\n",
       " 'A defrost control apparatus for refrigerator includes a microcomputer which counts the number of opening/closing times of a door of a storage room for each of time zones within a day so as to set indexes for every time zones on the basis of the number of opening/closing times. The microcomputer also counts operating hours of a compressor and total elapsed hours, and determines a sudden phenomenon and a season. The microcomputer further selectively fetches the indexes, and generates a single index by joining a plurality of indexes so as to apply the same to a neural network included in a defrost signal generating unit. The neural network generates a defrost on/off signal on the basis of inputted data. In addition, if feature amounts are generated on the basis of the indexes by a feature detecting unit, the neural network generates the defrost on/off signal on the basis of the feature amounts.',\n",
       " \"A method and a system for forecasting the demand agreeing with the fluctuation trend of sales results at high and stable precision, without requiring user's maintenance, by using a model optimum for grasping the fluctuation trend of sales results, even if the products are diverse, by storing a plurality of models of neural network, for example, a model for forecasting the demand from data of the past several months, a model for forecasting the demand from data of the same period of the previous year, and a model for forecasting the demand from both the latest data and data of the same period of the previous year, and also by feeding sales results into a model of neural network to make it learn by the short period such as by the week, and a recording medium in which is recorded such program.\",\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on computer storage media, for depth concatenation using a matrix computation unit. One of the methods includes: receiving a request to process network inputs to a neural network using an integrated circuit, the neural network comprising a depth concatenation neural network layer; and generating instructions that, when executed by the integrated circuit, cause the integrated circuit to performing operations comprising: for each spatial location in a first input tensor to the depth concatenation layer and a second input tensor to the depth concatenation layer: multiplying, using the matrix computation unit, a second depth vector for the spatial location by a shift weight matrix for the depth concatenation layer to generate a shifted second depth vector; and adding the shifted second depth vector and a first input depth vector for the spatial location to generate a concatenated depth vector.',\n",
       " 'Method for determining an expected value for a proposed reconnaissance electromagnetic (or any other type of geophysical) survey using a user-controlled source. The method requires only available geologic and economic information about the survey region. A series of calibration surveys are simulated with an assortment of resistive targets consistent with the known information. The calibration surveys are used to train pattern recognition software to assess the economic potential from anomalous resistivity maps. The calibrated classifier is then used on further simulated surveys of the area to generate probabilities that can be used in Value of Information theory to predict an expected value of a survey of the same design as the simulated surveys. The calibrated classifier technique can also be used to interpret actual CSEM survey results for economic potential.',\n",
       " 'A system (10) testing and rating operation-dependent processes and/or components (20) in automated production and test sequences comprises a robot (12) which by means of a minimum of one sensor (14, 16) detects test/measured values (M) of at least one operating and/or display element (22, 24) of the component (20) to be tested respectively rated and transmits to an analyzer (40) analyzing and rating the measured values (M) by means of defined quality functions (50), said quality functions by means of operators (52) imitating human rating schematics respectively rules and based on this processing result generating at least one rating.',\n",
       " 'A method and system for detecting eye corners using neural network classifiers is described. After an eye image is received, the eye image may be processed by at least two neural network classifiers including an inner eye corner neural network classifier and an outer eye corner neural network classifier. The neural network classifiers provide periocular information including a distance or coordinates of an eye corner location from a center of an iris of the eye, and an outcome of whether the eye corner is an inner eye corner or an outer eye corner. Output from the various neural network classifiers are combined to generate a decision on the location of eye corners in an eye image.',\n",
       " \"An arrangement for the detection of fraudulent use of a telephone subscriber's instrument in a mobile telephone system includes an input preprocessor (110), a neural network engine (111) coupled to the preprocessor, and an output postprocessor (112) coupled to the neural network engine. The preprocessor determines for each subscriber a first long term calling profile, a second short term calling profile, and a subscriber profile pattern comprising the difference between the first and second profiles. Each calling profile and subscriber profile pattern comprises a set of values for a respective set of call attributes. The neural network engine comprises a self organizing map trained to effect pattern recognition of the subscriber profile patterns and a multilayer perceptron adapted to determine for each recognized pattern a value indicative of the probability of a fraud being associated with that pattern.\",\n",
       " 'The present invention extends to methods, systems, and computer program products for detecting, classifying, and tracking abnormal data in a data stream. Embodiments include an integrated set of algorithms that enable an analyst to detect, characterize, and track abnormalities in real-time data streams based upon historical data labeled as predominantly normal or abnormal. Embodiments of the invention can detect, identify relevant historical contextual similarity, and fuse unexpected and unknown abnormal signatures with other possibly related sensor and source information. The number, size, and connections of the neural networks all automatically adapted to the data. Further, adaption appropriately and automatically integrates unknown and known abnormal signature training within one neural network architecture solution automatically. Algorithms and neural networks architecture are data driven, resulting more affordable processing. Expert knowledge can be incorporated to enhance the process, but sufficient performance is achievable without any system domain or neural networks expertise.',\n",
       " 'Apparatus and methods are disclosed for generating and outputting physiological event results from physiological data related to a patient. Physiological event results include results predicting and/or detecting individual physiological events related to a medical condition of the patient.',\n",
       " 'A system for detecting fluid influxes and losses can include a sensor which detects floating vessel movement, and a neural network which receives a sensor output, and which outputs a predicted flow rate from a wellbore. A method can include isolating the wellbore from atmosphere with an annular sealing device which seals against a drill string, inputting to a neural network an output of a sensor which detects vessel movement, the neural network outputting a predicted flow rate from the wellbore, and determining whether the fluid influx or loss has occurred by comparing the predicted flow rate to an actual flow rate from the wellbore. Another method can include inputting to a neural network actual flow rates into and out of the wellbore, and an output of a sensor which detects vessel movement, and training the neural network to output a predicted flow rate from the wellbore.',\n",
       " 'A first image and a second image are provided to a trained neural network. The first image comprises one or more static features and the second image comprises at least one of the one or more static features. A static feature is identified in both the first and second images by a branch of the trained neural network. A three dimensional image comprising the identified static feature is generated and three dimensional geometric information/data related to the static feature is extracted and stored in association with a tile of a digital map. A set of training images may be used to train the trained neural network comprises training image subsets comprising two or more images that substantially overlap that were (a) captured at different times; (b) captured under different (i) weather conditions, (ii) lighting conditions, or (iii) weather and lighting conditions; or both a and b.',\n",
       " 'A method for detecting a psychological disorder in a person comprises collecting movement and, optionally, other data from the person by a device borne by the person; storing the data in a memory in contact with the device during the collection of data; transferring the stored data to a computer; calculating at least one set of parameter data distinctive of the movement data; feeding the least one set of parameter data to an Artificial Neural Network trained to recognize in the data a feature specific for a psychological disorder or a group of such disorders. Also is disclosed an assembly for carrying out the method.',\n",
       " 'A system and method is provided for monitoring the operating condition of a pump by evaluating fault data encoded in the instantaneous current of the motor driving the pump. The data is converted to a frequency spectrum which is analyzed to create a fault signature having fault attributes relating to various fault conditions associated with the pump. The fault signature is then input to a neural network that operates in conjunction with a preprocessing and post processing module to perform decisions and output those decisions to a user interface. A stand alone module is also provided that includes an adaptive preprocessing module, a one-shot unsupervised neural network and a fuzzy based expert system to provide a decision making module that operates with limited human supervision.',\n",
       " 'A system and method is provided for monitoring the operating condition of a pump by evaluating fault data encoded in the instantaneous current of the motor driving the pump. The data is converted to a frequency spectrum which is analyzed to create a fault signature having fault attributes relating to various fault conditions associated with the pump. The fault signature is then input to a neural network that operates in conjunction with a preprocessing and post processing module to perform decisions and output those decisions to a user interface. A stand alone module is also provided that includes an adaptive preprocessing module, a one-shot unsupervised neural network and a fuzzy based expert system to provide a decision making module that operates with limited human supervision.',\n",
       " 'A system and method is provided for monitoring the operating condition of a pump by evaluating fault data encoded in the instantaneous current of the motor driving the pump. The data is converted to a frequency spectrum which is analyzed to create a fault signature having fault attributes relating to various fault conditions associated with the pump. The fault signature is then input to a neural network that operates in conjunction with a preprocessing and post processing module to perform decisions and output those decisions to a user interface. A stand alone module is also provided that includes an adaptive preprocessing module, a one-shot unsupervised neural network and a fuzzy based expert system to provide a decision making module that operates with limited human supervision.',\n",
       " 'The overall invention categorizes patients with suspected acute myocardial infarction (AMI) with regard to a) AMI/non-AMI; b) infarct size (e.g. Major/Minor); c) time since onset of infarction; and d) non-AMI with/without minor myocardial damage (MMD). Generally, the above categorization is based on frequent timed blood sampling and measurement of selected biochemical markers of AMI with different rates of appearance in circulating blood. The computations are performed by using specially designed artificial neural networks. According to a first main aspect of the invention, early, i.e. generally within 3 hours from admission of the patient, detection/exclusion of acute myocardial infarction is provided. Furthermore, early prediction of the infarct size and early estimation of the time from onset are also provided.',\n",
       " 'A detector array method and apparatus for real time in-situ color control in printers and copiers includes an array for performing a linear matrix transformation on color patch information generated by a printer or copier. A light sensor array detects color components from a series of color test patches and performs a predetermined matrix transformation on the color information to produce a set of control signals for feedback to the printer or copier. In another embodiment, the light sensor array is extended to produce a fully analog neural network processor which is capable of arbitrary mappings of the color information into control signals for use by the printer or copier apparatus. The system is fully programmable, adaptive and, in one embodiment, trainable using backpropagation or other techniques.',\n",
       " 'Methods and systems are provided for analyzing a physiological signal by applying a continuous wavelet transform on the signal and comparing the wavelet transformation to a library of wavelet signatures corresponding to one or more physiological conditions and/or patient conditions. A pulse oximeter system may relate the wavelet transformation with one or more of the wavelet signatures based on filters and/or thresholds, and may determine that the wavelet transformation indicates that the patient of the physiological signal has a physiological condition indicated by the related wavelet signature. In some embodiments, the pulse oximeter system may use previous analyses in a neural network to update the library. Further, non-physiological components of the wavelet transformation may also be identified and removed.',\n",
       " 'The concentration of a substance, such as glucose, in a biological sample, such as human tissue (e.g. the skin of an index finger) is non-invasively determined by directing the output beam of a laser diode onto and into the skin so as to cause Raman scattering. The output of a charge coupled device, upon which the scattered light is spatially dispersed according to frequency is digitized and applied to a processor. The processor compares the Raman scattering intensity characteristics of the sample with a comparative model, in particular, an artificial neural network discriminator (ANND). The ANND is trained with a plurality of Raman spectral characteristics from biological fluids or tissue, possessing known Raman scattered light intensities versus wavelength characteristics at known concentrations. A preferred implementation of the ANND employs fuzzy adaptive resonance theory-mapping (ARTMAP), which has robust noise rejection capabilities and can readily handle nonlinear phenomena.',\n",
       " 'Font recognition and similarity determination techniques and systems are described. In a first example, localization techniques are described to train a model using machine learning (e.g., a convolutional neural network) using training images. The model is then used to localize text in a subsequently received image, and may do so automatically and without user intervention, e.g., without specifying any of the edges of a bounding box. In a second example, a deep neural network is directly learned as an embedding function of a model that is usable to determine font similarity. In a third example, techniques are described that leverage attributes described in metadata associated with fonts as part of font recognition and similarity determinations.',\n",
       " 'A method and apparatus for determining time-varying thresholds for measured metrics are provided. With the method and apparatus, values of a given metric are captured over time. The behavior of the metric is analyzed to determine its seasonality. Correlated historical values of the metric and additional related metrics (cross-correlation) are used as inputs to a feed-forward back propagation neural network, in order to train the network to generalize the behavior of the metric. From this generalized behavior, point-by-point threshold values are calculated. The metric is monitored and the monitored values are compared with the threshold values to determine if the metric has violated its normal time-varying behavior. If so, an event is generated to notify an administrator of the error condition.',\n",
       " 'Based on the encoding of deterministic finite-state automata (DFA) in discrete-time, second-order recurrent neural networks, an algorithm constructs an augmented recurrent neural network that encodes a FFA and recognizes a given fuzzy regular language with arbitrary accuracy.',\n",
       " 'Neural networks are used to classify objects automatically by means of Doppler-broadened radar echo signals. The classification device KK contains a neural network (NET, NET2) which has an input layer (IL) of input nodes (IN1, . . . , IN57) for features (M) of the Doppler-broadened radar echo signals, and an output layer (OL) of output nodes (ON1, ON2, ON3) for predetermined classes to which the objects can be allocated. The neural network (NET, NET2) is adapted to the external conditions prevailing at the time of the classification operation. The adaptation takes place either via accessible input nodes (ZN1, ZN2) into which control information (SI) can be entered, and which cause the neural network (NET) to adapt to one or to several external influence factors, or via a selection device (SEL) which, from the parameters (P1, . . . , P4) of several neural networks stored in a memory (MEM), which are trained with training data under respectively different conditions of external influence factors, selects the one most similar to the prevailing conditions.',\n",
       " 'A device and a method for creation of emotions are provided for an interface of information, such as an artificial agent and a personified agent, intervened between a human being (i.e., user) and an electronic apparatus. For instance, an emotion creating device is configured by a neural network, a behavior determination engine and a feature determination engine. The neural network inputs user information, representing conditions of the user, and apparatus information, representing conditions of the apparatus, so as to produce emotional states. Herein, a present set of emotional states are produced in consideration of a previous set of emotional states. The emotional states represent prescribed emotions such as pleasure, anger, sadness and surprise. The behavior determination engine refers to a behavior determination database using the user information and the emotional states of the neural network so as to determine a behavior of the interface. The feature determination engine refers to a database using the emotional states of the neural network to determine a feature of the interface, which corresponds to a facial feature.',\n",
       " 'A device for distributing resources of a given physical network among logical links by subdividing physical link capacities into logical links using an algorithm. The device comprises a first neural network, in which one part of the algorithm is implemented, and a second neural network, in which a second part of the algorithm is implemented, said two neural networks interworking to compute logical link capacities. Furthermore, a method for distributing resources of a given physical network among logical links by subdividing physical link capacities into said logical links is provided. More specifically, the method involves the use of a first neural network, in which one part of an algorithm is implemented, and a second neural network, in which a second part of an algorithm is implemented, said two neural networks interworking to compute logical link capacities so that the operation of the physical network, given an objective function, is generally optimized, according to the objective function.',\n",
       " 'The disclosure provides a device and a method for performing morphological analysis for erythrocytes, wherein the method for performing morphological analysis for erythrocytes comprises: collecting a morphological image of each of cells in a sample through a Charge Coupled Device (CCD) after amplifying the sample through an automatic microscope; segmenting and positioning the image and extracting target feature parameters after digitizing the image through an image-digital converter; isolating morphological feature parameters of each of the erythrocytes through a classifier established on the basis of the neural network, and normalizing each type of the morphological feature parameters of the erythrocytes through a feature fusion device established on the basis of fuzzy clustering; performing a statistical analysis on each type of normalized parameters obtained or performing a comprehensive statistical analysis according to a plurality of types of parameters, and expressing the result of the statistical analysis or the comprehensive statistical analysis in the form of graph or numerical table, thereby judging whether the morphology of the erythrocyte is normal. The source and property of the erythrocytes can be identified according to the detection for each type of the erythrocytes with the abnormal morphology.',\n",
       " \"A device and method for estimating a mental decision to select a visual cue from the viewer's eye fixation and corresponding single event evoked cerebral potential. The device comprises an eyetracker, an electronic biosignal processor and a digital computer. The eyetracker determines the instantaneous viewing direction from oculometric measurements and a head position and orientation sensor. The electronic processor continually estimates the cerebral electroencephalogramic potential from scalp surface measurements following corrections for electrooculogramic, electromyogramic and electrocardiogramic artifacts. The digital computer analyzes the viewing direction data for a fixation and then extracts the corresponding single event evoked cerebral potential. The fixation properties, such as duration, start and end pupil sizes, end state (saccade or blink) and gaze fixation count, and the parametric representation of the evoked potential are all inputs to an artificial neural network for outputting an estimate of the selection interest in the gaze point of regard. The artificial neural network is trained off-line prior to application to represent the mental decisions of the viewer. The device can be used to control computerized machinery from a video display by ocular gaze point of regard alone, by determining which visual cue the viewer is looking at and then using the estimation of the task-related selection as a selector switch.\",\n",
       " 'Device and method of channel effect compensation for a telephone speech recognition system is disclosed. The telephone speech recognition system comprises a compensatory neutral network and a recognize. The compensatory neural network receives an input signal and compensates the input signal with a bias to generate an output signal. The compensatory neural network provides a plurality of first parameters to determine the bias. The recognizer is coupled to the compensatory neural network for classifying the output signal according to a plurality of second parameters in acoustic models to generate a recognition result and determine a recognition loss. The first parameters and second parameters are adjusted according to the recognition loss and an adjustment means during a training process.',\n",
       " 'An anomalous effect detector responsive to an influence of mind comprises a source of non-deterministic random numbers, SNDRN, a phase-sensitive filter and a results interface. In some embodiments, the phase-sensitive filter comprises a complex filter. An artificial sensory neuron comprises a SNDRN. Preferably, several artificial sensory neurons are grouped in a small volume. An analog artificial sensory detector comprises a plurality of analog artificial sensory neurons, an abstracting processor and a control or feedback unit. Some embodiments include an artificial neural network. An artificial consciousness network contains a plurality of artificial neural networks. One of the artificial neural networks comprises an activation pattern meta-analyzer. An artificial consciousness device comprises a cluster of artificial consciousness networks, a sensory input device to provide sensory input signals to the input of one or more ANNs in ACD, and an output device.',\n",
       " 'A method for the numerical control of machines with several axes, in particular machine tools and robots, to compensate for the inaccuracies occurring when the axes are reversed, wherein varying friction conditions, as well as slackness and torsional effects are compensated using a friction precontrol. Rotation speed reference values are corrected by injecting a correction pulse with an acceleration-dependent injection amplitude and a constant decay time for each axis at the time of passage from one quadrant to another, with the associated change in direction. The injection amplitude and constant decay time are determined for each machine manually or learned in an additional embodiment automatically in a self-learning system in the form of a neural network.',\n",
       " 'A machining condition setting apparatus for electrical discharge machining that sets the machining conditions, including the machining pulse energy, the feed of the electrode, etc. based on set data regarding specifications including the material of the workpiece and the desired surface roughness of the product. Plural sets of basic data showing the relationship between the machining conditions and the specifications resulting from the machining conditions are selected. The relationship between the specifications and machining conditions are stored in an inference unit which includes a neural network type computation unit, by using selected basic data. The inference unit determines the most appropriate machining conditions based on the set data and the specifications. Thus, the storage unit only need store a very small amount of basic data.',\n",
       " 'The invention relates to a device for designing a neural network, in which to determine the number of neurons (21 . . . 24) in the intermediate layer, the domain of the input signal (X1, X2) in question is subdivided into a predefinable number of subdomains, and in the case of a multiplicity n of input signals (X1, X2), the n-dimensional value space of the n input signals is subdivided in conformance with the subdomains in question into n-dimensional partial spaces, and the supporting values (xi, yi) of the training data are assigned to the subdomains or partial spaces, and the subdomains or partial spaces having the most supporting values are selected, and in which case, for each selected subdomain or partial space, provision is made for a neuron in the intermediate layer preceding the output layer. The device according to the invention can be advantageously used for designing neural networks where the training data are unevenly distributed. The invention is generally suited for applications in neural networks.',\n",
       " 'The present invention relates to a device for detecting and monitoring physiological conditions in mammalian tissue, and method for using the same. The device includes sensors for sensing physiological conditions and generating signals in response thereto and processor operatively associated with the sensors for receiving and manipulating the signals to produce a generalization indicative of normal and abnormal physiological condition of mammalian tissue. The processor is characterized to include a neural network having a predetermined solution spaced memory, the solution space memory including regions indicative of two (2) or more physiological conditions, wherein the generalization is characterized by the signals projected into the regions.',\n",
       " 'A device for estimating machining dimensions of a machine tool which employs tool members each being rotatably driven by a driving unit includes: a vibration sensor; a characteristics extracting unit for extracting amounts of characteristics from an output of the vibration sensor; a neural network for classifying the amounts of characteristics into categories; and a conversion unit. Amounts of characteristics of generated output by racing the tool member are used for training the neural network, and inputted again to the trained competitive learning neural network to excite neurons so that the relationships between Euclidean distances and machining dimensions of workpieces are registered in the conversion unit. The Euclidean distances are obtained between weight vectors of the excited neurons and respective corresponding training samples, and the machining dimensions are obtained when the workpieces are machined by the tool members at the same condition as the respective corresponding training samples are obtained.',\n",
       " 'For recognizing information conveyed by a received signal, represented by convention by possible elementary forms of the signal to be transmitted, a device includes a correlator for establishing a correlation between the received signal and various possible forms of signal, in accordance with the convention. A neural network using correlation coefficients obtained from the correlator is trained by application to its input of correlation coefficients corresponding to a received signal conveying given information whilst imposing the given information at its output. The network supplies recognized information.',\n",
       " 'A discovery system employing a neural network, training within this system, that is stimulated to generate novel output patterns through various forms of perturbation applied to it, a critic neural network likewise capable of training in situ within this system, that learns to associate such novel patterns with their utility or value while triggering reinforcement learning of the more useful or valuable of these patterns within the former net. The device is capable of bootstrapping itself to progressively higher levels of adaptive or creative competence, starting from no learning whatsoever, through cumulative cycles of experimentation and learning. Optional feedback mechanisms between the latter and former self-learning artificial neural networks are used to accelerate the convergence of this system toward useful concepts or plans of action.',\n",
       " 'A device for simulating human creativity employing a neural network trained to produce input-output maps within some predetermined knowledge domain, an apparatus for subjecting the neural network to perturbations that produce changes in the predetermined knowledge domain, the neural network having an optional output for feeding the outputs of the neural network to a second neural network that evaluates and selects outputs based on training within the second neural network. The device may also include a reciprocal feed back connection from the output of the second neural network to the first neural network to further influence and change what takes place in the aforesaid neural network.',\n",
       " 'A device for generating useful information employing a first neural network trained to produce input-output maps within a predetermined initial knowledge domain, an apparatus for subjecting the neural network to perturbations which may produce changes in the predetermined knowledge domain, the neural network having an optional output for feeding the outputs of the first neural network to a second neural network that evaluates the outputs based on training within the second neural network. The device may also include a reciprocal feed back connection from the output of the second neural network to the first neural network to further influence and change what takes place in the aforesaid neural network.',\n",
       " 'A particle image in a sample is formed at an imaging position by an objective lens of a microscope, projected on the image picking up plane of a TV camera via a projection lens and is subjected to photo-electric conversion. Image signals from the TV camera are supplied to an image memory via an A/D converter as well as to an image processing control unit. Image signals outputted from the image memory are supplied to a characteristic picking out unit and there a plurality of characteristics of the particle concerned are picked out. The picked-out characteristics are supplied to the classification unit and there classification of the sediment components is perfumed via a neural network with a learning capability. Accordingly, the classification unit performs provisionally an automatic classification of the objective sediment components by making use of the inputted characteristic parameters. The device allows accurate and fast automatic component particle analysis even for patient specimens containing a variety of components in high concentration.',\n",
       " 'Examples described herein involve detecting known impairments or other known conditions using a neural network. An example implementation involves receiving data indicating a response of a playback device as captured by a microphone. The implementation also involves determining an input vector by projecting a response vector that represents the response of the playback device onto a principle component matrix representing variance caused by one or more known impairments. The implementation further involves providing the determined input vector to a neural network that includes an output layer comprising neurons that correspond to respective known impairments. The implementation involves detecting that the input vector caused one or more neurons of the neural network to fire such that the neural network indicates that a particular known impairment is affecting the microphone and/or the playback device and adjusting operation of the playback device and/or the microphone to offset the particular known impairment.',\n",
       " 'A venue system of a client device can submit a location request to a server, which returns multiple venues that are near the client device. The client device can use one or more machine learning schemes (e.g., convolutional neural networks) to determine that the client device is located in one of specific venues of the possible venues. The venue system can further select imagery for presentation based on the venue selection. The presentation may be published as ephemeral message on a network platform.',\n",
       " 'A sensor device may include a computing device in communication with multiple microphones. A neural network executing on the computing device may receive audio signals from each microphone. One microphone signal may serve as a reference signal. The neural network may extract differences in signal characteristics of the other microphone signals as compared to the reference signal. The neural network may combine these signal differences into a lossy compressed signal. The sensor device may transmit the lossy compressed signal and the lossless reference signal to a remote neural network executing in a cloud computing environment for decompression and sound recognition analysis.',\n",
       " 'An artificial neural network-based system and method for determining desired concepts and relationships within a predefined field of endeavor, including a neural network portion, which neural network portion includes an artificial neural network that has been previously trained in accordance with a set of given training exemplars, a monitor portion associated with the neural network portion to observe the data outputs produced by the previously trained artificial neural network, and a perturbation portion for perturbing the neural network portion to effect changes, subject to design constraints of the artificial neural network that remain unperturbed, in the outputs produced by the neural network portion, the perturbation portion operable such that production of an output by the neural network portion thereafter effects a perturbation of the neural network portion by the perturbation portion, the monitor portion responsive to detection of the data outputs being produced by the previously trained neural network, whereby the system is operable to derive over a period of time a plurality of input/perturbation/output mapping relationships that differ from the input/perturbation/mapping relationships of the training exemplars.',\n",
       " 'A device and associated methods for escaping from a venue when a threat is detected is described. Venues can be buildings or outside areas and contain the area where the threat constitutes a hazard to a protected person. Threats include fire, terrorists, gunmen, explosion, collapse, loss of critical resources and crowd panic. The device incorporates a machine learning system implemented with a neural network or other pattern matching system and is trained in steps. Pre-training is based on general requirements such as edge-detection and audio analysis. Principles and data for venue layouts and human behavior can be included. The produced model is further trained from data gathered from sensors and servers after entry into the venue. Operation of the model produces warnings of threats and a plan of escape with steps of the plan communicated to the protected person by audio, visual or tactile sensory channels.',\n",
       " 'Aspects of the disclosure generally relate to computing devices and may be generally directed to devices, systems, methods, and/or applications for learning conversations among two or more conversation participants, storing this knowledge in a knowledgebase (i.e. neural network, graph, sequences, etc.), and enabling a user to simulate a conversation with an artificially intelligent conversation participant.',\n",
       " \"The present invention is based on the discovery that amyotrophic lateral sclerosis (ALS), Parkinson disease and Alzheimer disease are due to lack of a disorder-specific neurotrophic hormone. Diagnosis is accomplished by assaying hormones specific for a particular neuronal network or system: the motor neurotrophic hormones from muscle in the motor neural system are used to diagnose and treat ALS, dopamine neurotrophic hormones from striatum in the nigrostriatal neural system are used to diagnose and treat parkinsonism, and cholinergic neurotrophic hormones released from the cortex and hippocampus which are specific for cholinergic neurons of the nucleus basalis and septal nucleus are used to diagnose and treat Alzheimer's disease. With tissue culture, the presence or absence of specific neurotrophic hormones can be assessed in ALS, parkinsonism, and Alzheimer disease. If there is a deficiency, extracted and purified neurotrophic hormones specific to the particular neuronal network or system can be injected in ALS and Alzheimer disease and in parkinsonism.\",\n",
       " \"The present invention is based on the discovery that amyotrophic lateral sclerosis (ALS), Parkinson disease and Alzheimer disease are due to lack of a disorder-specific neurotrophic hormone. Diagnosis is accomplished by assaying hormones specific for a particular neuronal network or system: the motor neurotrophic hormones from muscle in the motor neural system are used to diagnose and treat ALS, dopamine neurotrophic hormones from striatum in the migrostriatal neural system are used to diagnose and treat parkinsonism, and cholinergic neurotrophic hormones released from the cortex and hippocampus which are specific for cholinergic neorons of the nucleus basalis and septal nucleus are used to diagnose and treat Alzheimer's disease. With tissue culture, the presence or absence of specific neurotrophic hormones can be assessed in ALS, parkinsonism, and Alzheimer disease. If there is a deficiency, extracted and purified neurotrophic hormones specific to the particular neuronal network or system can be injected in ALS and Alzheimer disease and in parkinsonism.\",\n",
       " 'A diagnosis processing device is provided in which diagnosis is realizable by a simple arrangement. A diagnosis processing device (1) of the present invention includes: a learning pattern creating section (10a) for creating a learning pattern by sampling data from a learning image in which abnormality information indicating a substantive feature of abnormality of a target is pre-known; a learning processing section (12) for causing a neural network (17) to learn, by using learning patterns; a diagnostic pattern creating section (10b) for creating a diagnostic pattern by sampling data from a diagnostic image in which abnormality information is unknown; a determination processing section (18) for determining a substantive feature of the abnormality of the target indicated in the abnormality information in the diagnostic image, based on an output value outputted, in response to an input of the diagnostic pattern, from a learned neural network (17) which is a neural network subjected to learning.',\n",
       " 'Loose parts are sensed moving in a conduit carrying a flowing material, such as the cooling circuit of a pressurized water nuclear reactor. An acoustic pickup produces an electrical signal with vibration of the conduit due to impact of the loose part, and background noise. A signal processor encodes the values of distinct parameters of the electrical signal such as amplitude, amplitude at particular frequencies, etc., in an ongoing manner, producing discrete output values. These outputs are coupled as inputs to a neural network with physical or logical neuron cells loaded with weighting factors affecting the strength and polarity of neural interconnections. The factors represent the acoustic signature of the loose part. Products of the input values and the weighting factors are summed to produce one or more neural network outputs, compared to a threshold. The sum normally varies randomly, but has a strong swing when the pattern is encountered, due to the factors emphasizing the pattern over background noise. The threshold comparison operates a display or alarm. The weighting factors are learned by repeating empirical tests and correlating the factors to the signal to minimize error.',\n",
       " 'A system is disclosed for diagnosing faults in electronic control systems wherein a large volume of information is exchanged between the electronic control processor and a mechanical system under its control. The data is acquired such that parameter vectors describing the system operation are formed. The vectors are provided to a pattern recognition system such as a neural network for classification according to the operating condition of the electronically controlled system. For diagnosis of electronically controlled engine operation, the parameters included in the vectors correspond to individual firing events occurring in the engine operating under a predetermined condition. The diagnostic system can be implemented as a service tool in an automotive service bay or can be implemented within the on-board electronic control system itself.',\n",
       " 'An indirect calorimeter estimates nutritional caloric intake by periodically monitoring weight and sensing physical exercise (i.e., physiological data and/or motion data related to physical exertion), which can then be used in a calorimetry model derived from regression analysis of a population (e.g., linear regression, feed-forward neural network, Gaussian process, boosted regression tree, etc.). A strap-on user device for tracking exercise can detect one or more of heart rate, body temperature, skin resistance, motion/acceleration sensing (e.g., pedometer, accelerometer), velocity sensing (e.g., global positioning system (GPS)), and an intelligent, integrated exercise machine (e.g., treadmill, exercise bike, etc.). To gain further fidelity, the user can fine-tune the estimate by undergoing a journal-based routine for a relatively short period of time or clinical calorimetry measurement (e.g., respiratory calorimeter), thereby providing a baseline for resting or exercising metabolic rate.',\n",
       " 'A difference calculating neural network is disclosed having an array of synapse cells arranged in rows and columns along pairs of row and column lines. The cells include a pair of floating gate devices which have their control gates coupled to receive one of a pair of complementary input voltages. The floating gate devices also have complementary threshold voltages such that packets of charge are produced from the synapse cells that are proportional to the difference between the input and voltage threshold. The charge packets are accumulated by the pairs of column lines in the array.',\n",
       " 'A preprocessing circuit receives signals representative of a current circulating in a primary winding and of a current circulating in a secondary winding of a transformer. The signals representative of currents are used to calculate the values of a through current and a differential current. The preprocessing circuit performs a spectral analysis and provides a neural network with signals representative of the fundamental component of the through current, of the fundamental component of the differential current, of the second harmonic and of the fifth harmonic of the differential current. The neural network identifies fault conditions and normal operation states, and supplies a triggering and/or alarm signal to an output when a fault condition is detected.',\n",
       " 'A maximum-likelihood sequence estimator receiver includes a matched filter connected to a digital transmission channel and a sampler for providing sampled signals output by the matched filter. The sampled signals are input to an analog neural network to provide high-speed outputs representative of the transmission channel signals. The neural network outputs are also provided as inputs to a coefficient estimator which produces coefficients for feedback to the matched filter. For time-varying transmission channel characteristics, the coefficient estimator provides a second coefficient output which is utilized for changing the interconnection strengths of the neural network connection matrix to offset the varying transmission channel characteristics.',\n",
       " 'A neuron for use in a neural processing network, comprises a memory having a plurality of storage locations at each of which a number representing a probability is stored, each of the storage locations being selectively addressable to cause the contents of the location to be read to an input of a comparator. A noise generator inputs to the comparator a random number representing noise. At an output of the comparator an output signal appears having a first or second value depending on the values of the numbers received from the addressed storage location and the noise generator, the probability of the output signal having a given one of the first and second values being determined by the number at the addressed location. Preferably the neuron receives from the environment signals representing success or failure of the network, the value of the number stored at the addressed location being changed in such a way as to increase the probability of the successful action if a success signal is received, and to decrease the probability of the unsuccessful action if a failure signal is received.',\n",
       " 'A plurality of neural circuits are connected in a neural network layer for generating their respective digital axonal responses to the same plurality of synapse input signals. Each neural circuit includes digital circuitry for approximating a sigmoidal response connected after respective circuitry for performing a weighted summation of the synapse input signals to generate a weighted summation result in digital form. In this digital circuitry the absolute value of the digital weighted summation result is first determined. Then, a window comparator determines into which of a plurality of amplitude ranges the absolute value of the weighted summation result falls. A digital intercept value and a digital slope value are selected in accordance with the range into which the absolute value of the weighted summation result falls. The absolute value of the digital weighted summation result is multiplied by the selected digital slope value to generate a digital product; and the digital intercept value is added to the digital product to generate an absolute value representation of a digital axonal response. The polarity of the weighted summation result is determined, and the same polarity is assigned to the absolute value representation of the digital axonal response, thereby to generate the digital axonal response.',\n",
       " 'Plural-bit digital input signals to be subjected to weighted summation are bit-sliced; and a number N of respective first through N.sup.th weighted summations of the bits of the digital input signals in each bit slice are performed, resulting in a respective set of first through N.sup.th partial weighted summation results. Each weighted summation of a bit slice of the digital input signals is performed using a capacitive network that generates partial weighted summation results in the analog regime; and analog-to-digital conversion circuitry digitizes the partial weighted summation results. Weighted summations of the digitized partial weighted summation results of similar ordinal number are then performed to generate first through N.sup.th final weighted summation results in digital form, which results are respective correlations of the pattern of the digital input signals with the patterns of weights established by the capacitive networks. A neural net layer can be formed by combining such weighted summation circuitry with digital circuits processing each final weighted summation result non-linearly, with a system function that is sigmoidal.',\n",
       " 'A digital neural network architecture including a forward cascade of layers of neurons, having one input channel and one output channel, for forward processing of data examples that include many data packets. Backward cascade of layers of neurons, having one input channel and one output channel, for backward propagation learning of errors of the processed data examples. Each packet being of a given size. The forward cascade is adapted to be fed, through the input channel, with a succession of data examples and to deliver a succession of partially and fully processed data examples each consisting of a plurality of packets. The fully processed data examples are delivered through the one output channel. Each one of the layers is adapted to receive as input in its input channel a first number of data packets per time unit and to deliver as output in its output channel a second number of data packets per time unit. The forward cascade of layers is inter-connected to the backward cascade of layers by means that include inter-layer structure, such that, during processing phase of the forward cascade of neurons, any given data example that is fed from a given layer in the forward cascade to a corresponding layer in the backward cascade, through the means, is synchronized with the error of the given processed data example that is fed to the corresponding layer from a preceding layer in the backward cascade. The first number of data packets and the second number of data packets being the same for all the layers.',\n",
       " 'A digital image display apparatus for converting a pixel value of medical digital image data such as MRI image data or CT image data into brightness in accordance with a display window including a window level and a window width of a display unit, determines the optimum window level and width for each image as follows. The apparatus obtains a histogram of pixel values from the digital image data and calculates brightness data of a pixel value having a highest frequency, brightness data of a pixel value at a boundary between a background and an image, area data of a portion having middle brightness within a display brightness range, area data of a portion having maximum brightness, and data indicating a ratio between an area of a portion having higher brightness than the middle brightness and an area of a portion having lower brightness than that obtained, when the digital image is to be displayed by a given display window on the basis of the histogram. The apparatus obtains image quality indicating clarity of the image displayed by the given window on the basis of the above data by using arithmetic operations or by using a neural network, thereby determining the optimum display window which provides a maximum image quality.',\n",
       " 'Taking into consideration the disadvantage that a large-scale analog neural network cannot be constructed as an LSI and, even if this were possible, the cost would be prohibitive and the network would lack universality, a digital image processor for processing input image data based upon a cellular neural network is provided with a first multiply-and-accumulate arithmetic unit for digitally processing multiplication and accumulation of input image data of a plurality of pixels and input weighting values in a predetermined area, a second multiply-and-accumulate arithmetic unit for digitally processing multiplication and accumulation of output image data of a plurality of pixels and output weighting values in a predetermined area, and a non-linear acting unit for deciding output image data in accordance with results of calculation from the first and second multiply-and-accumulate arithmetic unit and non-linear characteristic parameters. This makes it possible to realize an image processor which excels in universality, ease of control and ease of integration.',\n",
       " 'An artificial neural network is provided using a digital architecture having feedforward and feedback processors interconnected with a digital computation ring or data bus to handle complex neural feedback arrangements. The feedforward processor receives a sequence of digital input signals and multiplies each by a weight in a predetermined manner and stores the results in an accumulator. The accumulated values may be shifted around the computation ring and read from a tap point thereof, or reprocessed through the feedback processor with predetermined scaling factors and combined with the feedforward outcomes for providing various types neural network feedback computations. Alternately, the feedforward outcomes may be placed sequentially on a data bus for feedback processing through the network. The digital architecture includes a predetermined number of data input terminals for the digital input signal irrespective of the number of synapses per neuron and the number of neurons per neural network, and allows the synapses to share a common multiplier and thereby reduce the physical area of the neural network. A learning circuit may be utilized in the feedforward processor for real-time updating the weights thereof to reflect changes in the environement.',\n",
       " 'A digital neural network has a plurality of neurons (NR) completely meshed with one another, each of which comprises an evaluation stage having a plurality of evaluators (B) that is equal in number to the plurality of neurons (NR) and each of which comprises a decision stage having a decision unit (E). An adjustment information (INF.sub.E) that effects a defined pre-adjustment of the decision unit (E) can be supplied to every decision unit (E) by a pre-processing means via an information input. A weighting information (INF.sub.G) can be supplied to every evaluator (B) by a pre-processing means via an individual information input. An output information (INF.sub.A) can be output by every decision unit (E) to a post-processing means via a respective individual information output. The information outputs of the decision units (E) are each connected to an individual processing input of all evaluators (B) allocated to the appertaining decision unit (E). Individual processing outputs of the evaluators (B) are connected to individual processing inputs of the decision unit (E) in the appertaining neuron (N), so that every output information (INF.sub.A) can be indirectly fed back onto every neuron (NR).',\n",
       " 'A preprocessing device is disclosed which performs a linear transformation or power series expansion transformation on the input signals to a neural network node. The outputs of the preprocessing device are combined as a product of these linear transformations and compared to a threshold. This processing element configuration, combining a transformation with a product and threshold comparison, performs non-linear transformations between input data and output results. As a result, this processing element will, by itself, produce both linearly and non-linearly separable boolean logic functions. When this processing element is configured in a network, a two layer neural network can be created which will solve any arbitrary decision making function. This element can be configured in a probability based binary tree neural network which is validatable and verifiable in which the threshold comparison operation can be eliminated. The element can also be implemented in binary logic for ultra high speed. If the linkage element performs the power series expansion, a universal or general purpose element is created.',\n",
       " 'This application discloses a system that optimizes a neural network by generating all of the discrete weights for a given neural node by creating a normalized weight vector for each possible weight combination. The normalized vectors for each node define the weight space for that node. This complete set of weight vectors for each node is searched using a direct search method during the learning phase to optimize the network. The search evaluates a node cost function to determine a base point from which a pattern more within the weight space is made. Around the pattern mode point exploratory moves are made which are cost function evaluated. The pattern move is performed by eliminating from the search vectors with lower commonality.',\n",
       " \"In view of the neural network information parallel processing, a digital perceptron device analogous to the build-in neural network hardware systems for parallel processing digital signals directly by the processor's memory content and memory perception in one feed-forward step is disclosed. The digital perceptron device of the invention applies the configurable content and perceptive non-volatile memory arrays as the memory processor hardware. The input digital signals are then broadcasted into the non-volatile content memory array for a match to output the digital signals from the perceptive non-volatile memory array as the content-perceptive digital perceptron device.\",\n",
       " 'An artificial neural network is provided using a digital architecture having feedforward and feedback processors interconnected with a digital computation ring or data bus to handle complex neural feedback arrangements. The feedforward processor receives a sequence of digital input signals and multiplies each by a weight in a predetermined manner and stores the results in an accumulator. The accumulated values may be shifted around the computation ring and read from a tap point thereof, or reprocessed through the feedback processor with predetermined scaling factors and combined with the feedforward outcomes for providing various types neural network feedback computations. Alternately, the feedforward outcomes may be placed sequentially on a data bus for feedback processing through the network. The digital architecture includes a predetermined number of data input terminals for the digital input signal irrespective of the number of synapses per neuron and the number of neurons per neural network, and allows the synapses to share a common multiplier and thereby reduce the physical area of the neural network. A learning circuit may be utilized in the feedforward processor for real-time updating the weights thereof to reflect changes in the environment.',\n",
       " 'A digital signal processor implementation of three algorithms used to detect high impedance faults. The algorithms can be wavelet based, higher order statistics based and neural network based. The algorithms are modified to process one second of data instead of ten seconds of data and a double buffered acquisition is connected to the output of the algorithms.',\n",
       " 'A neuron for an artificial neural network provides digital weighting of input signals at a common portion of the neuron rather than at each synapse. The neuron is adapted for use of differential signals, and the weighting may be provided by field effect transistors of different widths, by subtracting a plurality of differential signal components from an opposite most significant component, or by subtracting one half of a differential signal component from the opposite next most significant component. The neuron may provide binary sign selection and digit selection by switching input and reference signals at each synapse.',\n",
       " 'A trained neural network is used, for estimating the number, positions or moments of one or more dipoles which are assumed as sources of the electromagnetic field distribution based upon an electromagnetic field distribution of a living body or an object. At least either one of the dipole number, positions and moments or more than two of their combination is referred to as dipole parameters.',\n",
       " 'Methods and apparatus relating to microphone devices and signal processing techniques are provided. In an example, a microphone device can detect sound, as well as enhance an ability to perceive at least a general direction from which the sound arrives at the microphone device. In an example, a case of the microphone device has an external surface which at least partially defines funnel-shaped surfaces. Each funnel-shaped surface is configured to direct the sound to a respective microphone diaphragm to produce an auralized multi-microphone output. The funnel-shaped surfaces are configured to cause direction-dependent variations in spectral notches and frequency response of the sound as received by the microphone diaphragms. A neural network can device-shape the auralized multi-microphone output to create a binaural output. The binaural output can be auralized with respect to a human listener.',\n",
       " 'A discrete cosine transform chip includes circuits using neural network concepts that have parallel processing capability as well as conventional digital logic circuits. In particular, the discrete cosine transform chip includes a cosine term processing portion, a multiplier, an adder, a subtractor, and two groups of latches. The multiplier, the adder and the subtractor incorporated in the discrete cosine transform chip use unidirectional feed back neural network models.',\n",
       " 'A Neural Network using interconnecting weights each with two values, one of which is selected for use, can be taught to map a set of input vectors to a set of output vectors. A set of input vectors is applied to the network and in response, a set of output vectors is produced by the network. The error is the difference between desired outputs and actual outputs. The network is trained in the following manner. A set of input vectors is presented to the network, each vector being propogated forward through the network to produce an output vector. A set of error vectors is then presented to the network and propagated backwards. Each Tensor Weight Element includes a selective change means which accumulates particular information about the error. After all the input vectors are presented, an update phase is initiated. During the update phase, in accordance with the results of the derived algorithm, the selective change means selects the other weight value if selecting the other weight value will decrease the total error. Only one such change is made per set. After the update phase, if a selected value was changed, the entire process is repeated. When no values are switched, the network has adapted as well as it can, and the training is completed.',\n",
       " 'A neural network determines optimal control inputs for a linear quadratic discrete-time process at M sampling times, the process being characterized by a quadratic cost function, p state variables, and r control variables. The network includes N=(p+r)M neurons, a distinct neuron being assigned to represent the value of each state variable at each sampling time and a distinct neuron being assigned to represent the value of each control variable at each sampling time. An input bias connected to each neuron has a value determined by the quandratic cost function for the variable represented by the neuron. Selected connections are provided between the output of each neuron and the input of selected other neurons in the network, each such connection and the strength of each such connection being determined by the relationship in the cost function between the variable represented by the connected output neuron and the variable represented by the connected input neuron, such that running the neural network for a sufficient time to minimize the cost function will produce optimum values for each control variable at each sampling time.',\n",
       " 'A family of novel multi-layer discrete-time neural net controllers is presented for the control of an multi-input multi-output (MIMO) dynamical system. No learning phase is needed. The structure of the neural net (NN) controller is derived using a filtered error/passivity approach. For guaranteed stability, the upper bound on the constant learning rate parameter for the delta rule employed in standard back propagation is shown to decrease with the number of hidden-layer neurons so that learning must slow down. This major drawback is shown to be easily overcome by using a projection algorithm in each layer. The notion of persistency of excitation for multilayer NN is defined and explored. New on-line improved tuning algorithms for discrete-time systems are derived, which are similar to e-modification for the case of continuous-time systems, that include a modification to the learning rate parameter plus a correction term. These algorithms guarantee tracking as well as bounded NN weights. An extension of these novel weight tuning updates to NN with an arbitrary number of hidden layers is discussed. The notions of discrete-time passive NN, dissipative NN, and robust NN are introduced.',\n",
       " 'A discriminant neural network and a method of training the network are disclosed. The network includes a set of hidden nodes having associated weights, and the number of hidden nodes is minimized by the training method of the invention. The training method includes the steps of 1) loading a training data set and assigning it to a residual data set, 2) computing a vector associated with a first hidden node using the residual data set, 3) projecting training data onto a hyperplane associated with said first hidden node, 4) determining the number and locations of hard-limiter thresholds associated with the first node, and 5) repeating the above for successive hidden nodes after removing satisfied subsets from the training data until all partitioned regions of the input data space are satisfied.',\n",
       " 'An apparatus for categorizing objects employs a neural network having a plurality of cells each having memory for storing a state variable, and a plurality of synaptic junctions connecting cells of the network and having memory for storing a synaptic strength variable. A computer is used to modify the synaptic strength variable in accordance with a heterocellular synaptic modification rule. That modification rule includes both the passage of time and the values of the state variables of each cell and of those other cells having specific spatial locations with respect to the cell in three dimensional space.',\n",
       " 'Discriminative pretraining technique embodiments are presented that pretrain the hidden layers of a Deep Neural Network (DNN). In general, a one-hidden-layer neural network is trained first using labels discriminatively with error back-propagation (BP). Then, after discarding an output layer in the previous one-hidden-layer neural network, another randomly initialized hidden layer is added on top of the previously trained hidden layer along with a new output layer that represents the targets for classification or recognition. The resulting multiple-hidden-layer DNN is then discriminatively trained using the same strategy, and so on until the desired number of hidden layers is reached. This produces a pretrained DNN. The discriminative pretraining technique embodiments have the advantage of bringing the DNN layer weights close to a good local optimum, while still leaving them in a range with a high gradient so that they can be fine-tuned effectively.',\n",
       " 'A disk memory device comprises a head which reads a read-out signal from a disk, an amplifier which amplifies an analog signal waveform of the read-out signal read from the head, a filter which decreases a noise of the read-out signal output from the amplifier, an A/D converter which converts the read-out signal of which noise is decreased by the filter into a digital signal including a waveform distortion component, and a neural network type signal processing circuit which detects a binarized data from the digital signal.',\n",
       " 'An adaptive distance calculating neural network classifier chip accepts high dimensionality input pattern vectors with up to 256 5-bit elements per vector and compares the input vector with up to 1024 prototype vectors stored on-chip by calculating the distance between the input vector and each of the prototype vectors. The classifier further provides for identifying up to 64 classes to which the prototype vectors belong. If the distance between input and prototype vector is less than a programmable threshold distance, the prototype fires and the class to which it belongs is identified. If prototype vectors belonging to more than one class fire, a probabilistic model based on Parzen windows may be invoked to resolve the classification by providing the relative probabilities of various class membership. The classifier chip is trainable by supplying appropriate training vectors and associated class membership. Distance and probability parameters are generated during training and are stored for use in the classification mode. Incremental training is also provided so that additional prototypes may be added to an existing base. In order to extend the classifier capacity, multichip operation is provided under the supervision of a system administrator controller/CPU.',\n",
       " 'One embodiment of a speech recognition system is organized with speech input signal preprocessing and feature extraction followed by a fuzzy matrix quantizer (FMQ). Frames of the speech input signal are represented by a vector .function. of line spectral pair frequencies and are fuzzy matrix quantized to respective a vector .function. entries in a codebook of the FMQ. A distance measure between .function. and .function., d(.function.,.function.), is defined as ##EQU1## where the constants .alpha..sub.1, a.sub.2, .beta..sub.1 and .beta..sub.2 are set to substantially minimize quantization error, and e.sub.i is the error power spectrum of the speech input signal and a predicted speech input signal at the ith line spectral pair frequency of the speech input signal. The speech recognition system may also include hidden Markov models and neural networks, such as a multilevel perceptron neural network, speech classifiers.',\n",
       " 'A cell phone having distributed artificial intelligence services is provided. The cell phone includes a neural network for performing a first pass of object recognition on an image to identify objects of interest therein based on one or more criterion. The cell phone also includes a patch generator for deriving patches from the objects of interest. Each of the patches includes a portion of a respective one of the objects of interest. The cell phone additionally includes a transmitter for transmitting the patches to a server for further processing in place of an entirety of the image to reduce network traffic.',\n",
       " 'A system that couples distributed power generators together as a collective unit for the purposes of selling or purchasing energy from the electrical power grid. The apparatus includes a charge/discharge controller and an adaptive controller. The charge/discharge controller transfers energy generated by the plurality of distributed power generators to the power grid. The adaptive controller directs when the charge/discharge controller transfers energy generated by at least one of the plurality of distributed power generators to the electrical grid.',\n",
       " 'A distributed system is described that employs electrical neural stimulation to modulate autonomic activity and which allows titration of the neural stimulation therapy in accordance with physiological measurements reflective of autonomic activity and/or physiological variables affected by the neural stimulation. Such a system may include a plurality of implantable neuromodulation units that communicate with one another over a network.',\n",
       " 'A distributed stress wave analysis system is disclosed for detecting structure borne sounds cause by friction. The detected information is processed using feature extraction and neural network artificial intelligence software. The system consists of stress wave sensors, interconnect cables, and preferably three modules: (1) distributed processing units, (2) maintenance advisory panel, and (3) laptop computer. A derived stress wave pulse train which is independent of background levels of vibration and audible noise is used to extract signature features, which when processed by neural networks of polynomial equations, characterize the mechanical health of the monitored components. The system includes an adjustable data fusion architecture to optimize indication thresholds, maximize fault detection probability, and minimize false alarms.',\n",
       " 'The distributed water flow predicting device comprises seasonal prediction model learning means for learning weight coefficients by back propagation over a prediction model a neural network model for predicting daily distributed water flows and specific characters of an hourly distributed water flow pattern for a season, based on processed actual seasonal weather data and seasonal distributed water flows, so as to identify the prediction model. Seasonal distributed water flow predicting means pridicts daily distributed water flows and specific characters of hourly distributed water flow patterns for a required season by using the prediction model, based on inputted information about the weather, temperature, a weekday or a holiday. The seasonal distributed water flow predicting means compares the specific characters of an hourly distributed water flow pattern given by the prediction model with specific characters of past actual distributed water flow patterns so as to retrieve a most similar hourly distributed flow pattern from the past actual distributed water flow patterns, giving the retrieved pattern as a predicted hourly distributed water flow pattern, and multiplys the predicted daily distributed water flow by the predicted hourly distributed water flow pattern to predict an hourly distributed water flow.',\n",
       " 'A technique for enriching sparse data for machine learning techniques such as supervised artificial neural network includes receiving the sparse data and enriching the received data around a deviation of the mean of the received data using a predetermined distribution. The technique further includes outputting the enriched data for unbiased and increased performance during the machine learning.',\n",
       " 'A divider circuit for efficiently and quickly performing a hardware implemented division by adopting a neural network architecture. The circuit includes a series of cascaded subtracter components that complement the divisor input and effectively perform an adder function. The subtracters include a synaptic configuration consisting of PMOS transistors, NMOS transistors, and CMOS inverters. The components are arranged in accordance with the predetermined connection strength assigned to each of the transistors and its respective position in the neural type network arrangement.',\n",
       " 'A divider using neural network configurations comprises a subtractor, a selecting means, a first latch means, a second latch means, a shift register and a control means. The subtractor of the divider comprises plural inverters and plural 3-bit full-adders which are composed of four output lines, an input synapse group, a first bias synapse group, a second bias synapse group, a feedback synapse group, a neuron group and an inverter group.',\n",
       " 'In a microarray image analysis system, when one of a plurality of statuses is set for a spot of a microarray by the user, the status of a similar spot is automatically determined. In a microarray image, the user determines a status of a spot, the pixel value matrix of an image in a spot region is learned by a neural network, a vertically and horizontally symmetrical image and an image rotated about the center of the region are formed and are learned by the neural network, and the neural network formed by repeating these steps is used for automatically recognizing the status of an undecided spot.',\n",
       " 'This invention is an oligomer-based analog neural network (ANN) comprising weight and saturation oligomers, the concentrations of which are selected such that activation of the ANN by a set of input oligomers generates a set of output oligomers, the sequences and relative concentrations of which are dependent on the sequences and relative concentrations of the input oligomers. The invention further includes methods for using such an ANN for solving any problems amenable to solution by a trained neural network. A preferred embodiment of the claimed invention is a DNA-based ANN that accepts cDNA molecules as inputs and analyzes the gene expression profile of the cells from which the cDNA is derived. The DNA-based ANN is typically trained with a computer to identify the weights giving accurate mapping of the inputs to the outputs; and the concentrations of weight oligomers of the DNA-based ANN are then selected accordingly.',\n",
       " 'A method of frequency discrimination associated with the Doppler effect is presented. The method includes mapping a first signal to a first plurality of frequency bins and a second signal to a second plurality of frequency bins. The first signal and the second signal corresponding to different times. The method also includes firing a first plurality of neurons based on contents of the first plurality of frequency bins and firing a second plurality of neurons based on contents of the second plurality of frequency bins.',\n",
       " \"Methods are provided for downhole sensing and flow control utilizing neural networks. In a described embodiment, a temporary sensor is positioned downhole with a permanent sensor. Outputs of the temporary and permanent sensors are recorded as training data sets. A neural network is trained using the training data sets. When the temporary sensor is no longer present or no longer operational in the well, the neural network is capable of determining the temporary sensor's output in response to the input to the neural network of the permanent sensor's output.\",\n",
       " 'An approach for phoneme recognition is described. A sequence of intermediate output posterior vectors is generated from an input sequence of cepstral features using a first layer perceptron. The intermediate output posterior vectors are then downsampled to form a reduced input set of intermediate posterior vectors for a second layer perceptron. A sequence of final posterior vectors is generated from the reduced input set of intermediate posterior vectors using the second layer perceptron. Then the final posterior vectors are decoded to determine an output recognized phoneme sequence representative of the input sequence of cepstral features.',\n",
       " 'A driving condition-monitoring apparatus for an automotive vehicle monitors a driving condition of a driver of the automotive vehicle. At least one of behavior of the vehicle, a driving operation of the driver, and at least one condition of the driver is detected to thereby generate driving condition-indicative data indicative of the driving condition of the driver. It is determined whether the driving condition of the driver is abnormal, based on the driving condition-indicative data generated. When it is not determined that the driving condition of the driver is abnormal, a degree of normality of the driving condition of the driver is determined by inputting a plurality of pieces of the driving condition-indicative data to a neural network. At least one of warning and control of the vehicle is carried out depending on a result of the determination as to whether the driving condition of the driver is abnormal and the degree of normality of the driving condition of the driver.',\n",
       " 'A slip frequency type driving control apparatus includes a detector for detecting an input current and an input voltage to an induction motor, a calculating unit for calculating a rotor flux and a torque current of the induction motor, a neural network for outputting an excitation current command value and a slip frequency command value, and a vector control unit for performing vector control for the induction motor. The neural network receives a rotor flux command value, a torque current command value, a calculated rotor flux value, and a calculated torque current value, performs learning on the basis of a back-propagation law using signals output in correspondence with these inputs, and outputs an excitation current command value and a slip frequency command value. The vector control unit detects the torque current and the excitation current on the basis of the output slip frequency command value from the neural network and controls the induction motor in accordance with a deviation between the detected excitation current value and the excitation current command value and a deviation between the detected torque current value and the torque current command value.',\n",
       " 'A neural network of a neuro computer has learned a prediction pattern based on the vehicle speed and time series data of the acceleration stroke received before the shipment of a vehicle. Based on the vehicle speed and time series data of the acceleration stroke, a request on the acceleration is predicted by a neural network computer during driving. At this time, an acceleration sensor or the like is not used, and the acceleration request is predicted more directly. Based on the prediction result, the throttle sensitivity is computed and set. A throttle computer refers to the throttle sensitivity to open or close the throttle valve to control the output of the engine.',\n",
       " 'A dynamic bandwidth allocation method of an Ethernet passive optical network, comprises a predictor and a rule of QoS-promoted dynamic bandwidth allocation (PQ-DBA); the predictor predicts a client behavior and numbers of various kinds of packets by using a pipeline scheduling predictor consisted of a pipelined recurrent neural network (PRNN), and a learning rule of the extended recursive least squares (ERLS); the present invention establishes a better QoS traffic management for the OLT-allocated ONU bandwidth and client packets sent by priority.',\n",
       " '\" The present invention provides an apparatus for decoding and classifying a digital audio input signal and for reconstructing the digital audio input signal, so that when the reconstructed signal is converted to an analog signal by a digital to analog converter (\"\"DAC\"\"), the analog signal can drive a preamplifier, power amplifier or speakers directly. In particular, the present invention proposes a digital filter than can be adapted to have appropriate filtering characteristics based on the signal being filtered. The invention uses a neural network to adjust coefficients of a digital filter, depending on whether the digital audio input signal is more periodic or more aperiodic. If the digital audio input signal is more periodic, the coefficients will configure the digital filter so that the filter has the characteristics of an analog brickwall filter. Whereas if the digital audio input signal is more aperiodic, the coefficients produced by the neural network will configure the digital filter to have more characteristics of an interpolation filter. The neural network is trained to recognize certain periodic and aperiodic signals and to produce digital filter parameters, preferably polynomial coefficients, correspondingly. The coefficients are selected to respond to the pure or blended periodic and aperiodic features of certain archetypal input signals. \"',\n",
       " 'A dynamic memory processor for time variant pattern recognition and an input data dimensionality reduction is provided having a multi-layer harmonic neural network and a classifier network. The multi-layer harmonic neural network receives a fused feature vector of the pattern to be recognized from a neural sensor and generates output vectors which aid in discrimination between similar patterns. The fused feature vector and each output vector are separately provided to corresponding positional king of the mountain (PKOM) circuits within the classifier network. Each PKOM circuit generates a positional output vector with only one element having a value corresponding to one, the element corresponding to the element of its input vector having the highest contribution. The positional output vectors are mapped into a multidimensional memory space and read by a recognition vector array which generates a plurality of recognition vectors.',\n",
       " 'A method for dynamically allocating network resources while transferring multimedia at variable bit-rates in a network extracts first content features from the multimedia to determine renegotiation points and observation periods. Second content features and traffic features are extracted from the multimedia bit stream during the observation periods. The second content features and the traffic features are combined in a neural network to predict the network resources to be allocated at the renegotiation points.',\n",
       " 'An adaptative source rate control method and apparatus utilizing a neural network are presented for controlling a data transmission of a media object over a communication network. A back propagation method transmitting control parameters related to the operation of a communications network is used for to dynamically adjust the performance of the network, in view of network parameters being sourced to a point of transmission. The bit rate and quantization level of the data stream are dynamically adjusted and shaped by the neural network in response to control parameters.',\n",
       " 'An electronic circuit is disclosed having a sample/hold amplifier connected to an adaptive amplifier. A plurality of such electronic circuits may be configured in an array of rows and columns. An input voltage vector may be compared with an analog voltage vector stored in a row or column of the array and the stored vector closest to the applied input vector may be identified and further processed. The stored analog value may be read out of the synapse by applying a voltage to a read line. An array of the readable synapses may be provided and used in conjunction with a dummy synapse to compensate for an error offset introduced by the operating characteristics of the synapses.',\n",
       " 'A method for dynamically modifying synaptic delays in a neural network includes initializing a delay parameter and operating the neural network. The method further includes dynamically updating the delay parameter based on a program which is based on a statement including the delay parameter.',\n",
       " \"The present invention proposes a dynamically reconfigurable multi-level parallel single instruction multiple data array processing system which has a pixel level parallel image processing element array and a row-parallel array processor. The PE array mainly implements a linear operation which is adapted to be executed in parallel in the low and middle levels of image processing and the RP array implements an operation which is adapted to execute in row-parallel in the low and middle levels of image processing or more complex nonlinear operations. In particularly, such a system can be dynamically reconfigured as an SOM neural network at a low cost of area, and the neural network supports high level of image processing such as a high speed online neural network training and image feature recognition, and completely overcomes a defect that a high level of image processing can't be done by pixel-level parallel processing array in the existing programmable vision chips and parallel vision processors, and facilitates an intelligent and portable real time on-chip vision image system with a complete function at low device cost and low power consumption.\",\n",
       " '\" A dynamically stable associative learning neural network system includes, in its basic architectural unit, at least one each of a conditioned signal input, an unconditioned signal input and an output. Interposed between input and output elements are \"\"patches,\"\" or storage areas of dynamic interaction between conditioned and unconditioned signals which process information to achieve associative learning locally under rules designed for application-related goals of the system. Patches may be fixed or variable in size. Adjustments to a patch radius may be by \"\"pruning\"\" or \"\"budding.\"\" The neural network is taught by successive application of training sets of input signals to the input terminals until a dynamic equilibrium is reached. Enhancements and expansions of the basic unit result in multilayered (multi-subnetworked) systems having increased capabilities for complex pattern classification and feature recognition. \"',\n",
       " 'A dynamically stable associative learning neural system includes a plurality of neural network architectural units. A neural network architectural unit has as input both condition stimuli and unconditioned stimulus, an output neuron for accepting the input, and patch elements interposed between each input and the output neuron. The patches in the architectural unit can be modified and added. A neural network can be formed from a single unit, a layer of units, or multiple layers of units.',\n",
       " 'A dynamically stable associative learning neural network system include a plurality of synapses (122,22-28), a non-linear function circuit (30) and an adaptive weight circuit (150) for adjusting the weight of each synapse based upon the present signal and the prior history of signals applied to the input of the particular synapse and the present signal and the prior history of signals applied to the input of a predetermined set of other synapses. An embodiment of a conditional-signal neuron circuit (100) receives input signals from conditional stimuli and an unconditional-signal neuron circuit (110) receives input signals from unconditional stimuli. A neural network (200) is formed by a set of conditional-signal and unconditional-signal neuron circuits connected by flow-through synapses to form separate paths between each input (215) and a corresponding output (245). In one embodiment, the neural network (200) is initialized by varying the weight of the input signals from conditional stimuli, until a dynamic equilibrium is reached.',\n",
       " 'A dynamically stable associative learning neural network system include a plurality of synapses (122,22-28), a non-linear function circuit (30) and an adaptive weight circuit (150) for adjusting the weight of each synapse based upon the present signal and the prior history of signals applied to the input of the particular synapse and the present signal and the prior history of signals applied to the input of a predetermined set of other collateral synapses. A flow-through neuron circuit (1110) embodiment includes a flow-through synapse (122) having a predetermined fixed weight. A neural network is formed by a set of flow-through neuron circuits connected by flow-through synapses to form separate paths between each input (215) and a corresponding output (245). In one embodiment (200), the neuron network is initialized by setting the adjustable synapses at some value near the minimum weight and setting the flow-through neuron circuits at some arbitrarily high weight. The neural network embodiments are taught by successively application of sets of inputs signals to the input terminals until a dynamic equilibrium is reached.',\n",
       " 'Dynamically updating neural network systems may be implemented to generate, train, evaluate and update artificial neural network data structures used by content distribution networks. Such systems and methods described herein may include generating and training neural networks, using neural networks to perform predictive analysis and other decision-making processes within content distribution networks, evaluating the performance of neural networks, and generating and training pluralities of replacement candidate neural networks within cloud computing architectures and/or other computing environments.',\n",
       " 'A sensor module is provided that monitors the odor within the physical enclosure of a computing device that includes one or more components. A recognition module determines whether the odor within the physical enclosure is indicative of an overheating component that is overheating within the physical enclosure of the computing device. The recognition module may use an artificial neural network (ANN) to determine whether the odor is indicative of an overheating component. An alert module initiates an overheating protocol in response to determining that the odor within the physical enclosure is indicative of an overheating component. The alert module may, for example, alert the user and/or applications that a component is overheating.',\n",
       " 'A method is provided that monitors the odor within the physical enclosure of a computing device that includes one or more components. The method includes determining whether the odor within the physical enclosure is indicative of an overheating component that is overheating within the physical enclosure of the computing device. Determining whether the odor within the physical enclosure may include an artificial neural network (“ANN”) to determine whether the odor is indicative of an overheating component. The method includes initiating an overheating protocol in response to determining that the odor within the physical enclosure is indicative of an overheating component. The method may, for example, alert the user and/or applications that a component is overheating.',\n",
       " 'The present disclosure relates to an early warning and recommendation system for proactive management of a wireless broadband network. Without human intervention, the system processes highly heterogeneous network and non-network data and applies unsupervised machine learning to the data to predict and understand the situations that lead to different network state conditions. More specifically, unsupervised clustering is applied to the data to understand “situations” that can lead to non-normal network state conditions. A deep neural network model of situations is then created to further understand the underlying data relationships between the elements of a situation and network states. The deep neural network model and Reinforcement Learning is used to provide recommendations as to changes in network configuration parameters to improve the state of a predicted situation associated with non-normal network conditions. The system displays warnings and recommendations regarding predicted non-normal network conditions in a user interface for a network operator.',\n",
       " 'In an echo cancelling device including adaptive echo cancellers for cancelling an echo signal to a microphone amplifier and an echo signal to a receiver amplifier, respectively, there is provided a neural network controller responsive to cancelling errors at every taps in each of the cancellers for searching, with reference to a tap producing a maximum error and to the maximum error, a library containing past echo signal patterns to find an optimum echo signal pattern as a searched pattern, changing weighting factors for the taps in each of the cancellers in accordance with the searched pattern, modifying the searched pattern to eliminate the error when the error becomes small, finely adjusting the weighting factors for the taps, and registering the modified pattern in the library.',\n",
       " 'An economic phenomenon predicting and/or analyzing system using a neural network. In the disclosed system, time series data indicating economic phenomena are input to preparation modules, and moving-average values and their differences are generated. One of the preparation modules performs a predetermined process over the time series data indicating an economic phenomenon, i.e. the change of TOPIX, to remove trends. A pattern sorter sorts the trend-free data into a certain number of groups. Average values of various time series data, their differences and the result of pattern sorting are input to input layer neurons of the network. The network is provided in advance with learning information of the change of TOPIX in the past. The output of the output layer neurons will be a value of prediction of the change of TOPIX. For the output of hidden layer neurons, principal components are obtained by principal analysis modules. A correlation analysis module obtains a distribution of frequency of principal component rankings and analyzes the correlation between the explanation variants and the output of the neural network based on the obtained distribution of frequency.',\n",
       " 'A signal processing technique which correlates eddy current inspection data from a tube having a critical tubing defect with a range of predicted burst pressures for the tube is provided. The method can directly correlate the raw eddy current inspection data representing the critical tubing defect with the range of burst pressures using a regression technique, preferably an artificial neural network. Alternatively, the technique deconvolves the raw eddy current inspection data into a set of undistorted signals, each of which represents a separate defect of the tube. The undistorted defect signal which represents the critical tubing defect is related to a range of burst pressures utilizing a regression technique.',\n",
       " 'Edge extracting method and apparatus using a neural network performing a function of diffusing an excitation. The method and apparatus continuously detect a variety of intensity changes of an image via a function having a variety of frequency characteristics. An edge of a fixed object is detected from images continuously input, and an edge of a moving object is selectively detected from the images. The edge extracting apparatus includes a first neural network which receives an image signal. The first neural network derives a Gaussian function representing the regularity of an excitatory response and an inhibitory response to a spot excitation of the image signal. The apparatus also includes a second neural network which detects edges of an image represented by the image signal by convolving the Gaussian function and the image signal.',\n",
       " 'Methods and apparatus are provided for effecting modulation using global scalar values in a spiking neural network. One example method for operating an artificial nervous system generally includes determining one or more updated values for artificial neuromodulators to be used by a plurality of entities in a neuron model and providing the updated values to the plurality of entities.',\n",
       " '\" The present invention provides methods for preventing low train voltages and managing interference, thereby improving the efficiency, reliability, and passenger comfort associated with commuter trains. An algorithm implementing neural network technology is used to predict low voltages before they occur. Once voltages are predicted, then multiple trains can be controlled to prevent low voltage events. Further, algorithms for managing inference are presented in the present invention. Different types of interference problems are addressed in the present invention such as \"\"Interference. During Acceleration\"\", \"\"Interference Near Station Stops\"\", and \"\"Interference During Delay Recovery.\"\" Managing such interference avoids unnecessary brake/acceleration cycles during acceleration, immediately before station stops, and after substantial delays. Algorithms are demonstrated to avoid oscillatory brake/acceleration cycles due to interference and to smooth the trajectories of closely following trains. This is achieved by maintaining sufficient following distances to avoid unnecessary braking/accelerating. These methods generate smooth train trajectories, making for a more comfortable ride, and improve train motor reliability by avoiding unnecessary mode-changes between propulsion and braking. These algorithms can also have a favorable impact on traction power system requirements and energy consumption. \"',\n",
       " 'A speech recognition system that is insensitive to external noise and applicable to actual life includes an A/D converter that converts analog voice signals to digital signals. An FIR filtering section employs powers-of-two conversion to filter the digital signals converted at the A/D converter into numbers of channels. A characteristic extraction section immediately extracts speech characteristics having strong noise-resistance from the output signals of the FIR filtering section without using additional memories. A word boundary detection section discriminates the information of the start-point and the end-point of a voice signal on the basis of the characteristics extracted by the characteristic extraction section. Finally, a normalization/recognition section codes and outputs the final result by carrying out a timing normalization and a classifying process using a radial basis function (RBF) neural network on the basis of the voice characteristics provided by the characteristic extraction section and the information for the start-point and the end-point of the voice signal from the word boundary detection section.',\n",
       " 'A system, method and program product for estimating effort of implementing a system based on a use case specification document. A system is provided that includes: a volumetrics processor that quantifies a structure of the document and evaluates a format of the document; a domain processor that identifies a domain of the system associated with the document; a complexity processor that defines a set of complexity variables associated with the document based on the structure of the document, a format of the document and a domain of the document; and a neural network that estimates an effort based on the set of complexity variables.',\n",
       " 'A system, method and program product for estimating effort of implementing a system based on a use case specification document. A system is provided that includes: a volumetrics processor that quantifies a structure of the document and evaluates a format of the document; a domain processor that identifies a domain of the system associated with the document; a complexity processor that defines a set of complexity variables associated with the document based on the structure of the document, a format of the document and a domain of the document; and a neural network that estimates an effort based on the set of complexity variables.',\n",
       " 'A system, method and program product for estimating effort of implementing a system based on a use case specification document. A method is provided that includes: quantifying a structure of the document and evaluating a format of the document using a computing device; identifying a domain of an application associated with the document; defining a set of complexity variables associated with the document based on the structure of the document, a format of the document and a domain of the document; using a neural network to estimate an effort based on the set of complexity variables; and outputting the effort via a tangible medium.',\n",
       " '\" An artificial intelligence system is provided which makes use of a dual subroutine to adapt weights. Elastic Fuzzy Logic (\"\"ELF\"\") System is provided in which classical neural network learning techniques are combined with fuzzy logic techniques in order to accomplish artificial intelligence tasks such as pattern recognition, expert cloning and trajectory control. The system may be implemented in a computer provided with multiplier means and storage means for storing a vector of weights to be used as multiplier factors in an apparatus for fuzzy control. \"',\n",
       " 'A semiconductor device is disclosed, which includes a multiple negative differential resistance element having negative differential resistance characteristics at at least two places in the current-voltage characteristics, and which is suitable for constructing a neural network having a high density integration and a high reliability.',\n",
       " 'The electric power supply and demand control device judges whether or not electric power shortage is occurred or whether or not electric power surplus is occurred in the electric power supplier and demander provided with the electric power supply and demand control device based on data on total electric energy, the amount of maximum electric power demanded, and the amount of total electric power demanded of the following day in each electric power supplier and demander, predicted by a neural network; receives electric power from other electric power suppliers and demanders provided with the power generation devices and/or the electrical storage devices in the case where electric power shortage is occurred in the electric power supplier and demander; and controls to deliver electric power to other electric power suppliers and demanders in the case where electric power surplus is occurred in the electric power supplier and demander.',\n",
       " 'A synaptic array according to the present invention comprises a plurality of electrically-adaptable elements. Electrons may be placed onto and removed from a floating node in each electrically adaptable element associated with at least one MOS insulated gate field effect transistor, usually the gate of the transistor, in an analog manner, by application of first and second electrical control signals generated in response to an adapt signal. The inputs to all synaptic elements in a row are connected to a common row input line. Adapt inputs to all synaptic elements in a column are connected together to a common column adapt line. The current supplied to all amplifiers in a column is commonly provided by a sense line. In order to adapt the synaptic elements in the M row by N column matrix of the present invention, the voltages to which a given column n of the matrix is to be adapted are placed onto the input voltage lines, and the synaptic elements in column n are then simultaneously adapted by assertion of an adapt signal on the adapt line for column n. The vectors of input voltages for adapting successive columns may be placed sequentially onto the row input voltage lines and used to adapt the columns of synaptic elements by assertion of the adapt signals on the appropriate column adapt lines until the entire array is electrically adapted. After each synaptic element has been adapted, the current flowing through it will be maximized when the voltage at the input of the synaptic element equals the voltage to which the synaptic element has been adapted. An electrically adaptable winner-take-all circuit has its inputs connected to the column-sense lines of the array.',\n",
       " 'An electro-optical method and apparatus for evaluating the dimensions of any protrusion from the threshold of the fabric surface is achieved by bending any length of fabric over a rotating roller so that the contoured area of the protrusion body above the surface can be visualized. The image of the silhouette as seen by a digital camera is processed by image processing algorithms then processed statistically and then by a neural network to yield an integrated picture of the fabric protrusions. The grading results of pilling are well correlated to the human visual method of pilling evaluation.',\n",
       " 'An electrochemical synapse adapted for use in a neural network which includes an input terminal and an output terminal located at a distance of less than 100 microns from the input terminal. A permanent interconnect having controllable conductivity is located between the two inputs. The conductivity of the permanent interconnect is controlled by either growing or eliminating metallic whiskers between the inputs. The growth and elimination of whiskers provides a rapid and controllable electrochemical synapse. Partial neural network systems are disclosed utilizing the electrochemical synapse.',\n",
       " 'Non-invasive quantitative in-vivo electromagnetic evaluation of bone is performed by subjecting bone to an electrical excitation waveform supplied to a single magnetic field coil near the skin of a bony member, and involving a repetitive finite duration signal consisting of plural frequencies that are in the range 0 Hz-200 MHz. Signal-processing of a bone-current response signal and a bone-voltage response signal is operative to sequentially average the most recently received given number of successive bone-current and bone-voltage response signals to obtain an averaged per-pulse bone-current signal and an averaged per-pulse bone-voltage signal, and to produce their associated Fourier transforms. These Fourier transforms are further processed to obtain the inductively determined frequency-dependent bone-admittance function. A neural network, configured to generate an estimate of one or more of the desired bone-related quantities, is connected for response to the bone-admittance function, whereby to generate the indicated estimates of bone status, namely, bone-density, bone-architecture, bone-strength and bone-fracture risk. In another embodiment, a stochastic electromagnetic field generated by a single magnetic field coil is used to therapeutically treat living tissue in vivo.',\n",
       " \"Non-invasive quantitative in-vivo electromagnetic evaluation of bone is performed by subjecting bone to an electrical excitation wave-form supplied to a pair of electrodes on opposite sides of a bony member, and involving a repetitive finite duration signal consisting of plural frequencies that are in the range 0 Hz-200 MHz. Signal-processing of a bone-current response signal and a bone-voltage response signal is operative to sequentially average the most recently received given number of successive bone-current and bone-voltage response signals to obtain an averaged per-pulse bone-current signal and an averaged per-pulse bone-voltage signal, and to produce their associated Fourier transforms. These Fourier transforms are further processed to obtain the frequency-dependent bone-admittance function. In a separate operation, the same electrodes respond to the same excitation signal via a medium of known electromagnetic properties and path length to establish a reference-voltage signal and reference-current signal, which are processed to produce their associated Fourier transforms. These two Fourier transforms are further processed to produce a frequency-dependent reference-admittance function, which together with the bone-admittance function are processed to derive the frequency-dependent bone-conductivity real function, .sigma.'.sub.b (f), and frequency-dependent dielectric bone-permittivity real function, .di-elect cons.'.sub.b (f). The function .sigma.'.sub.b (f) is related to the energy loss in the bony member, and the function .di-elect cons.'.sub.b (f) is related to the energy storage in the bony member. A neural network, configured to generate an estimate of one or more of the desired bone-related quantities, is connected for response to the functions .sigma.'.sub.b (f) and .di-elect cons.'.sub.b (f), whereby to generate the indicated estimates of bone status, namely, bone-density, bone-architecture, bone-strength and bone-fracture risk.\",\n",
       " 'A method, system and computer program product for managing false alarms in a security system. A detection zone is established. An alarm event is triggered based on the detection of a tag in the detection zone using an initial alarm trigger sensitivity. The initial alarm trigger sensitivity is based on an initial set of one or more detection criteria. The set of detection criteria is modified to adjust the alarm trigger sensitivity of the security system.',\n",
       " 'A method of controlling the movements of a multi-actuator electro-mechanical system having a matrix of locally interconnected analog cells associated therewith is provided. Each cell represents a hardware implementation of a model of fuzzy inference rules. The model includes a fuzzy circuit architecture which may be implemented in an integrated circuit with VLSI CMOS technology that generates and controls a reaction diffusion mechanism typical of auto-waves using a fuzzy neural network. The fuzzy neural network defines the functional relationships that may duplicate simultaneous reaction diffusion equations. The duplication of the simultaneous reaction diffusion equations is provided using two sets of fuzzy rules processing, in a linguistic manner, the state variables of the cells. An oscillatory type dynamic is imposed on each cell where two dynamic processes having different kinetic characteristics coexist.',\n",
       " 'Neuromorphic circuits are multi-cell networks configured to imitate the behavior of biological neural networks. A neuromorphic circuit is provided which comprises a network of neurons each identified by a neuron address in the network, each neuron being able to receive and process at least one input signal and then later emit on an output of the neuron a signal representing an event which occurs inside the neuron, and a programmable memory composed of elementary memories each associated with a respective neuron. The elementary memory, which is a memory of post-synaptic addresses and weights, comprises an activation input linked by a conductor to the output of the associated neuron to directly receive an event signal emitted by this neuron without passing through an address encoder or decoder. The post-synaptic addresses extracted from an elementary memory activated by a neuron are applied, with associated synaptic weights, as inputs to the neural network.',\n",
       " 'An electronic comparison system includes input stages that successively provide bits of code words. One-shots connected to respective stages successively provide a first bit value until receiving a bit having a non-preferred value concurrently with an enable signal, and then provide a second, different bit value. An enable circuit provides the enable signal if at least one of the one-shots is providing the first bit value. A neural network system includes a crossbar with row and column electrodes and resistive memory elements at their intersections. A writing circuit stores weights in the elements. A signal source applies signals to the row electrodes. Comparators compare signals on the column electrodes to corresponding references using domain-wall neurons and store bit values in CMOS latches by comparison with a threshold.',\n",
       " 'An electronic comparison system includes input stages that successively provide bits of code words. One-shots connected to respective stages successively provide a first bit value until receiving a bit having a non-preferred value concurrently with an enable signal, and then provide a second, different bit value. An enable circuit provides the enable signal if at least one of the one-shots is providing the first bit value. A neural network system includes a crossbar with row and column electrodes and resistive memory elements at their intersections. A writing circuit stores weights in the elements. A signal source applies signals to the row electrodes. Comparators compare signals on the column electrodes to corresponding references using domain-wall neurons and store bit values in CMOS latches by comparison with a threshold.',\n",
       " 'A musical tone parameter generating method and a musical tone generating device of this invention feature that when data inputted by a player is inputted into a neural network as input pattern, the neural network infers the parameters necessary to specify a musical tone wave form to be formed. This makes it possible to get parameters other than those stored in a memory by inferring, which increases variation of the musical tone to be generated.',\n",
       " 'An electronic synapse circuit is disclosed for multiplying an analog weight signal value by a digital state signal value to achieve a signed product value as a current which is capable of being summed with other such synapse circuit outputs. The circuit employs a storage multiplying digital-to-analog converter which provides storage for the analog weight signal value. Additional circuitry permits programming different analog weight signal values into the circuit, performing four-quadrant multiplication, generating a current summable output, and maintaining the stored analog weight signal value at a substantially constant value independent of the digital state signal values.',\n",
       " 'An electronic synapse circuit is disclosed for multiplying an analog weight signal value by a digital state signal value to achieve a signed product value as a current which is capable of being summed with other such synapse circuit outputs. The circuit employs a storage multiplying digital-to-analog converter which provides storage for the analog weight signal value. Additional circuitry permits programming different analog weight signal values into the circuit, performing four-quadrant multiplication, generating a current summable output, and maintaining the stored analog weight signal value at a substantially constant value independent of the digital state signal values.',\n",
       " 'Techniques are used to detect and identify analytes. Techniques are used to fabricate and manufacture sensors to detect analytes. An analyte (1810) is sensed by sensors (1820) that output electrical signals in response to the analyte. The electrical signals are preprocessed (1830) by filtering and amplification. In an embodiment, this preprocessing includes adapting the sensor and electronics to the environment in which the analyte exists. The electrical signals are further processed (1840) to classify and identify the analyte, which may be by a neural network.',\n",
       " 'Techniques are used to detect and identify analytes. Techniques are used to fabricate and manufacture sensors to detect analytes. An analyte (1810) is sensed by sensors (1820) that output electrical signals in response to the analyte. The electrical signals are preprocessed (1830) by filtering and amplification. In an embodiment, this preprocessing includes adapting the sensor and electronics to the environment in which the analyte exists. The electrical signals are further processed (1840) to classify and identify the analyte, which may be by a neural network.',\n",
       " 'An electrophotographic process control device for an electrophotographic image forming apparatus. A neural network is incorporated in the control device for estimating the state of the image forming unit. Parameters of the kind which should not be frequently measured, e.g., the surface potential of a photoconductive element and the amount of toner deposition thereon and parameters which are not easy to measure are determined by inference so as to control each section of the apparatus in an optimum way.',\n",
       " 'An electrophotographic process control device capable of controlling the supply of a toner in such a manner as to stabilize an image against changes in the characteristics of a photoconductive element and in toner density. At the learning stage of a neural network, data from sensors are applied to the input layer of the network while a latent image gamma characteristic indicative of a relation between the amount of exposure and the potential of an image area is used as learning data to be given via the output layer of the network. At a control stage, the data from the sensors are applied to the input layer of the network, as at the learning stage, and the amount of exposure is so controlled as to set up a desired potential in an image area on the basis of a latent image gamma characteristic obtainable from the output layer of the network.',\n",
       " 'A simple format is disclosed and referred to as Elementary Network Description (END). The format can fully describe a large-scale neuronal model and embodiments of software or hardware engines to simulate such a model efficiently. The architecture of such neuromorphic engines is optimal for high-performance parallel processing of spiking networks with spike-timing dependent plasticity. The format is specifically tuned for neural systems and specialized neuromorphic hardware, thereby serving as a bridge between developers of brain models and neuromorphic hardware manufactures.',\n",
       " 'An elevator control apparatus determines the time required for a call to reach a hall and controls an operation of the car using the obtained estimated travel time. The elevator control apparatus includes an input data conversion unit for converting traffic data, including car position, car direction data, and data regarding car calls and hall calls into data that can be used as input data to a neural network. An estimated travel time operation unit including an input layer is provided for taking in the input data. An output layer is provided for outputting the estimated travel time. An intermediate layer is provided between the input and output layers in which a weighting factor is set. The estimated travel time operation unit comprises a neural network and an output data conversion unit for converting the estimated travel time output from the output layer into data that can be used for a predetermined control operation.',\n",
       " 'An elevator control apparatus capable of predicting reversion floors of elevator cages accurately. The control apparatus comprises a neural network, in which traffic state data are fetched into the neural network, so that predicted values of floors where the moving direction of each cage is reversed are calculated as predicted reversion floors. In the elevator control apparatus, reversion floors near true reversion floors can be predicted flexibly correspondingly to traffic state and traffic volume.',\n",
       " 'A remaining response time for an elevator car under consideration for assignment to a newly registered hall call is estimated by using a neural network. The neural network or any other downstream module may be standardized for use in any building by use of an upstream fixed length stop description that summarizes the state of the building at the time of the registration of the new hall call for one or more postulated paths of each and every car under consideration for answering the new hall call.',\n",
       " 'A rule base storing control rule sets predicts elevator group management performance, such as waiting time distribution, obtained when applying each rule set stored in the rule base to the current traffic situation, and selects a rule set in accordance with a performance prediction. In addition, a weight database stores weighting parameters of a neural network corresponding to the rule sets and performance learning measures for correcting the weighting parameters in accordance with learning by the neural network. As a result, the optimal rule set is applied at all times for group management control of the elevators to provide passengers with excellent service and to enhance prediction accuracy in correspondence with the actual operational situation of the elevators.',\n",
       " 'A real time kernel for deploying health monitoring functions in Condition Base Maintenance (CBM) and Real Time Monitoring (RTM) systems is disclosed in this invention. The Optimized Neuro Genetic Fast Estimator (ONGFE) allows embedding failure detection, identification, and prognostics (FDI&P) capability by using Intelligent Software Element (ISE) based upon Artificial Neural Network (ANN). ONGFE enables embedded fast and on-line training for designing ANNs, which perform very high performance FDI&P functions. An advantage is the optimization block based on pseudogenetic algorithms, which compensate for effects due to initial weight values and local minimums without the computational burden of genetic algorithms. It provides a synchronization block for communication with secondary diagnostic modules. Also a scheme for conducting sensor data validation is embedded in Smart Sensors (SS). The algorithms are designed for a distributed, scalar, and modular deployment. The system electronics is built upon a network of smart sensors and a health monitoring computer for providing data acquisition capability and distributed computational power.',\n",
       " 'An integrated circuit processor having a processing unit that includes a logical circuit with multiple transistors and a top metal landing pad, and an embedded STT memory. The STT memory includes a dielectric layer formed on the top metal landing pad, an adhesion and topography planarization (ATP) layer formed on the dielectric layer, and an MTJ film layer disposed on the ATP layer. The memory may also include bit lines formed on the MTJ film layer. The ATP layer may have multiple layers such as a top layer and a bottom layer. The top layer may act as an etch stop for etching the MTJ film layer on the top. The ATP layer may have a total thickness of 500 A to 4000 A. The bit lines can be configured to send data to the logic circuit of the processing unit to perform one or more convolution neural network computations.',\n",
       " 'The present invention relates to a method of embedding a neural network into an application program such as a spreadsheet program. The method comprises providing an application program in which information is stored in rows and columns or a database containing fields and records and embedding a neural network in the application program or database using the stored information. The embedding step includes allocating unused memory in the application program and creating both a neural network engine and an application interface structure from the unused memory. Once the neural network engine and an application interface structure have been created, the neural network may be trained using variable numerical and symbolic data stored within the application program. Once training is completed, the neural network is ready for use, merely by using a recall function built into the applications program.',\n",
       " 'Methods and apparatus are provided pertaining to a design of experiments. The method comprises generating a data set from historical data; identifying and removing any fault data points in the data set so as to create a revised data set; supplying the data points from the revised data set into a nonlinear neural network model; and deriving a simulator model characterizing a relationship between the input variables and the output variables. The apparatus comprises means for generating a data set from historical data; means for identifying and removing any fault data points in the data set so as to create a revised data set; means for supplying the data points from the revised data set into a nonlinear neural network model; and means for deriving a simulator model characterizing a relationship between the input variables and the output variables.',\n",
       " 'A plurality of neural networks or other models can be used in employee selection technologies. A hiring recommendation can be based at least on processing performed by a plurality of neural networks. For example, parallel or series processing by neural networks can be performed. A neural network can be coupled to one or more other neural networks. A binary or other n-ary output can be generated by one or more of the neural networks. In a series arrangement, candidates can be processed sequentially in multiple stages, and those surviving the stages are recommended for hire.',\n",
       " 'The present invention provides a method and an apparatus to enable desired wireless connectivity in a high frequency and/or high speed wireless local area network for providing mobile communications to a user of a wireless communication device which may be otherwise unable to connect to the high frequency and/or speed wireless local area network in response to a request for a wireless service. By using a chipset disposed in another wireless communication device, a neural network may be formed for enabling such wireless connectivity. In one embodiment, availability of wireless connectivity may be determined to a first user of a wireless service at a first wireless communication device to communicate with an access point associated with a Wi-Fi wireless network that offers the wireless service. Absent such wireless connectivity at the first wireless communication device, additional bandwidth available at a second wireless communication device may be used to connect the first user at the first wireless communication device over another network that offers the wireless service, for example, a wide area network capable of communicating mobile or cellular data. Accordingly, a user that desires use of a wireless service in a wireless network of sparsely populated Wi-Fi access points may obtain desired wireless connectivity for mobile communications across a relatively longer range and/or at much higher transfer speeds than otherwise available.',\n",
       " 'Techniques for reconstructing a signal encoded with a time encoding machine (TEM) using a recurrent neural network including receiving a TEM-encoded signal, processing the TEM-encoded signal, and reconstructing the TEM-encoded signal with a recurrent neural network.',\n",
       " 'Methods and systems according to the present disclosure improve upon known biometric security systems by not permanently storing (e.g., for later comparison as in known systems) the actual image of the biometric characteristic. Instead, an image of a biometric identifier (e.g., retina, fingerprint, etc.) may be used to form a key which may be used to secure and provide access to data. The key may be formed, in embodiments, using a neural network and/or a random input (e.g., a vector of random characters), for example. The image of the biometric identifier may be discarded, and thus may not be vulnerable to theft. In an embodiment, the key may be used in a key-based encryption system.',\n",
       " 'A method for generating a system for predicting saliency in an image and method of use of the prediction system are described. Attention maps for each of a set of training images are used to train the system. The training includes passing the training images though a neural network and optimizing an objective function over the training set which is based on a distance measure computed between a first probability distribution computed for a saliency map output by the neural network and a second probability distribution computed for the attention map for the respective training image. The trained neural network is suited to generation of saliency maps for new images.',\n",
       " 'The present invention is directed to a deep neural network (DNN) having a triplet network architecture, which is suitable to perform speaker recognition. In particular, the DNN includes three feed-forward neural networks, which are trained according to a batch process utilizing a cohort set of negative training samples. After each batch of training samples is processed, the DNN may be trained according to a loss function, e.g., utilizing a cosine measure of similarity between respective samples, along with positive and negative margins, to provide a robust representation of voiceprints.',\n",
       " 'A device and a method for determining the interaction position and energy measurement of a radiation detector. A plurality of waveshifting optical fiber are positioned on the surface of a scintillator which is subjected to incident radiation causing the release of photons of a first wavelength from the scintillator which are absorbed by the optical fiber with a portion of the released photons being reemitted from one end of the fibers. The reemitted photons are measured and the centroid of the distribution of these measured photons is determined in order to provide an indication of the interaction position of incident radiation. A measurement of photons generated by the incident radiation which pass through the fibers but which are not transported down said fibers provide an indication of the energy of the incident radiation. In a further embodiment, a crossed wire anode photomultiplier is used in conjunction with a plurality of scintillating fibers embedded in grooves on both sides of the scintillator in order to provide an accurate position for the centroid of a more extended distribution of incident photons. Furthermore a designed neural network extracts, from the crossed wire anode photomultiplier output pulses, a linear position to provide real time imaging.',\n",
       " 'In one embodiment, the present invention is a retrofit to rapidly transition to existing consumer refrigerator-freezer product lines in order to greatly eliminate wasted energy. This occurs because spurious opening of the system doors allows heat to enter with the deleterious side effect of causing the compressor to cycle on and off. This, in turn, consumes more power than if such duty cycles could be predicted, which would allow for their smoothing. The invention takes advantage of existing sensor technologies and develops a computational framework for their fusion for the prediction of a dependency, which controls operation of the compressor. Instances of a predictive schema are evolved and this approach allows for greater accuracy in less time than would be possible using competing neural network or support vector machine technologies. A novel evolutionary algorithm is included, which is so defined as to allow its execution on a lower-end computer.',\n",
       " 'A method, system and machine-readable storage medium for monitoring an engine using a cascaded neural network that includes a plurality of neural networks is disclosed. In operation, the method, system and machine-readable storage medium store data corresponding to the cascaded neural network. Signals generated by a plurality of engine sensors are then inputted into the cascaded neural network. Next, a second neural network is updated at a first rate, with an output of a first neural network, wherein the output is based on the inputted signals. In response, the second neural network outputs at a second rate, at least one engine control signal, wherein the second rate is faster than the first rate.',\n",
       " 'A method, system and machine-readable storage medium for monitoring an engine using a cascaded neural network that includes a plurality of neural networks is disclosed. In operation, the method, system and machine-readable storage medium store data corresponding to the cascaded neural network. Signals generated by a plurality of engine sensors are then inputted into the cascaded neural network. Next, a second neural network is updated at a first rate, with an output of a first neural network, wherein the output is based on the inputted signals. In response, the second neural network outputs at a second rate, at least one engine control signal, wherein the second rate is faster than the first rate.',\n",
       " 'A Method for estimating NOx creation in a combustion process of a four-stroke internal combustion engine includes monitoring engine sensor inputs, modeling parameters descriptive of said combustion process based upon said engine sensor inputs, and estimating NOx creation with an artificial neural network based upon said parameters.',\n",
       " 'An interface for a neural network includes a generalized data translator and a certainty filter in the data path including the neural network for rendering a decision on raw data, possibly from a data processing application. The data translator is controlled with user-definable parameters and procedures contained in a property list in order to manipulate translation, truncation, mapping (including weighting) and other transformations of the raw data. The neuron to which the output of the data translator is applied is controlled by a code index contained in an action list. An external certainty threshold is also provided, preferably by the action list to filter the output of the neural network. The core program used with the ConExNS neurons for system maintenance also includes further core operations and size maintenance operations responsive to commands from the user of an application to cause operations to be performed with in the neural network as well as to create and update the property and action lists.',\n",
       " 'An enhanced neural network shell for application programs is disclosed. The user is prompted to enter in non-technical information about the specific problem type that the user wants solved by a neural network. The user also is prompted to indicate the input data usage information to the neural network. Based on this information, the neural network shell creates a neural network data structure by automatically selecting an appropriate neural network model and automatically generating an appropriate number of inputs, outputs, and/or other model-specific parameters for the selected neural network model. The user is no longer required to have expertise in neural network technology to create a neural network data structure.',\n",
       " 'An enhanced neural network shell for application programs is disclosed. The user is prompted to enter in non-technical information about the specific problem type that the user wants solved by a neural network. The user also is prompted to indicate the input data usage information to the neural network. Based on this information, the neural network shell creates a neural network data structure by automatically selecting an appropriate neural network model and automatically generating an appropriate number of inputs, outputs, and/or other model-specific parameters for the selected neural network model. The user is no longer required to have expertise in neural network technology to create a neural network data structure.',\n",
       " \"A predictive model, for example, a neural network, evaluates individual debt holder accounts and predicts the amount that will be collected on each account based on learned relationships among known variables. The predictive model is generated using historical data of delinquent debt accounts, the collection methods used to collect the debts in the accounts, and the success of the collection methods. In one embodiment, the predictive model is generated using profiles of delinquent debt accounts summarizing patterns of events in the accounts, and the success of the collection effort in each account. In another embodiment, the predictive model includes a mathematical representation of the collector's notes created during the collection period for each account.\",\n",
       " \"A predictive model, for example, a neural network, evaluates individual debt holder accounts and predicts the amount that will be collected on each account based on learned relationships among known variables. The predictive model is generated using historical data of delinquent debt accounts, the collection methods used to collect the debts in the accounts, and the success of the collection methods. In one embodiment, the predictive model is generated using profiles of delinquent debt accounts summarizing patterns of events in the accounts, and the success of the collection effort in each account. In another embodiment, the predictive model includes a mathematical representation of the collector's notes created during the collection period for each account.\",\n",
       " 'Methods of creating and using robust neural network ensembles are disclosed. Some embodiments take the form of computer-based methods that comprise receiving a set of available inputs; receiving training data; training at least one neural network for each of at least two different subsets of the set of available inputs; and providing at least two trained neural networks having different subsets of the available inputs as components of a neural network ensemble configured to transform the available inputs into at least one output. The neural network ensemble may be applied as a log synthesis method that comprises: receiving a set of downhole logs; applying a first subset of downhole logs to a first neural network to obtain an estimated log; applying a second, different subset of the downhole logs to a second neural network to obtain an estimated log; and combining the estimated logs to obtain a synthetic log.',\n",
       " 'A neural network is used to process a set of ranking features in order to determine the relevancy ranking for a set of documents or other items. The neural network calculates a predicted relevancy score for each document and the documents can then be ordered by that score. Alternate embodiments apply a set of data transformations to the ranking features before they are input to the neural network. Training can be used to adapt both the neural network and certain of the data transformations to target environments.',\n",
       " 'An epithelial detector and method for automatically identifying epithelial portions of a tissue sample, includes: staining the tissue sample with at least two dyes; applying a color transformation to a color image of the tissue sample to obtain one or more color channels; and applying a trained convolutional neural network to the color channels to obtain a decision for position in the tissue as to whether it is inside or outside an epithelial layer. Also, a method for training the convolutional neural network.',\n",
       " 'An error absorbing system for absorbing errors through a weight correction is provided in a neuron computer for receiving an analog input signal through a first analog bus in a time divisional manner, performing a sum-of-the-products operation, and outputting an analog output signal to a second analog bus. The error absorbing system includes a dummy node for producing a fixed voltage to an analog bus in a test mode. The dummy node is connected to the analog bus of the neural network. An error measuring unit compulsorily inputs 0 volts to the first analog bus through the dummy node in a first state of a test mode and detects an offset voltage produced in an analog neuron processor through the second analog bus. A weight correcting unit, in a second state of the test mode, determines a temporary weight between the dummy node and the neuron processor. The temporary weight is multiplied by the fixed voltage produced by the dummy node, based on an offset voltage of respective neuron processors. The weight correcting unit calculates a correct weight using a gain based on the detection output voltage output from the second analog bus. A weight memory stores the weight corrected by the weight correcting unit.',\n",
       " 'Method and apparatus of error back-propagation for use in a neural network system. A first group (11) of processing devices (13.sub.1, 13.sub.2, 13.sub.3) performs the resolving steps and a second group (12) of analogous processing devices (13.sub.4, 13.sub.5) performs the training steps while backpropagating errors calculated in a central processing device (10). The synaptic coefficient matrix C.sub.ij of the first group and the transposed matrix T.sub.ji of the second group are simultaneously updated. This updating of the synaptic coefficients can be performed by means of multipliers (34.sub.1 to 34.sub.N) and adders (37.sub.1 to 37.sub.N).',\n",
       " 'A communication system and method that translates a first plurality of information symbols into a plurality of code words, transmits the plurality of code words through a communication channel receives the plurality of code words transmitted through the communication channel, deciphers the plurality of code words transmitted through the communication channel into a second plurality of information symbols that correspond to the first set plurality of information symbols, wherein the plurality of code words are derived from a reverse dynamical flow within a first neural network.',\n",
       " 'Code word generation by recursive reverse flows in a neural network, and transmission systems encoding using such code words. The neural network (30) may be an array of operational amplifiers (34) as neurons with inverted amplifier output feedback through resistors (32) as the interconnection strengths to the amplifier inputs. The inversion of the amplifier output implies the dynamical flow of the neuron states is away from stored vectors; this contrasts with Hopfield networks which have a dynamical flow to stored states and thus an associative memory function. The method of generating code words recursively uses this reverse dynamical flow with previously generated code words as the stored vectors. That is, the already generated code words define the stored vectors in a neural network, then the reverse dynamical flow finds a new vector away from the stored vectors, and lastly this new vector defines the next code word and the cycle repeats with the augmented set of stored vectors.',\n",
       " 'An error correction circuit is provided which uses NMOS and PMOS synapses to form neural network type responses to a coded multi-bit input. Use of MOS technology logic in error correction circuits allows such devices to be easily interfaced with other like technology circuits without the need to use distinct interface logic as with conventional error correction circuitry.',\n",
       " 'An error correction circuit is provided which uses NMOS and PMOS synapses to form network type responses to a coded multi-bit input. Use of MOS technology logic in error correction circuits allows such devices to be easily interfaced with other like technology circuits without the need to use distinct interface logic as with conventional error correction circuitry.',\n",
       " 'A controller directs a process primarily performed to control emission of a particular pollutant into the air. The process has multiple process parameters (MPPs), including a parameter representing an amount of the particular pollutant. The controller includes either a neural network process model or a non-neural network process model. In either case, the model represents a relationship between a first of the MPPs and one or more of the other MPPs. The one or more other MPPs include a second of the MPPs which is other than the parameter representing the amount of the emitted particular pollutant. Also included is a processor configured with logic to estimate a value of the second MPP, and to direct control of the first MPP based on the estimated value of the second MPP and the model.',\n",
       " 'A method for estimating an achievable power production of a wind turbine, which is operated with a reduced power set point is provided. The method includes determining the values of at least two parameters, inputting the values of the at least two parameters into a neural network, and outputting an output value from the neural network. The at least two parameters are indicative of an operating condition of the wind turbine. Thereby, the output value is an estimate of the achievable power production of the wind turbine. A control system which is adapted to carry out the described power estimation method is also provided. Furthermore, a wind turbine which uses the control system adapted to carry out the described power estimation method is provided.',\n",
       " 'An economic parameter estimator is provided for a process that has multiple process parameters (MPPs) and is performed to control emission of a pollutant into the air. The performance of the process is associated with one or more economic factors (EFs). The estimator includes either a neural network process model or a non-neural network process model. In either case, the model represents a relationship between one or more of the MPPs and an economic parameter. Also included is a processor configured with logic, e.g. programmed software, to estimate a monetary value of the economic parameter based on a value of each of the one or more MPPs, a value of each of at least one of the one or more EFs, and the one model.',\n",
       " 'In one embodiment of the present invention, a loudspeaker parameter estimation subsystem efficiently and accurately estimates parameter values for a lumped parameter model (LPM) of a loudspeaker. In operation, the loudspeaker parameter estimation subsystem trains a neural network model based on responses generated via the lumped parameter model and the corresponding sets of parameter values. Subsequently, based on the relationship between the measured output response of a loudspeaker to an input stimulus, the loudspeaker parameter estimation subsystem estimates parameter values for the LPM of the loudspeaker. Advantageously, by sagaciously estimating parameter values for the LPM of loudspeakers, these NN-based techniques enable designers to leverage the LPM to reliably improve the design of loudspeakers, perform nonlinear correction of loudspeakers, and the like.',\n",
       " 'Features are disclosed for estimating affine transforms in Log Filter-Bank Energy Space (“LFBE” space) in order to adapt artificial neural network-based acoustic models to a new speaker or environment. Neural network-based acoustic models may be trained using concatenated LFBEs as input features. The affine transform may be estimated by minimizing the least squares error between corresponding linear and bias transform parts for the resultant neural network feature vector and some standard speaker-specific feature vector obtained for a GMM-based acoustic model using constrained Maximum Likelihood Linear Regression (“cMLLR”) techniques. Alternatively, the affine transform may be estimated by minimizing the least squares error between the resultant transformed neural network feature and some standard speaker-specific feature obtained for a GMM-based acoustic model.',\n",
       " 'A method for estimating a loading criterion relating to the load experienced by a structural component of an aircraft, and assistance with detecting a so-called “hard” landing. The method includes measuring parameters of the aircraft and calculating at least one loading criterion for the loading of the structural component using at least one neural network receiving the parameters as input. Assistance with detecting a hard landing then includes determining of a time of impact of the aircraft on a landing strip from the measured parameters, then estimating a plurality of the parameters at the determined time of impact so as to calculate the at least one loading criterion relating to the loading of the structural component.',\n",
       " 'A neural network is used to combine one or more estimates of a physiologic parameter with one or more associated signal quality metrics, creating a more accurate estimate of said physiologic parameter, as well as a second estimate of the accuracy of said physiologic parameter estimate.',\n",
       " 'An artificial neural network may be configured to test the impact of certain input parameters. To improve testing efficiency and to avoid test runs that may not alter system performance, the effect of input parameters on neurons or groups of neurons may be determined to classify the neurons into groups based on the impact of certain parameters on those groups. Groups may be ordered serially and/or in parallel based on the interconnected nature of the groups and whether the output of neurons in one group may affect the operation of another. Parameters not affecting group performance may be pruned as inputs to that particular group prior to running system tests, thereby conserving processing resources during testing.',\n",
       " 'The invention relates to a method for performing acid fracturing operations of an oilfield. The method includes obtaining a plurality of historical data of acid fracturing treatments of the oilfield, generating a neural network based on the plurality of historical data, identifying a stimulation parameter, in the neural network, associated with optimal performance of the acid fracturing treatments, and establishing a best practice procedure for performing the acid fracturing operations based on the stimulation parameter.',\n",
       " 'An evaluation system (10) for evaluating media is described. The system is particularly suitable for evaluating banknotes to determine their suitability for use in an ATM. The system comprises sensing means (12) for sensing properties of media (18) including the location of any imperfection in the media, and an evaluation module (16) for evaluating imperfections in the media(18). The evaluation module (16) includes a classifier (52) comprising an artificial neural network (60) and fuzzy logic (66). The evaluation module (16) may include a plurality of classifiers (52), and a second level classifier (56) for generating a suitability index (20) from the outputs of the first level classifiers (52). A method of evaluating media is also described.',\n",
       " 'Apparatus for measuring neural network activity with a textured semiconductor substrate. Sensor elements have a respective detection electrode on the substrate surface for detecting neural network signals, and the detected neural signals are a basis for outputting electrical sensor output signals via respective sensor element outputs. Each amplifier element has an input and an output. Each of the sensor elements has associated therewith one of the amplifier elements whose input is connected to the sensor output of the respective sensor element. The amplified sensor output signal is output the amplifier output as an amplifier output signal. An activity evaluator has an input, which is connected to at least one of the amplifier outputs, and an output. The activity evaluation device produces an activity signal, which is a measure of activity of the neural network, based on the amplifier output signal, and outputs the amplifier output signal via the evaluation output.',\n",
       " 'In embodiments of event image curation, a computing device includes memory that stores a collection of digital images associated with a type of event, such as a digital photo album of digital photos associated with the event, or a video of image frames and the video is associated with the event. A curation application implements a convolutional neural network, which receives the digital images and a designation of the type of event. The convolutional neural network can then determine an importance rating of each digital image within the collection of the digital images based on the type of the event. The importance rating of a digital image is representative of an importance of the digital image to a person in context of the type of the event. The convolutional neural network generates an output of representative digital images from the collection based on the importance rating of each digital image.',\n",
       " \"A device (10) for processing events (4), including an identifier (8) identifying the event's type, and at least one parameter carrying information about a process, includes an event selector (20) and an event type recognizer (30). The device (10) is configured for receiving an event (4), providing the event (4) to the event selector (20), and providing the identifier (8) to the event type recognizer (30). The event selector (20) stores the provided event (4). The event type recognizer (30) determines, using at least one neural network unit, whether the identifier (8) corresponds to a type for which a subscription exists, and, if so, it causes the event selector (20) to transmit the event (4S) for processing by one or more applications. Furthermore, the device (10) is configured for allowing one or more types of event to be subscribed to. The invention also relates to methods for processing events (4).\",\n",
       " 'The present invention relates to a control system comprising a control interface between one or more wind turbine generators and a power grid, where the wind turbine generators are coupled to the power grid and contribute to the power production of the grid. The control interface is arranged to receive a set of event data. In embodiments, the set of event data may be any data available to a SCADA system. The set of event data is analyzed in terms of predetermined event rules comprising at least one predefined event condition and a set of adaptive event conditions. Based on the analysis an event output is provided in order to control a parameter of the one or more wind turbine generators. In embodiments, the control system may be implemented in, or in connection with a SCADA system, moreover, the event output may be based on fuzzy logic, a neural network or statistical analysis.',\n",
       " 'The present invention provides an event-driven universal neural network circuit. The circuit comprises a plurality of neural modules. Each neural module comprises multiple digital neurons such that each neuron in a neural module has a corresponding neuron in another neural module. An interconnection network comprising a plurality of digital synapses interconnects the neural modules. Each synapse interconnects a first neural module to a second neural module by interconnecting a neuron in the first neural module to a corresponding neuron in the second neural module. Corresponding neurons in the first neural module and the second neural module communicate via the synapses. Each synapse comprises a learning rule associating a neuron in the first neural module with a corresponding neuron in the second neural module. A control module generates signals which define a set of time steps for event-driven operation of the neurons and event communication via the interconnection network.',\n",
       " 'The present invention provides an event-driven universal neural network circuit. The circuit comprises a plurality of neural modules. Each neural module comprises multiple digital neurons such that each neuron in a neural module has a corresponding neuron in another neural module. An interconnection network comprising a plurality of digital synapses interconnects the neural modules. Each synapse interconnects a first neural module to a second neural module by interconnecting a neuron in the first neural module to a corresponding neuron in the second neural module. Corresponding neurons in the first neural module and the second neural module communicate via the synapses. Each synapse comprises a learning rule associating a neuron in the first neural module with a corresponding neuron in the second neural module. A control module generates signals which define a set of time steps for event-driven operation of the neurons and event communication via the interconnection network.',\n",
       " 'The present invention provides an event-driven universal neural network circuit. The circuit comprises a plurality of neural modules. Each neural module comprises multiple digital neurons such that each neuron in a neural module has a corresponding neuron in another neural module. An interconnection network comprising a plurality of digital synapses interconnects the neural modules. Each synapse interconnects a first neural module to a second neural module by interconnecting a neuron in the first neural module to a corresponding neuron in the second neural module. Corresponding neurons in the first neural module and the second neural module communicate via the synapses. Each synapse comprises a learning rule associating a neuron in the first neural module with a corresponding neuron in the second neural module. A control module generates signals which define a set of time steps for event-driven operation of the neurons and event communication via the interconnection network.',\n",
       " 'Apparatus, and an accompanying method, for use in, e.g., a neural network-based optical character recognition (OCR) system (5) for accurately classifying each individual character extracted from a string of characters, and specifically for generating a highly reliable confidence measure that would be used in deciding whether to accept or reject each classified character. Specifically, a confidence measure, associated with each output of, e.g., a neural classifier (165), is generated through use of all the neural activation output values. Each individual neural activation output provides information for a corresponding atomic hypothesis of an evidence function. This hypothesis is that a pattern belongs to a particular class. Each neural output is transformed (1650) through a pre-defined monotonic function into a degree of support in its associated evidence function. These degrees of support are then combined (1680, 1690) through an orthogonal sum to yield a single confidence measure associated with the specific classification then being produced by the neural classifier.',\n",
       " 'An evolutionary neural network and a method of generating such a neural network is disclosed. The evolutionary neural network comprises an input set consisting of at least one input neuron, said input neurons being adapted for receiving an input signal form an external system, an output set consisting of at least one output neuron, said output neurons being adapted for producing an output signal for said external system, an internal network composed of a plurality of internal neurons, each internal neuron being adapted for processing a signal received from at least one of said input neurons or other internal neurons and producing a signal for at least one of said output neurons or other internal neurons, and a plurality of synapses constituting connections between said neurons, each of said synapses having a value of strength that can be adjusted by a learning process. Each of said neurons is assigned to a neuron class, the parameter values of which are defined by the genotype of the neural network, and each of said synapses are assigned to a respective synapse class, the parameter values of which are also defined by said genotype of the neural network. At reproduction, the genotype of any new neural network is subject to genetic operations. The evolutionary neural network is associated with a neural space, said neural space comprising a plurality of neural layers. Each neuron is associated with at least one neural layer and described by a set of topographical parameters with respect to said neural space. At least one of said topographical parameters of at least the internal neurons is encoded in the genotype of the evolutionary neural network in a statistical form.',\n",
       " 'Synthesis of novel images from example images is achieved by determining a pixelwise optical flow among example images, computing a parameter set for a new image, and synthesizing the new image based on the parameter vector and the example images. The parameter set may describe characteristics of the image, in which case the characteristics are applied to a neural network trained with the example images in order to synthesize the novel image. The parameter set may also be an estimate of relative contributions of each of the example images to the new image, in which case the new image may be synthesized by taking a linear combination of the example images, weighted by the parameter set. In one embodiment, both the example and the new images are of the same object. In another embodiment, the example image represents a first object while the new image represents a second object. In yet another embodiment, a set of target images is synthesized from a single target image and a set of source images. Analysis of existing images to determine image parameters is achieved by determining parameters for the existing image based on comparison of the existing image with an image set for which parameters are known.',\n",
       " 'A semiconductor cell for producing an output current that is related to the match between an input vector pattern and a weighting pattern is described. The cell is particularly useful as a synapse cell within a neural network to perform pattern recognition tasks. The cell includes a pair of input lines for receiving a differential input vector element value and a pair of output lines for providing a difference current to a current summing neural amplifier. A plurality of floating gate devices each having a floating gate member are employed in the synapse cell to store charge in accordance with a predetermined weight pattern. Each of the floating gate devices is uniquely coupled to a combination of an output current line and an input voltage line such that the difference current provided to the neural amplifier is related to the match between the input vector and the stored weight.',\n",
       " 'A semiconductor cell for producing an output current that is related to the match between an input vector pattern and a weighting pattern is described. The cell is particularly useful as a synapse cell within a neural network to perform pattern recognition tasks. The cell includes a pair of input lines for receiving a differential input vector element value and a pair of output lines for providing a difference current to a current summing neural amplifier. A plurality of floating gate devices each having a floating gate member are employed in the synapse cell to store charge in accordance with a predetermined weight pattern. Each of the floating gate devices is uniquely coupled to a combination of an output current line and an input voltage line such that the difference current provided to the neural amplifier is related to the match between the input vector and the stored weight.',\n",
       " 'An exhaust gas purifying apparatus for an internal combustion engine having a lean NOx catalyst in an exhaust system is provided. The lean NOx catalyst traps NOx in exhaust gases when the exhaust gases are in an oxidizing state, and discharges the trapped NOx when the exhaust gases are in an reducing state. In this apparatus, an estimated trapped NOx amount which is an estimated value of an amount of NOx trapped in the lean NOx catalyst, is calculated using a neural network. Engine operating parameters indicative of an operating condition of the engine are input, and the neural network outputs at least one control parameter which is relevant to the lean NOx catalyst. A reducing process of the NOx trapped in the lean NOx catalyst is performed according to the estimated trapped NOx amount.',\n",
       " 'A method of estimating soot loading in a diesel particulate filter (DPF) in a vehicle exhaust system includes estimating an engine-out soot rate using a first neural network that has a first set of vehicle operating conditions as inputs. The method further includes estimating DPF soot loading using a second neural network that has the estimated engine-out soot rate from the first neural network and a second set of vehicle operating conditions as inputs. Estimating the engine-out soot rate and estimating the DPF soot loading are performed by an electronic controller that executes the first and the second neural networks. The method also provides for training the first and second neural networks both offline (for initial settings of the neural networks in the vehicle), and online (when the vehicle is being used by a vehicle operator). An exhaust system has a controller that implements the method.',\n",
       " 'A technique for qualification of loops for new digital subscriber line services (DSL) involves use of an expert system, such as a neural network. A database of loop characteristic information and performance data enables the expert system to train or learn how to predict performance for future loops. In response to data characterizing a new loop to be qualified, the trained expert system predicts digital subscriber line performance for the new loop. Typically, the prediction enables classification of service capacity for the new loop into one of several classes corresponding to levels of DSL service offered through the network. The database for use by the expert system is updated as each newly qualified loop is brought into service and actual performance for that loop is known.',\n",
       " 'Technologies pertaining to training a deep neural network (DNN) for use in a recognition system are described herein. The DNN is trained using heterogeneous data, the heterogeneous data including narrowband signals and wideband signals. The DNN, subsequent to being trained, receives an input signal that can be either a wideband signal or narrowband signal. The DNN estimates the class posterior probability of the input signal regardless of whether the input signal is the wideband signal or the narrowband signal.',\n",
       " 'A computer-implemented method includes receiving, by a computing device, input activations and determining, by a controller of the computing device, whether each of the input activations has either a zero value or a non-zero value. The method further includes storing, in a memory bank of the computing device, at least one of the input activations. Storing the at least one input activation includes generating an index comprising one or more memory address locations that have input activation values that are non-zero values. The method still further includes providing, by the controller and from the memory bank, at least one input activation onto a data bus that is accessible by one or more units of a computational array. The activations are provided, at least in part, from a memory address location associated with the index.',\n",
       " 'Deep Neural Network (DNN) training technique embodiments are presented that train a DNN while exploiting the sparseness of non-zero hidden layer interconnection weight values. Generally, a fully connected DNN is initially trained by sweeping through a full training set a number of times. Then, for the most part, only the interconnections whose weight magnitudes exceed a minimum weight threshold are considered in further training. This minimum weight threshold can be established as a value that results in only a prescribed maximum number of interconnections being considered when setting interconnection weight values via an error back-propagation procedure during the training. It is noted that the continued DNN training tends to converge much faster than the initial training.',\n",
       " 'An optical image of an object is incident on a light-receiving unit of a two-dimensional matrix through a photographing lens. An output from the light-receiving unit is input to a first arithmetic logic unit to calculate an actual object brightness value in consideration of an aperture value of an aperture. An output from the first arithmetic logic unit is input to a multiplexer and a neural network. The neural network determines a main part of the object from brightness value pattern as a set of brightness values of the photoelectric transducer elements and outputs a position signal representing the main part. A multiplexer selectively passes only brightness values of the photoelectric transducer elements corresponding to the main part of the object from the outputs from the first arithmetic logic unit. An output from the multiplexer is supplied to a second arithmetic logic unit, and the second arithmetic logic unit calculates an APEX calculation on the basis of a speed value, an aperture value, a time value, and a mode signal representing a shutter or aperture priority operation, thereby determining a shutter speed or an f-number.',\n",
       " 'The method of the present invention utilizes machine-learning techniques, particularly Support Vector Machines in combination with a neural network, to process a unique machine-learning enabled representation of the audio bitstream. Using this method, a classifying machine is able to autonomously detect characteristics of a piece of music, such as the artist or genre, and classify it accordingly. The method includes transforming digital time-domain representation of music into a frequency-domain representation, then dividing that frequency data into time slices, and compressing it into frequency bands to form multiple learning representations of each song. The learning representations that result are processed by a group of Support Vector Machines, then by a neural network, both previously trained to distinguish among a given set of characteristics, to determine the classification.',\n",
       " 'A method for extracting a representation from an image includes inputting an image to a pre-trained neural network. The gradient of a loss function is computed with respect to parameters of the neural network, for the image. A gradient representation is extracted for the image based on the computed gradients, which can be used, for example, for classification or retrieval.',\n",
       " 'A system and method is disclosed which predicts the relative occurrence or presence of an event or item based on sample data consisting of samples which contain and samples which do not contain the event or item. The samples also consist of any number of descriptive attributes, which may be continuous variables, binary variables, or categorical variables. Given the sampled data, the system automatically creates statistically optimal segments from which a functional input/output relationship can be derived. These segments can either be used directly in the form of a lookup table or in some cases as input data to a secondary modeling system such as a linear regression module, a neural network, or other predictive system.',\n",
       " 'Briefly, embodiments of methods and/or systems of detecting and image of a human face in a digital image are disclosed. For one embodiment, as an example, parameters of a neural network may be developed to generate object labels for digital images. The developed parameters may be refined by a neural network to generate signal sample value levels corresponding to probability that a human face may be depicted at a localized region of a digital image.',\n",
       " 'Face hallucination using a bi-channel deep convolutional neural network (BCNN), which can adaptively fuse two channels of information. In one example, the BCNN is implemented to extract high level features from an input image. The extracted high level features are combined with low level details in the input image to produce the higher resolution image. Preferably, a proper coefficient is obtained to adaptively combine the high level features and the low level details.',\n",
       " 'A face recognition method using artificial neural network and an apparatus thereof are provided. The apparatus comprises an eigenpaxel selection unit which generates eigenpaxels indicating characteristic patterns of a face and selects a predetermined number of eigenpaxels among the generated eigenpaxels; an eigenfiltering unit which filters an input image with the selected eigenpaxels; a predetermined number of neural networks, each of which corresponds to one of the selected eigenpaxels, receives an image signal which is filtered by the corresponding eigenpaxel, and output a face recognition result; and a determination unit which receives the recognition result from each of the neural networks and outputs a final face recognition result of the input image.',\n",
       " 'A classification neural network for piecewise linearly separating an input space to classify input patterns is described. The multilayered neural network comprises an input node, a plurality of difference nodes in a first layer, a minimum node, a plurality of perceptron nodes in a second layer and an output node. In operation, the input node broadcasts the input pattern to all of the difference nodes. The difference nodes, along with the minimum node, identify in which vornoi cell of the piecewise linear separation the input pattern lies. The difference node defining the vornoi cell localizes input pattern to a local coordinate space and sends it to a corresponding perceptron, which produces a class designator for the input pattern.',\n",
       " \"A facial feature extraction method and apparatus uses the variation in light intensity (gray-scale) of a frontal view of a speaker's face. The sequence of video images are sampled and quantized into a regular array of 150.times.150 pixels that naturally form a coordinate system of scan lines and pixel position along a scan line. Left and right eye areas and a mouth are located by thresholding the pixel gray-scale and finding the centroids of the three areas. The line segment joining the eye area centroids is bisected at right angle to form an axis of symmetry. A straight line through the centroid of the mouth area that is at right angle to the axis of symmetry constitutes the mouth line. Pixels along the mouth line and the axis of symmetry in the vicinity of the mouth area form a horizontal and vertical gray-scale profile, respectively. The profiles could be used as feature vectors but it is more efficient to select peaks and valleys (maximas and minimas) of the profile that correspond to the important physiological speech features such as lower and upper lip, mouth corner, and mouth area positions and pixel values and their time derivatives as visual vector components. Time derivatives are estimated by pixel position and value changes between video image frames. A speech recognition system uses the visual feature vector in combination with a concomitant acoustic vector as inputs to a time-delay neural network.\",\n",
       " 'The present invention overcomes the limitations of the prior art by performing facial landmark localization in a coarse-to-fine manner with a cascade of neural network levels, and enforcing geometric constraints for each of the neural network levels. In one approach, the neural network levels may be implemented with deep convolutional neural network. One aspect concerns a system for localizing landmarks on face images. The system includes an input for receiving a face image, and an output for presenting landmarks identified by the system. Neural network levels are coupled in a cascade from the input to the output for the system. Each neural network level produces an estimate of landmarks. The estimate of landmarks is more refined than an estimate of landmark of a previous neural network level.',\n",
       " \"A method for interpreting electromagnetic survey data includes acquiring electromagnetic survey data near a top of a portion of the Earth's subsurface. An initial model of the portion of the Earth's subsurface is generated. The model includes at least spatial distribution of formation resistivity within the portion. The initial model is applied to an artificial neural network trained to generate expected electromagnetic survey instrument response to the initial model. The acquired electromagnetic survey data are compared to an output of the artificial neural network. The initial model is adjusted, and the applying the model to the artificial neural network and the comparing are repeated until differences between the output of the network and the acquired survey data fall below a selected threshold.\",\n",
       " 'A system, method, and product provide rapid explanations for the scores determined by a neural network for new observations input into the neural network. The explanations are associated with a table of percentile bins for each of the input variables used to define the observation. The table contains for each input variable a number of percentile bins. Each percentile bin contains an expected score for values of the input variable containing with the percentile bin. The expected score in each percentile bin is determined from historical observation data. Preferably each percentile bin is associated with an explanation that describes the meaning of the value of the input variable falling within the percentile bin. During observation processing, a new observation is scored. The value of each input variable in the new observation is compared with the percentile bins for the input variable in the table. The expected score in the percentile bin that contains the value of the input variable is retrieved, and this is repeated for all input variables in the new observation. The explanation associated with the percentile bin that has an expected score closest to the actual score is retrieved and provided as the explanation of the most significant input variable accounting for score. Other explanations from the next closest expected scores may also be retrieved.',\n",
       " 'A method of accelerating the training of an artificial neural network uses a computer configured as an artificial neural network with a network input and a network output and having a plurality of interconnected units arranged in layers including an input layer and an output layer. Each unit has a multiplicity of unit inputs and a set of variables for operating upon a unit inputs to provide a unit output in the range between binary 1 and binary 0. A plurality of training examples is serially provided to the network input and the network output is observed. The computer is programmed with a back propagation algorithm for changing each set of variables in response to feedback representing differences between the network output for each example and the desired output. The examples are iterated while the output of a unit is observed. The feedback to a unit is adjusted so that a larger feedback is obtained when the output of the unit is near binary 1 or binary 0 than when the output is midrange between binary 1 or binary 0.',\n",
       " 'A phase diversity wavefront correction system for use in a multiple aperture optical imaging system forms an in-focus image as a composite, focused image from the multiple apertures of the system and also forms an additional image which is deliberately made out of focus to a known extent. Taken together, the two images are processed to create one or more metrics, such as the power metric and sharpness metric. Neural networks are provided, each having an output corresponding to a parameter of an aperture of the imaging system, such as a piston position (axial displacement) or tip/tilt (angular displacement) of one telescope with respect to the others in the system. The neural networks each correspond to one parameter of a telescope or a combinations of parameters and are trained to identify a subset of elements within the metrics that, when input into the network, produce the best estimate of the piston or tip/tilt position relative to a reference telescope or an estimate of a combination of parameters, such as the average of a subset of telescopes. During active use of the system, metrics generated from the in-focus and out-of-focus images of the object scene and the trained neural networks are used to provide estimates of piston and/or tip/tilt positions which are in turn used to drive the pistons and/or tip/tilt controllers to correct for aberrant movement and keep the telescopes phased.',\n",
       " 'A system and method for semantic extraction using a neural network architecture includes indexing each word in an input sentence into a dictionary and using these indices to map each word to a d-dimensional vector (the features of which are learned). Together with this, position information for a word of interest (the word to labeled) and a verb of interest (the verb that the semantic role is being predicted for) with respect to a given word are also used. These positions are integrated by employing a linear layer that is adapted to the input sentence. Several linear transformations and squashing functions are then applied to output class probabilities for semantic role labels. All the weights for the whole architecture are trained by backpropagation.',\n",
       " 'A neural network is trained to output a time dependent target vector defined over a predetermined time interval in response to a time dependent input vector defined over the same time interval by applying corresponding elements of the error vector, or difference between the target vector and the actual neuron output vector, to the inputs of corresponding output neurons of the network corrective feedback. This feedback decreases the error and quickens the learning process, so that a much smaller number of training cycles are required to complete the learning process. A conventional gradient descent algorithm is employed to update the neural network parameters at the end of the predetermined time interval. The foregoing process is repeated in repetitive cycles until the actual output vector corresponds to the target vector. In the preferred embodiment, as the overall error of the neutral network output decreases during successive training cycles, the portion of the error fed back to the output neurons is decreased accordingly, allowing the network to learn with greater freedom from teacher forcing as the network parameters converge to their optimum values. The invention may also be used to train a neural network with stationary training and target vectors.',\n",
       " 'A neural network for an adaptive pattern recognition apparatus includes a plurality of comparators coupled to an input signal. Each comparators compares the input to a different offset voltage. The comparator output is fed to scaling multipliers and then summed to generate an output. The scaling multipliers receive weighing factors generated by using a specific equation selected to insure a fat-learning neural network.',\n",
       " 'A fatigue monitoring system and method is disclosed in which a stream of data relating to the stresses experienced at a plurality of locations over the structure during operation is applied to a neural network trained to remove data stream values deemed to be in error. The data from the neural network is then processed to determine the fatigue life.',\n",
       " 'A method for detecting an diagnosing faults in printed circuit boards. Emissivity data and thermal image data of the various components of the board are obtained. The emissivity data is used to correct the thermal image data. The corrected data is converted to device space data, which is then input to a previously trained neural network. The output of the neural network indicates the location of the fault. The method includes an improved method for obtaining an emissivity map and a method for providing suitable neural network input.',\n",
       " 'A system and method for fault detection is provided. The fault detection system provides the ability to detect symptoms of fault in turbine engines and other mechanical systems that have nonlinear relationships between two or more variables. The fault detection system uses a neural network to perform feature extraction from data for representation of faulty or normal conditions. The values of extracted features, referred to herein as scores, are then used to determine the likelihood of fault in the system. Specifically, the lower order scores, referred to herein as “approximate null space” scores can be classified into one or more clusters, where some clusters represent types of faults in the turbine engine. Classification based on the approximate null space scores provides the ability to classify faulty or nominal conditions that could not be reliably classified using higher order scores.',\n",
       " 'The present invention provides a fault prediction and condition-based repair method of an urban rail train bogie. An optimum service life distribution model of a framework, a spring device, a connecting device, a wheel set and axle box, a driving mechanism, and a basic brake device of a bogie is determined by adopting a method based on survival analysis; a reliability characteristic function of each subsystem is obtained; then, a failure rate of each subsystem of the bogie is calculated by adopting a neural network model optimized by an evolutionary algorithm; and finally, proportional risk modelling is conducted by taking the failure rate and safe operation days of each subsystem of the bogie as concomitant variables; and on the basis of cost optimization, thresholds and control limits for condition-based repair of a bogie system are obtained.',\n",
       " '\" Any deterministic finite-state automata (DFA) can be implemented in a sparse recurrent neural network (RNN) with second-order weights and sigmoidal discriminant functions. Construction algorithms can be extended to fault-tolerant DFA implementations such that faults in an analog implementation of neurons or weights do not affect the desired network performance. The weights are replicated k times for k-1 fault tolerance. Alternatively, the independent network is replicated 2k+1 times and the majority of the outputs is used for a k fault tolerance. In a further alternative solution, a single network with k.eta. neurons uses a \"\"n choose k\"\"encoding algorithm for k fault tolerance. \"',\n",
       " 'A method of obtaining one or more components from an image may include normalizing and pre-processing the image to obtain a processed image. Features may be extracted from the processed image. Neural-network-based regression may then be performed on the set of extracted features to predict the one or more components. These techniques may be applied, for example, to the problem of extracting and removing bone components from radiographic images, which may be thoracic (lung) images.',\n",
       " 'A system is described herein which uses a neural network having an input layer that accepts an input vector and a feature vector. The input vector represents at least part of input information, such as, but not limited to, a word or phrase in a sequence of input words. The feature vector provides supplemental information pertaining to the input information. The neural network produces an output vector based on the input vector and the feature vector. In one implementation, the neural network is a recurrent neural network. Also described herein are various applications of the system, including a machine translation application.',\n",
       " 'A recognition system is disclosed, including a representation of an object in terms of its constituent parts that is translationally invariant, and which provides scale invariant recognition. The system further provides effective recognition of patterns that are partially present in the input signal, or that are partially occluded, and also provides an effective representation for sequences within the input signal. The system utilizes dynamically determined, context based expectations, for identifying individual features/parts of an object to be recognized. The system is computationally efficient, and capable of highly parallel implementation, and further includes a mechanism for improving the preprocessing of individual sections of an input pattern, either by applying one or more preprocessors selected from a set of several preprocessors, or by changing the parameters within a single preprocessor.',\n",
       " 'Feed forward neural network models for associative content addressable memory utilize a first level matrix of resistor connections to store words and compare addressing cues with the stored words represented by connections of unit resistive value, and a winner-take-all circuit for producing a unary output signal corresponding to the word most closely matched in the first matrix. The unary output signal is converted to a binary output code, such as by a suitable matrix. Cues are coded for the address input as binary 1=+V, binary 0=-V, and unknown =0V. Two input amplifiers are employed with two input conductors for each input bit position, one noninverting and the other inverting, so that the winner-take-all circuit at the output of the first matrix may be organized to select the highest number of matches with stored words as the unary output signal. By inverting the cues at the input to the first matrix, and inverting the output of the first level matrix, the effect of resistor value imprecision in the first matrix is virtually obviated. By space coding, the first and second matrices may be expanded into multiple sets of matrices, each with its own winner-take-all circuit for producing unary output signals applied from the first set to the second set of matrices. The output conductors of the second set of matrices are grouped to provide a sparse output code that is then converted to a binary code corresponding to the word recalled.',\n",
       " '\" A Forward Feed Neural Network is disclosed using data flow techniques on a data flow microprocessor. As a result of this invention, a neural network is provided that has the capacity of \"\"learning\"\" to distinguish among patterns of data which may differ recognizably from idealized cases, and is able to perform pattern recognition faster while utilizing less memory and fewer clock cycles than neural networks implemented on sequential processors. This implementation is simpler and faster because of an inherent similarity between the flow of information in the brain and in data flow architecture. \"',\n",
       " 'A feedback control device at a certain control time, predicts a feedback quantity at the next control time on the basis of a feedback quantity fed back from a controlled object and then performs a control operation based on the predicted feedback quantity. The feedback control device includes a predictive control unit for producing such an actuating signal as to decrease a deviation between the predicted feedback quantity and a desired value. The actuating signal is used to control the controlled object. This eliminates the detrimental effects of time delays associated with the controlled object or the control device, thus ensuring good control. The use of the predictive control unit permits the controlled quantity from the controlled object to converge to the desired value monotonically and quickly. The predictive control unit may use a layered neural network having an input layer supplied with a feedback quantity and an input value corresponding to an actuating signal, and an output layer outputting a predicted feedback quantity. The deviation is back propagated from the output layer to the input layer by a relaxation algorithm in order to update the input value. The updated input value is applied to an actuating unit as an actuating signal, thereby controlling the controlled object.',\n",
       " 'A method and apparatus for detecting a singing frequency in a signal processing system using two neural-networks is disclosed. The first one (a hit neural network) monitors the maximum spectral peak FFT bin as it changes with time. The second one (change neural network) monitors the monotonic increasing behavior. The inputs to the neural-networks are the maximum spectral magnitude bin and its rate of change in time. The output is an indication whether howling is likely to occur and the corresponding singing frequency. Once the singing frequency is identified, it can be suppressed using any one of many available techniques such as notch filters. Several improvements of the base method or apparatus are also disclosed, where additional neural networks are used to detect more than one singing frequency.',\n",
       " 'Feedback control of a process to reduce process variations is advantageously accomplished by the combination of a signal processor (26) and an artificial neural network (27). The signal processor (26) first determines which of a plurality of process outputs has the greatest deviation from a corresponding desired value for that output. Having determined which of the process outputs has the greatest deviation from its corresponding desired value, the process controller (25) then adjusts the output having the greatest deviation to yield an estimated process output vector T.sub.m.sup.n supplied to the artificial neural network (27) trained to represent an inverse model of the process. In response to the estimated process output vector T.sub.m.sup.n, the artificial neural network (27) generates a process control vector c.sub.n that controls the process in accordance with the first order variation between the actual process output and a desired value therefor to reduce process variations.',\n",
       " \"In an artificial neural network a method and neuron device that produce weight-adjustment factors, also called error values (116), for pre-synaptic neurons (302a . . . 302c) that are used to adjust the values of connection weights (106 . . . 106n) in neurons (100) used in artificial neural networks (ANNs). The amount of influence a pre-synaptic neuron has had over a post-synaptic neuron is calculated during signal propagation in the post-synaptic neuron (422a . . . 422n) and accumulated for the pre-synaptic neuron (426) for each post-synaptic neuron to which the pre-synaptic neuron's output is connected (428). Influence values calculated for use by pre-synaptic neurons may further be modified by the post-synaptic neuron's output value (102) (option 424), and its error value (116) (option 1110).\",\n",
       " 'The present invention provides a method and system for characterizing the sounds of ocean captured by passive sonar listening devices. The present invention accomplishes this by first generating a spectrogram from the received sonar signal. The spectrogram is characterized in terms of textural features and signal processing parameters. The textural features and signal processing parameters are fed into a neural network ensemble that has been trained to favor specific features and/or parameters. The trained neural network ensemble classifies the signal as either Type-I or clutter.',\n",
       " 'The present invention relates to a product-sum operation circuit element and a circuit for addition by weighting a number of signals input in one neuron circuit in a neural network, and can provide an adaptive-learning neuron circuit for changing an interval of output pulses by learning by connecting a simple pulse generating circuit consisting of capacitance, resistance, unijunction transistor and the like. A product-sum operation circuit element according to the present invention, includes an insulator substrate, a single crystal semiconductor thin film having a p-n-p or n-p-n structure in a lateral direction formed in the shape of stripes on the insulator substrate, a ferroelectric thin film deposited thereon for covering at least the semiconductor stripe structure, and a stripe-like electrode consisting of a metal or a polycrystalline semiconductor further formed thereon for intersecting the semiconductor stripes at a right angle or suitable angle.',\n",
       " 'Accelerator systems and methods are disclosed that utilize FPGA technology to achieve better parallelism and processing speed. A Field Programmable Gate Array (FPGA) is configured to have a hardware logic performing computations associated with a neural network training algorithm, especially a Web relevance ranking algorithm such as LambaRank. The training data is first processed and organized by a host computing device, and then streamed to the FPGA for direct access by the FPGA to perform high-bandwidth computation with increased training speed. Thus, large data sets such as that related to Web relevance ranking can be processed. The FPGA may include a processing element performing computations of a hidden layer of the neural network training algorithm. Parallel computing may be realized using a single instruction multiple data streams (SIMD) architecture with multiple arithmetic logic units in the FPGA.',\n",
       " 'A method of optimizing performance of a well system utilizes a neural network. In a described embodiment, the method includes the step of accumulating data indicative of the performance of the well system in response to variable influencing parameters. The data is used to train a neural network to model an output of the well system in response to the influencing parameters. An output of the neural network may then be input to a valuing model, e.g., to permit optimization of a value of the well system. The optimization process yields a set of prospective influencing parameters which may be incorporated into the well system to maximize its value.',\n",
       " 'Embodiments of the present invention relate to finding semantic parts in images. In implementation, a convolutional neural network (CNN) is applied to a set of images to extract features for each image. Each feature is defined by a feature vector that enables a subset of the set of images to be clustered in accordance with a similarity between feature vectors. Normalized cuts may be utilized to help preserve pose within each cluster. The images in the cluster are aligned and part proposals are generated by sampling various regions in various sizes across the aligned images. To determine which part proposal corresponds to a semantic part, a classifier is trained for each part proposal and semantic part to determine which part proposal best fits the correlation pattern given by the true semantic part. In this way, semantic parts in images can be identified without any previous part annotations.',\n",
       " 'A fire alarm system employs a neural network for obtaining one or more types of fire related information values. A plurality of detection information values are time-serially collected from plural fire phenomenon detectors. The detection information values are signal processed such that a weighting coefficient is assigned thereto in accordance with a relative significance of the detection information value to the desired fire related information value. The various weighting coefficients are stored in advance in a memory. The weighting coefficients stored are established so that the fire related information value for a particular set of detection information values approximates a desired fire related information value.',\n",
       " 'Actuation of the firing mechanism of a firearm is prevented until grip pattern sensing means on the handgrip of the firearm supply to a microprocessor signals corresponding to a grip pattern stored in a programmed simulated neural network memory. All of these components are contained within the firearm. Programming of the neural network memory is accomplished by using a host computer with a simulated neural network to train that network to recognize a particular grip pattern using grip pattern signals generated by the grip pattern sensing means as the sensing means is repeatedly gripped for the person for whom the firearm is to be programmed.',\n",
       " '\"A neural network portion comprising N pre-synaptic neurons capable each of firing an action potential, wherein the number N can be encoded in a word of n bits;    \"',\n",
       " 'In an image classification method, a feature vector representing an input image is generated by unsupervised operations including extracting local descriptors from patches distributed over the input image, and a classification value for the input image is generated by applying a neural network (NN) to the feature vector. Extracting the feature vector may include encoding the local descriptors extracted from each patch using a generative model, such as Fisher vector encoding, aggregating the encoded local descriptors to form a vector, projecting the vector into a space of lower dimensionality, for example using Principal Component Analysis (PCA), and normalizing the feature vector of lower dimensionality to produce the feature vector representing the input image. A set of mid-level features representing the input image may be generated as the output of an intermediate layer of the NN.',\n",
       " 'A controller for a plant having a fixed-weight recurrent neural network with at least one external input signal representative of a desired condition of the plant and actual condition of the plant, and an output connected as a control signal to the plant. The fixed recurrent neural network includes a set of nodes with fixed weight interconnections between the nodes and at least one feedback input interconnecting an output from at least one of the nodes to an input of at least one node. These nodes collectively determine the value of the output from the neural network as a function of the input signal and the feedback input. The controller also includes an adaptive neural network having a plurality of nodes with variable weight interconnections between the nodes. A cost input from the plant is connected to the adaptive neural network while an output from the adaptive neural network is coupled as a processed feedback signal to nodes of the fixed-weight recurrent neural network.',\n",
       " 'A flame detection system includes a plurality of sensors for generating a plurality of respective sensor signals. The plurality of sensors includes a set of discrete optical radiation sensors responsive to flame as well as non-flame emissions. An Artificial Neural Network may be applied in processing the sensor signals to provide an output corresponding to a flame condition.',\n",
       " 'Exemplary embodiments of a flame detector and operating method. Optical energy is received at one or more optical sensors, and the detector processes the energy to determine whether the received energy is from a known remote test source. If so, the flame detector is operated in a test mode. If the processing indicates that the received optical energy is not a test signal, the flame detector is operated in a flame detection operating mode. The detector processing uses an artificial neural network in an exemplary embodiment in the flame detection operation mode.',\n",
       " 'A method to minimize human intervention during decision making processes while controlling an electrical power system by identifying an initiating element that cause a tripping of the transmission overhead lines and identifying potential future protection system failures that can initiate a cascading of tripping or total national blackout. A method of producing flashover analysis signal as a protection system analysis including processing a neutral current, three phase current profile, three phase voltage profile, and a plurality of digital signal of a transmission line using an artificial neural network to calculate pickup time, reset time, DEF confirmation time or total fault clearance time. A method of producing flashover analysis signal including as a flashover signature analysis to identify the cause of the flashover as a current transformer explosion, tree encroachment, crane, lightning strike or polluted insulator.',\n",
       " \"Methods for determining if a nerve is nearby a device. The neural stimulation tools described herein are configured to be flexible and low-profile, so that they can be used within body regions that may be tortuous or difficult to reach, such as within a compressed or partially occluded neural foramen. In most cases, these tools described herein are ribbon-shaped and adapted to be manipulated bimanually, applying force to the ends of the devices from separate locations outside of the patient's body. Thus, the distal end region of the device may be configured to couple to the proximal end of a guidewire. One or more surfaces of the devices may include an electrode or multi-polar network of electrodes configured to stimulate only nerves within a predetermined distance of a particular face of the device. Methods of using these devices are described.\",\n",
       " 'A system for testing and quantifying visual field and other visual function information in a head-mounted virtual reality environment, utilizing a directed image formation device for scanning of a flickering image for display to the test subject. A method and an apparatus are also provided for utilizing a central neural network and a central data bank to perform automatic interpretation of the visual function test parameters obtained in a plurality of visual field testing systems, for a plurality of patients, with control and response signals being transmitted via the Internet. The data produced by the testing systems are automatically analyzed and compared with patterns on which the neural network was previously trained, and clinical diagnoses for pathological conditions are thereby suggested to the respective clinician for each patient.',\n",
       " 'A floating point adder circuit using neural network concepts and having high speed operation is obtained by a controlling circuit using a comparator and an operating circuit using an adder and a subtractor.',\n",
       " 'A non-invasive flow analysis system and method wherein a sensor, such as an acoustic sensor, is coupled to a conduit for transmitting a signal which varies depending on the characteristics of the flow in the conduit. The signal is amplified and there is a filter, responsive to the sensor signal, and tuned to pass a narrow band of frequencies proximate the resonant frequency of the sensor. A demodulator generates an amplitude envelope of the filtered signal and a number of flow indicator quantities are calculated based on variations in amplitude of the amplitude envelope. A neural network, or its equivalent, is then used to determine the flow rate of the flow in the conduit based on the flow indicator quantities.',\n",
       " 'A fluid flow meter is of the type including a heated probe sensor of known electric resistance dipped into or swept by a fluid stream having a predetermined velocity. The sensor is capable of converting each flow velocity value to a voltage value, and is connected to a processor operating using fuzzy logic for producing the flow measurements. The sensor may be an NTC thermistor. The thermistor may be powered from a current generator, and the processor may include a neural network. The sensor may include at least two discrete thermistors, one being a hot thermistor and the other being a cold thermistor.',\n",
       " 'A two-axis fluxgate sensor has a driving pulse generating circuit which generates pulse signal and outputs as a driving signal, and X-axis and Y-axis fluxgates which are in proportional relation with each other. The two-axis fluxgate sensor generates voltage values of X-axis and Y-axis fluxgates corresponding to the magnetism which is generated from the driving signal, and a memory stores therein a neural network weight matrix. When the voltage values of the X-axis and Y-axis fluxgates are measured, a control unit compensates for the voltage values by using the neural network weight matrix which is stored in the memory, and computes an azimuth angle by using the compensated voltage values. An accurate azimuth angle can be obtained even at slopes.',\n",
       " 'An optical image transmitted through a photographing lens is incident on a light-receiving unit of a two-dimensional matrix. An output from the light-receiving unit is input to a first arithmetic logic unit, and the first arithmetic logic unit calculates actual object brightness values in consideration of an aperture value of an aperture. An output from the first arithmetic logic unit is supplied to a multiplexer and a neural network. The neural network determines a main part of the object from a pattern of brightness values of the respective photoelectric transducer elements and outputs a position signal of the main part. The multiplexer selectively passes the brightness value of the photoelectric transducer element corresponding to the main part of the object from the outputs generated by the first arithmetic logic unit. An output from the multiplexer is supplied to a second arithmetic logic unit. The second arithmetic logic unit performs a focus detection calculation based on only the brightness of the main part. The photographing lens is moved along the optical axis, thereby performing a focusing operation.',\n",
       " 'Font recognition and similarity determination techniques and systems are described. In a first example, localization techniques are described to train a model using machine learning (e.g., a convolutional neural network) using training images. The model is then used to localize text in a subsequently received image, and may do so automatically and without user intervention, e.g., without specifying any of the edges of a bounding box. In a second example, a deep neural network is directly learned as an embedding function of a model that is usable to determine font similarity. In a third example, techniques are described that leverage attributes described in metadata associated with fonts as part of font recognition and similarity determinations.',\n",
       " 'A convolutional neural network (CNN) is trained for font recognition and font similarity learning. In a training phase, text images with font labels are synthesized by introducing variances to minimize the gap between the training images and real-world text images. Training images are generated and input into the CNN. The output is fed into an N-way softmax function dependent on the number of fonts the CNN is being trained on, producing a distribution of classified text images over N class labels. In a testing phase, each test image is normalized in height and squeezed in aspect ratio resulting in a plurality of test patches. The CNN averages the probabilities of each test patch belonging to a set of fonts to obtain a classification. Feature representations may be extracted and utilized to define font similarity between fonts, which may be utilized in font suggestion, font browsing, or font recognition applications.',\n",
       " 'A first collection including an analytical feature vector and a Q&A feature vector is constructed. A second collection is constructed from the first collection by inserting noise in at least one of the vectors. A third collection is constructed by crossing over at least one of vectors of the second collection with a corresponding vector of a fourth collection, migrating at least one of the vectors of the second collection with a corresponding vector of a fifth collection. Using a forecasting configuration, an analytical feature vector of the third collection is aged to generate a changed analytical feature vector containing analytical feature values expected at a future time. The changed analytical feature vector is input into a trained neural network to predict a probability of the cyber-attack occurring at the future time.',\n",
       " 'A first collection including a first feature vector and a Q&A feature vector is constructed. A second collection is constructed from the first collection by inserting noise in at least one of the vectors. A third collection is constructed by crossing over at least one of vectors of the second collection with a corresponding vector of a fourth collection. The second and the fourth collections have a property similar to one another. Using a forecasting configuration, a vector of the third collection is aged to generate a changed feature vector, the changed feature vector containing feature values expected at a future time. The changed feature vector is input into a trained neural network to predict a probability of the cyber-attack occurring at the future time.',\n",
       " 'A first collection including a first feature vector and a Q&A feature vector is constructed. A second collection is constructed from the first collection by inserting noise in at least one of the vectors. A third collection is constructed by crossing over at least one the vectors of the second collection with a corresponding vector of a fourth collection, migrating at least one of the vectors of the second collection with a corresponding vector of a fifth collection, or both. Using a forecasting configuration, a vector of the third collection is aged to generate a changed feature vector, the changed feature vector containing feature values expected at a future time. The changed feature vector is input into a trained neural network to predict a probability of the cyber-attack occurring at the future time.',\n",
       " 'A first collection including a pattern of life (POL) feature vector and a Q&A feature vector is constructed. A second collection is constructed from the first collection by inserting noise in at least one of the vectors. A third collection is constructed by crossing over at least one of vectors of the second collection with a corresponding vector of a fourth collection, migrating at least one of the vectors of the second collection with a corresponding vector of a fifth collection. Using a forecasting configuration, a POL feature vector of the third collection is aged to generate a changed POL feature vector containing POL feature values expected at a future time. The changed POL feature vector is input into a trained neural network to predict a probability of the cyber-attack occurring at the future time.',\n",
       " 'A system and method for forecasting that combines a neural network with a statistical forecast is presented. A neural network having an input layer, a hidden layer, and an output layer with each layer having one or more nodes is presented. Each node in the input layer is connected to each node in the hidden layer and each node in the hidden layer is connected to each node in the output layer. Each connection between nodes has an associated weight. One node in the input layer is connected to a statistical forecast that is produced by a statistical model. All other nodes in the input layer are connected to a different historical datum from the set of historical data. The neural network being operative by outputting a forecast, the output of the output layer nodes, when presented with input data. The weights associated with the connections of the neural network are first adjusted by a training device. The training device applies a plurality of training sets to the neural network, each training set consisting of historical data, an associated statistical output and a desired forecast, with each set of training data the training device determines a difference between the forecast produced by the neural network given the training data and the desired forecast, the training device then adjusts the weights of the neural network based on the difference.',\n",
       " 'A method for determining density of a formation. The method includes irradiating the formation with gamma rays having energy consistent with Compton scattering. Gamma rays are measured at axially spaced apart locations. Two of the axially spaced apart locations are at an equal distance and in opposite directions relative to the source of gamma rays. The distance is smaller than the spacing of another one of the spaced apart locations. An apparent density for each spaced apart location is determined from the counts. Differences are calculated in apparent density between each one of the spaced apart locations, and a correction factor is determined for apparent density at each spaced apart location, thereby determining the density of the earth formation. In a preferred embodiment, determining correction factors is performed by a neural network using the differences in apparent density as an input vector.',\n",
       " 'This invention includes the generation of forming information and its manipulation scheme as a method to form curved plates in ship hull-pieces. This invention consists of three components as follows: one is to construct and utilize a database which includes data about flat plates, objective curved plates, plates which are being formed, and their forming information, another is to infer new forming information with an artificial neural network system, and the third is to obtain forming information through calculating in-plane and bending strains. In the third, initial forming information is obtained by calculating strains from relationship between flat plates and objective curved plates. And new forming information is yielded through calculating the strains from relationship between partially formed curved plates and objective curved plates. Final objective plate are reached by repeatedly performing the measurement of the difference between plates in the proceeding steps and final objective plates and the calculation of the new strains in each process. Therefore, through this invention standardization and automation can be realized in the formation of curved plates.',\n",
       " 'A method of storing information relating to the transmission of messages by an entity over a given time period comprises the step of creating a signature comprising a plurality of parameters related to the transmission of messages over that time period wherein the parameters comprise at least one parameter related to the transmission of messages over a portion of the period and also related to the position of the portion in the period, to enable output data to be derived from the stored information. The signature may be updated by a weighted averaging process with other more recent signatures. Application in fraud detection where signature representing information in many call detail records from a particular subscriber is fed to a neural network.',\n",
       " 'A four quadrant multiplier using multiple input floating-gate MOS transistors is provided. It is based on the square law characteristics of the MOS transistor and can be realised with only four floating gate MOS transistors, two resistors and a current source. The four floating gate transistors are configured with their sources connected in common and biased by a single current source. Output is taken between two common drain connections. Each transistor has three control gates with two being provided for selected ones of the two input signals and one for a biasing signal (optional). Input signals can be connected to the control gates in either a differential or single ended configuration. In one application, a programmable synaptic cell for neural networks employs the multi-input floating-gate MOS four-quadrant analog multiplier. Varying of the neural weight connection strength of each synaptic cell is achieved by two possible methods. One method involves programming charges into or out of the primary floating-gate of the MFMOS devices associated with the multiplier. The other method is to configure the third input gate of each MFMOS device of the multiplier as another (secondary) floating-gate structure whereby charge can be programmed into or out of this secondary floating-gate structure and its coupling area to the primary floating-gate would determine the neural weight. The differential output current is proportional to the product of the input signal and the programmed charge difference. In a natural extension an array of individually programmable synaptic cells form a neural network.',\n",
       " 'A multiprocessor having an input/output controller, a process controller, and a multidimensional arrays of field programmable gate arrays (FPGAs), each FPGA having its own local memory. The multiprocessor may be programmed to function as a single-instruction, multiple-data (SIMD) parallel processor having a matrix of processing elements (PEs), where each FPGA may be programmed to operate as a submatrix array of PEs. The multiprocessor is especially useful for image processing, pattern recognition, and neural network applications.',\n",
       " 'Techniques related to implementing neural networks for speech recognition systems are discussed. Such techniques may include implementing frame skipping with approximated skip frames and/or distances on demand such that only those outputs needed by a speech decoder are provided via the neural network or approximation techniques.',\n",
       " 'A method and system for frame-level merging of HMM state predictions determined by different techniques is disclosed. An audio input signal may be transformed into a first and second sequence of feature vector, the sequences corresponding to each other and to a temporal sequence of frames of the audio input signal on a frame-by-frame basis. The first sequence may be processed by a neural network (NN) to determine NN-based state predictions, and the second sequence may be processed by a Gaussian mixture model (GMM) to determine GMM-based state predictions. The NN-based and GMM-based state predictions may be merged as weighted sums for each of a plurality of HMM state on a frame-by-frame basis to determine merged state predictions. The merged state predictions may then be applied to the HMMs to speech content of the audio input signal.',\n",
       " 'An automated system and method detects fraudulent transactions using a predictive model such as a neural network to evaluate individual customer accounts and identify potentially fraudulent transactions based on learned relationships among known variables. The system may also output reason codes indicating relative contributions of various variables to a particular result. The system periodically monitors its performance and redevelops the model when performance drops below a predetermined level.',\n",
       " 'Embodiments generally relate to providing systems and methods for assessing image quality of a distorted image relative to a reference image. In one embodiment, the system comprises a convolutional neural network that accepts as an input the distorted image and the reference image, and provides as an output a metric of image quality. In another embodiment, the method comprises inputting the distorted image and the reference image to a convolutional neural network configured to process the distorted image and the reference image and provide as an output a metric of image quality.',\n",
       " 'A fuzzy data comparator receives a fuzzy data digital data bit stream and compares each frame thereof with multiple sets of differing known data stored in a plurality of pattern memories, using a selected comparison metric. The results of the comparisons are accumulated as error values. A first neural postprocessing network ranks error values less than a preselected threshold. A second neural network receives the first neural network solutions and provides an expansion bus for interconnecting to additional comparators.',\n",
       " 'An method and apparatus for extracting an interpretable, meaningful, and concise rule set from neural networks is presented. The method involves adjustment of gain parameter, &lgr; and the threshold, Tj for the sigmoid activation function of the interactive-or operator used in the extraction/development of a rule set from an artificial neural network. A multi-stage procedure involving coarse and fine adjustment is used in order to constrain the range of the antecedents of the extracted rules to the range of values of the inputs to the artificial neural network. Furthermore, the consequents of the extracted rules are provided based on degree of membership such that they are easily understandable by human beings. The method disclosed may be applied to any pattern recognition task, and is particularly useful in applications such as vehicle occupant sensing and recognition, object recognition, gesture recognition, and facial pattern recognition, among others.',\n",
       " '\" In the present invention, prior art techniques are extended to allow application of the backpropagation learning technique to artificial neural networks derived from fuzzy expert system rule-bases. A method in accordance with the invention, referred to herein as a Fuzzy Expert Network (FEN), is implemented in a programmed machine such as a computer to provide automated learning of both \"\"fine\"\" and \"\"coarse\"\" knowledge in a network of artificial neural objects (ANOs) implementing fuzzy modeling rules. Through application of the FEN method, an event-driven fuzzy expert network comprising acyclically connected ANOs derived from fuzzy modelling rules may be implemented. Neural objects implement one or more fuzzy combining and defuzzification rules and use backpropagation of error techniques to implement learning. As in prior art, the FEN allows each ANO to adjust its input weight parameters--\"\"fine\"\" knowledge learning. Unlike prior art, the FEN allows each ANO to modify its internal parameters--\"\"coarse\"\" knowledge learning. This latter action means that individual ANOs have the capability to modify the parameters of the fuzzy rule\\'s membership function upon which they are based. In this way the FEN is able to change the structure of its encoded knowledge over time, making it a more adaptable architecture for autonomous and/or adaptable control systems. Simulation results showing the FEN\\'s learning and adaptability behavior are given. \"',\n",
       " 'A fuzzy inference device determines an inference operational quantity in accordance with inference rules each constituted by an antecedent and a consequent. An inference rule division determiner which receives data of input variables and output variables so as to determine the number of the inference rules. An antecedent neural element obtains a membership value corresponding to an antecedent of a specific inference rule from the divided data of the input variables and the output variables. A situational change processor adaptively determines an inference quantity of a consequent of each inference rule in the case of a change of an initial state or inference situations. An inference operational quantity determiner receives outputs from the antecedent neural element and the situational change processor and performs fuzzy inference in accordance with the inference rules so as to determine the inference operational quantity. An evaluator evaluates, on the basis of an evaluation reference, the inference operational quantity outputted by the inference operational quantity determiner.',\n",
       " \"A fuzzy logic design generator for providing a fuzzy logic design for an intelligent controller in a plant control system includes an artificial neural network for generating fuzzy logic rules and membership functions data. These fuzzy logic rules and membership functions data can be stored for use in a fuzzy logic system for neural network based fuzzy antecedent processing, rule evaluation and defuzzification, thereby avoiding heuristics associated with conventional fuzzy logic algorithms. The neural network, used as a fuzzy rule generator to generate fuzzy logic rules and membership functions for the system's plant controller, is a multilayered feed-forward neural network based upon a modified version of a back-propagation neural network and learns the system behavior in accordance with input and output data and then maps the acquired knowledge into a new non-heuristic fuzzy logic system. Interlayer weights of the neural network are mapped into fuzzy logic rules and membership functions. Antecedent processing is performed according to a weighted product of the antecedents. One layer of the neural network is used for performing rule evaluation and defuzzification.\",\n",
       " 'The invention relates to a modular architecture of a cellular network for improved large-scale integration, of the type which comprises a plurality of fuzzy cellular elements (C.sub.m,n) interconnected to form a matrix of elements having at least m rows and n columns, the row and column numbers describing the location of each element. Each fuzzy processor is adapted for connection to other processors of the same type such that a parallel architecture of the modular type can be implemented. The management of the architecture is facilitated by each submatrix being controlled by an individually dedicated fuzzy processor device.',\n",
       " 'A fuzzy neural network system which is provided with an input layer, a membership layer front half section, a membership layer back half section, a rule layer, and an output layer; and constructs a network from a plurality of input/output items. The input layer and the membership layers are structured so as to divide each input value into three regions of fuzzy sets, respectively. The rule layer selects one each respectively from the above mentioned items divided into three regions, and is structured so as to make these the AND rules for the two input items.',\n",
       " 'There is disclosed a pattern identifying neural network comprising at least an input and an output layer, the output layer having a plurality of principal nodes, each principal node trained to recognize a different class of patterns, and at least one fuzzy node trained to recognize all classes of patterns recognized by the principal nodes but with outputs set out at levels lower than the corresponding outputs of the principal nodes.',\n",
       " 'This invention relates to an apparatus and method for generating membership functions and rules for a fuzzy system whereby fuzzy rules and membership functions are synthesized by observing a sample output/input data array and by creating new fuzzy sets which closely approximate various data associations in accordance with maximum inference error calculations. Applications of this system are provided in a temperature controller, a vehicle suspension controller, and a neural network/fuzzy rule converter device.',\n",
       " 'A fuzzy neural network system includes a learning function. The learning is performed by determining degrees of coincidence of rules from combinations of membership functions for realizing fuzzy rules, constructing a network based on the number of input and output items, in such a manner as to produce output in conformity with the degrees of coincidence, to thereby properly simulate relations between input and output as to sample data represented by a subject input pattern and an output pattern corresponding thereto. The system further includes a fuzzy rule setup portion for programming fuzzy rules created by engineers into the fuzzy neural network, a fuzzy rule extracting portion for extracting each fuzzy rule from the network after a learning period, and a degree-of-importance extracting portion which extracts, for each input, a respective contribution ratio of each input on each output in the network, after a learning period. In a preferred embodiment, the network structure includes an input layer, a membership layer having front and rear halves, a rule layer, and an output layer.',\n",
       " 'A fuzzy-neural network system includes: an input layer outputting values of input parameters; a membership layer wherein a multiple number of regions for each of the input parameters are formed by dividing the probable range of the input parameter and a membership function is defined for each of the regions, the membership layer producing membership values as to the regions for each of the input parameters, in accordance with the output values from the input layer; a rule layer wherein specific rules are formed between regions belonging to different input parameters, the rule layer outputting a suitability for each of the rules; an outputting layer producing an output parameter or parameters in accordance with the output values from the rule layer; and a membership value setup means which, if some of the input parameters are unknown, sets up prescribed values as membership values corresponding to the unknown parameters.',\n",
       " \"A method and system for detecting and displaying clustered microcalcifications in a digital mammogram, wherein a single digital mammogram is first automatically cropped to a breast area sub-image which is then processed by means of an optimized Difference of Gaussians filter to enhance the appearance of potential microcalcifications in the sub-image. The potential microcalcifications are thresholded, clusters are detected, features are computed for the detected clusters, and the clusters are classified as either suspicious or not suspicious by means of a neural network. Thresholding is preferably by sloping local thresholding, but may also be performed by global and dual-local thresholding. The locations in the original digital mammogram of the suspicious detected clustered microcalcifications are indicated. Parameters for use in the detection and thresholding portions of the system are computer-optimized by means of a genetic algorithm. The results of the system are optimally combined with a radiologist's observation of the original mammogram by combining the observations with the results, after the radiologist has first accepted or rejected individual detections reported by the system. An alternative embodiment reduces false positive detections by means of Gabor filtering the cropped mammogram image to identify elongated structures such as milk ducts and veins. Individual microcalcifications coincident with the elongated structures are removed and the remaining detections grouped into clusters.\",\n",
       " 'A method of correcting errors in imaging data in a Gamma Camera including determining a first correction map based on one or both of (1) calculated corrections and (2) a first data acquisition, determining a second correction map based on a second data acquisition and correcting the imaging data based on the first and second correction maps. In a preferred embodiment of the invention, error correction is implemented using a neural network. Alternatively, a neural network can be used to perform the entire calculation of event position and/or energy.',\n",
       " 'A computer system computes a score for a received data exchange and, in accordance with a neural network and input variables determined by received current exchange and history data, the computed score indicates a condition suitable for a denial. A set of attribution scores are computed using an Alternating Decision Tree model in response to a computed score that is greater than a predetermined score threshold value for the denial. The computed score is provided to an assessment unit and, if the computed score indicates a condition suitable for the denial and if attribution scores are computed, then a predetermined number of input variable categories from a rank-ordered list of input variable categories is also provided to the assessment unit of the computer system.',\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating acoustic models. In some implementations, a first neural network trained as an acoustic model using the connectionist temporal classification algorithm is obtained. Output distributions from the first neural network are obtained for an utterance. A second neural network is trained as an acoustic model using the output distributions produced by the first neural network as output targets for the second neural network. An automated speech recognizer configured to use the trained second neural network is provided.',\n",
       " 'A knowledge base (KB) is generated and used to classify images. The knowledge base includes a number subcategories of a specified category. Instead of obtaining images just based on a category name, structured and unstructured data sources are used to identify subcategories of the category. Subcategories that are determined to not be relevant to the category may be removed. The remaining data may be used to generate the KB. After identifying the relevant subcategories, representative images are obtained from one or more image sources based on the subcategories identified by the KB. The obtained images and the KB are then used to train an image classifier, such as a neural network or some other machine learning mechanism. After training, the neural network might, for example, classify an object within an image of a car, as a car, but also as a particular brand and model type.',\n",
       " 'The present invention is directed to generating audience analytics that includes providing a database containing a plurality of user input pattern profiles representing the group of users of terminal device, in which each user of the group is associated with one of the plurality of user input pattern profiles. A clickstream algorithm, tracking algorithm, neural network, Bayes classifier algorithm, or affinity-day part algorithm can be used to generate the user input pattern profiles. A user input pattern is detected based upon use of the terminal device by the current user and the user input pattern of the current user is dynamically matched with one of the user input pattern profiles contained in the database. The current user is identified based upon dynamic matching of the user input pattern generated by the current user with one of the user input pattern profiles. The present invention processes each user input pattern profile to identify a demographic type. A plurality of biometric behavior models are employed to identify a unique demographic type. Each user input pattern profile is compared against the plurality of biometric behavior models to match each user input pattern profile with one of the biometric behavior models such that each user input pattern profile is correlated with one demographic type. Audience analytics are then based upon the identified demographic types.',\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating author vectors. One of the methods includes obtaining a set of sequences of words, the set of sequences of words comprising a plurality of first sequences of words and, for each first sequence of words, a respective second sequence of words that follows the first sequence of words, wherein each first sequence of words and each second sequence of words has been classified as being authored by a first author; and training a neural network system on the first sequences and the second sequences to determine an author vector for the first author, wherein the author vector characterizes the first author.',\n",
       " 'Techniques for increasing robustness of a convolutional neural network based on training that uses multiple datasets and multiple tasks are described. For example, a computer system trains the convolutional neural network across multiple datasets and multiple tasks. The convolutional neural network is configured for learning features from images and accordingly generating feature vectors. By using multiple datasets and multiple tasks, the robustness of the convolutional neural network is increased. A feature vector of an image is used to apply an image-related operation to the image. For example, the image is classified, indexed, or objects in the image are tagged based on the feature vector. Because the robustness is increased, the accuracy of the generating feature vectors is also increased. Hence, the overall quality of an image service is enhanced, where the image service relies on the image-related operation.',\n",
       " 'The invention is to provide a generating method for transaction models with indicators for option. The method comprises: (S1) collecting a variety of indicators from the financial market; (S2) establishing an indicator pool saved with the indicators; (S3) distinguishing and classifying the indicators by Neural Network; (S4) determining a plurality of transaction models, the indicator of each transaction model in an independent classification; (S5) determining a date parameter for each indicator; (S6) deleting a part of the transaction models; (S7) determining a plurality of final transaction models from another transaction models; and (S8) determining a weight of each final transaction model.',\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating descriptions of input images. One of the methods includes obtaining an input image; processing the input image using a first neural network to generate an alternative representation for the input image; and processing the alternative representation for the input image using a second neural network to generate a sequence of a plurality of words in a target natural language that describes the input image.',\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating numeric embeddings of images. One of the methods includes obtaining training images; generating a plurality of triplets of training images; and training a neural network on each of the triplets to determine trained values of a plurality of parameters of the neural network, wherein training the neural network comprises, for each of the triplets: processing the anchor image in the triplet using the neural network to generate a numeric embedding of the anchor image; processing the positive image in the triplet using the neural network to generate a numeric embedding of the positive image; processing the negative image in the triplet using the neural network to generate a numeric embedding of the negative image; computing a triplet loss; and adjusting the current values of the parameters of the neural network using the triplet loss.',\n",
       " 'Methods of directly analyzing wireline well logging data to derive pore types, pore volumes and capillary pressure curves from the wireline logs are disclosed. A trained and validated neural network is applied to wireline log data on porosity, bulk density and shallow, medium and deep conductivity to derive synthetic pore type proportions as a function of depth. These synthetic data are then applied through a derived and validated capillary pressure curve data model to derive pore volume and pressure data as a function of borehole depth.',\n",
       " 'Briefly, embodiments of methods and/or systems of generating preference indices for contiguous portions of digital images are disclosed. For one embodiment, as an example, parameters of a neural network may be developed to generate object labels for digital images. The developed parameters may be transferred to a neural network utilized to generate signal sample value levels corresponding to preference indices for contiguous portions of digital images.',\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating representation of acoustic sequences. One of the methods includes: receiving an acoustic sequence, the acoustic sequence comprising a respective acoustic feature representation at each of a plurality of time steps; processing the acoustic feature representation at an initial time step using an acoustic modeling neural network; for each subsequent time step of the plurality of time steps: receiving an output generated by the acoustic modeling neural network for a preceding time step, generating a modified input from the output generated by the acoustic modeling neural network for the preceding time step and the acoustic representation for the time step, and processing the modified input using the acoustic modeling neural network to generate an output for the time step; and generating a phoneme representation for the utterance from the outputs for each of the time steps.',\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a neural network. One of the methods includes accessing a first neural network that was trained to recognize a given keyword or keyphrase using a set of hotword training data, wherein the hotword training data includes positive hotword training data that correspond to utterances of the keyword or keyphrase, and negative hotword training data that corresponds to utterances of words or phrases that are other than the keyword or keyphrase, selecting a seed hotsound, mapping, to a feature space, (i) the positive hotword training data, (ii) the negative hotword training data, and (iii) the seed hotsound, performing an optimization of a position of the seed hotsound within the feature space to generate a modified seed hotsound, generating a set of hotsound training data using the modified seed hotsound, training a second neural network to recognize the modified seed hotsound using the generated set of hotsound training data, and using the trained second neural network to recognize the modified hotsound.',\n",
       " 'Various implementations disclosed herein include an expert-assisted phoneme recognition neural network system configured to recognize phonemes within continuous large vocabulary speech sequences without using language specific models (“left-context”), look-ahead (“right-context”) information, or multi-pass sequence processing, and while operating within the resource constraints of low-power and real-time devices. To these ends, in various implementations, an expert-assisted phoneme recognition neural network system as described herein utilizes a-priori phonetic knowledge. Phonetics is concerned with the configuration of the human vocal tract while speaking and acoustic consequences on vocalizations. While similar sounding phonemes are difficult to detect and are frequently misidentified by previously known neural networks, phonetic knowledge gives insight into what aspects of sound acoustics contain the strongest contrast between similar sounding phonemes. Utilizing features that emphasize the respective second formants allows for more robust sound discrimination between these problematic phonemes.',\n",
       " 'Features are disclosed for using an artificial neural network to generate customized speech recognition models during the speech recognition process. By dynamically generating the speech recognition models during the speech recognition process, the models can be customized based on the specific context of individual frames within the audio data currently being processed. In this way, dependencies between frames in the current sequence can form the basis of the models used to score individual frames of the current sequence. Thus, each frame of the current sequence (or some subset thereof) may be scored using one or more models customized for the particular frame in context.',\n",
       " 'This invention relates to an artificial neural network (ANN), particularly to a neuron circuit and its activation function including the derivative. The neuron circuit capable of generating an adjustable sigmoid-like function and a good approximation of its derivative, comprises: a current generator for generating a current; a current-controlled transistor for changing an output voltage according to the current from the current generator; and at least one differential pair of transistors for generating the adjustable sigmoid-like function output and the good approximation of its derivative by the changed output voltage.',\n",
       " 'A electronic engine control (EEC) module executes a generic neural network processing program to perform one or more neural network control funtions. Each neural network funtion is defined by a unitary data structure which defines the network architecture, including the number of node layers, the number of nodes per layer, and the interconnections between nodes. In addition, the data structure holds weight values which determine the manner in which network signals are combined. The network definition data structures are created by a network training system which utilizes an external training processor which employs gradient methods to derive network weight values in accordance with a cost function which quantitatively defines system objectives and an identification network which is pretrained to provide gradient signals representative the behavior of the physical plant. The training processor executes training cycles asynchronously with the operation of the EEC module in a representative test vehicle.',\n",
       " 'Neural networks for object detection in images are used with a spatial pyramid pooling (SPP) layer. Using the SPP network structure, a fixed-length representation is generated regardless of image size and scale. The feature maps are computed from the entire image once, and the features are pooled in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. Thus, repeated computation of the convolutional features is avoided while accuracy is enhanced.',\n",
       " 'A generic anomaly detection engine is described which provides neural network technology to process information such as call detail records and detect anomalies in the information, such as mobile phone fraud. Information from call detail records is pre-processed to form signatures which represent the calling behavior of a subscriber. These signatures are formed in one of a plurality of predetermined formats. The generic anomaly detection engine is instantiated in order to create an anomaly detector which is suitable for a particular situation and during the instantiation process the topology of the neural network components is automatically adjusted to fit the required situation. The topology is adjusted to according to the format of the signatures.',\n",
       " 'A system and method for generating a neural network ensemble. Conventional algorithms are used to train a number of neural networks having error diversity, for example by having a different number of hidden nodes in each network. A genetic algorithm having a multi-objective fitness function is used to select one or more ensembles. The fitness function includes a negative error correlation objective to insure diversity among the ensemble members. A genetic algorithm may be used to select weighting factors for the multi-objective function. In one application, a trained model may be used to produce synthetic open hole logs in response to inputs of cased hole log data.',\n",
       " 'The disclosure relates to the use of genetic learning techniques to evolve neural network architectures for specific applications in which a general representation of neural network architecture is linked with a genetic learning strategy to create a very flexible environment for the construction of custom neural networks.',\n",
       " 'A generic algorithm search is applied to determine an optimum set of values (e.g., interconnection weights in a neural network), each value being associated with a pair of elements drawn from a universe of N elements, N an integer greater than zero, where the utility of any possible set of said values may be measured. An initial possible set of values is assembled, the values being organized in a matrix whose rows and columns correspond to the elements. A genetic algorithm operator is applied to generate successor matrices from said matrix. Matrix computations are performed on the successor matrices to generate measures of the relative utilities of the successor matrices. A surviving matrix is selected from the successor matrices on the basis of the metrics. The steps are repeated until the metric of the surviving matrix is satisfactory.',\n",
       " 'Genetically adaptive neural network systems and methods provide environmentally adaptable classification algorithms for use, among other things, in multi-static active sonar classification. Classification training occurs in-situ with data acquired at the onset of data collection to improve the classification of sonar energy detections in difficult littoral environments. Accordingly, in-situ training sets are developed while the training process is supervised and refined. Candidate weights vectors evolve through genetic-based search procedures, and the fitness of candidate weight vectors is evaluated. Feature vectors of interest may be classified using multiple neural networks and statistical averaging techniques to provide accurate and reliable signal classification.',\n",
       " 'A method for automatic analysis of genomic information in order to determine relationships among genes allows one to determine complex relationships among genes. First a clustering algorithm is chosen and is applied to the table, obtaining sub-tables of data relative to groups of genes that satisfy the chosen clustering criterion. Therefore, all possible combinations of pair of sub-tables are generated and characteristic parameters are calculated for genes contained in these sub-tables. Finally, for each combination a characteristic value is calculated with a decision algorithm defined in function of these parameters, by considering the genes of the combination as constituting a “Gene Network” if this characteristic value exceeds a pre-defined threshold. The method is preferably is implemented by a relative system of identification of groups of co-expressed and co-regulated genes comprising an intelligent fuzzy sub-system trained off-line identified by a neural network.',\n",
       " 'Interpreting data obtained by analysis of nucleic acids (DNA) by obtaining nucleic acid data in a spatial domain, transforming the nucleic acid data from the spatial domain into a frequency domain, and obtaining sequence data of the nucleic acid data by executing a data mining process on the transformed nucleic acid data. The transformation may be performed by a Hadamard transform, a Fourier transform or a Wavelet transform to obtain frequency coefficients, with less than all of the frequency coefficients being utilized in the data mining process. In addition, the frequency domain data may be normalized prior to the data mining process. The data mining process may be subjecting the frequency coefficients to a connectionist (neural network) algorithm or to a classification tree/rule induction (CART) algorithm.',\n",
       " 'The present invention provides a method of optimizing a painting process for applying a paint layer on an article. The method comprises defining a functional relationship paint processing parameters and a paint layer property (i.e., the average paint layer thickness) using a neural network. This functional relationship is then used in a paint optimization function that measures a combination of quality control parameters and efficiency parameters. Finally, the paint optimization function is optimized by adjusting the paint processing parameters utilizing the functional relationship formed by the neural network. The invention also provides a system that implements the methods of the invention.',\n",
       " 'The problem of thresholding is considered from a clustering point of view and a novel weight-based clustering method (WCThresh) is implemented in a neural network image processor 50. The neural network image processor 50 uses weights 51-53, representing clusters of gray scale pixels of an image of document 43, to provide a threshold for the image of document 43. The processor 50 modifies weights 51-53 with the input pixels and comparator 60 using a nearest value criterion to provide the threshold.',\n",
       " 'Embodiments of the invention relate to a globally asynchronous and locally synchronous neuromorphic network. One embodiment comprises generating a synchronization signal that is distributed to a plurality of neural core circuits. In response to the synchronization signal, in at least one core circuit, incoming spike events maintained by said at least one core circuit are processed to generate an outgoing spike event. Spike events are asynchronously communicated between the core circuits via a routing fabric comprising multiple asynchronous routers.',\n",
       " 'Clustering for purposes of data visualization and making predictions is disclosed. Embodiments of the invention are operable on a number of variables that have a predetermined representation. The variables include input-only variables, output-only variables, and both input-and-output variables. Embodiments of the invention generate a model that has a bottleneck architecture. The model includes a top layer of nodes of at least the input-only variables, one or more middle layer of hidden nodes, and a bottom layer of nodes of the output-only and the input-and-output variables. At least one cluster is determined from this model. The model can be a probabilistic neural network and/or a Bayesian network.',\n",
       " 'A GPS receiver includes a satellite receiver/processor having an input that receives input signals from at least one GPS satellite. The output of the receiver/processor provides satellite-related navigation information. A neural network receives the satellite-related information to obtain an output signal representative of receiver-related navigation information. The neural network includes a first node layer connected to a second node layer through a first connection layer and a third node layer connected to the second node layer through a second connection layer. Each of the node layers comprises a plurality of neurons.',\n",
       " 'A GPS receiver includes a satellite receiver/processor having an input that receives input signals from at least one GPS satellite. The output of the receiver/processor provides satellite-related navigation information. A neural network receives the satellite-related information to obtain an output signal representative of receiver-related navigation information. The neural network includes a first node layer connected to a second node layer through a first connection layer and a third node layer connected to the second node layer through a second connection layer. Each of the node layers comprises a plurality of neurons.',\n",
       " 'A method for producing a graph representation of an input image, the method including the procedures of applying convolutional layers of a trained convolutional neural network on the input image, defining a receptive field of a last convolutional layer of the trained convolutional neural network as a vertex of the graph representation, defining a vector of a three dimensional output matrix of the last convolutional layer that is mapped to the receptive field as a descriptor for the vertex and determining an edge between a pair of vertices of the graph representation by applying an operator on a pair of descriptors respective of the pair of vertices.',\n",
       " 'A ground anchorage testing arrangement having an impulse imparting apparatus connectable to a ground anchorage tendon (20) or element thereof to be tested, the impulse imparting apparatus comprising an attachment means (22) for attachment to the ground anchorage tendon (20), a movable mass (31), a guide (28, 34) for guiding movement of the mass in the direction substantially aligned with the axis 0 of the ground anchorage to be tested and a drive means for imparting a driving force to move the mass in said direction (not shown). A method of assessing the integrity of ground anchorages, the method comprising the steps of (a) imparting a load impulse to a ground anchorage tendon to be tested, (b) monitoring the vibrational response signal of the anchorage to the imparted load impulse, (c) conditioning the vibrational response signal and (d) applying the conditioned vibrational response signal to an artificial neural network.',\n",
       " 'A system, method and computer program product for navigating categorized information, including (a) a two-dimensional map displayed to a user on a screen, the map showing search terms relating to a subject matter, where the display of the search terms corresponds to relationship between the terms, and wherein a manner of display of the terms corresponds to their relative importance to the subject matter; and (b) a neural network underlying the map, wherein the manner of display and a selection of the search terms is derived from the neural network. The manner of display includes font color, font size, font transparency, distance between search terms and positioning of the search terms within the map. Positioning of a cursor over one of the search terms rearranges the search terms on the map to correspond to an increased relevance of the one of the search terms, while the cursor is over the one of the search terms. Clicking on the one of the search terms corresponds to navigating into a sub-subject matter of the one of the search terms.',\n",
       " 'A system, method and computer program product for navigating categorized information, including (a) a two-dimensional map displayed to a user on a screen, the map showing search terms relating to a subject matter, where the display of the search terms corresponds to relationship between the terms, and wherein a manner of display of the terms corresponds to their relative importance to the subject matter; and (b) a neural network underlying the map, wherein the manner of display and a selection of the search terms is derived from the neural network. The manner of display includes font color, font size, font transparency, distance between search terms and positioning of the search terms within the map. Positioning of a cursor over one of the search terms rearranges the search terms on the map to correspond to an increased relevance of the one of the search terms, while the cursor is over the one of the search terms. Clicking on the one of the search terms corresponds to navigating into a sub-subject matter of the one of the search terms.',\n",
       " 'A system, method and computer program product for navigating categorized information, including (a) a two-dimensional map displayed to a user on a screen, the map showing search terms relating to a subject matter, where the display of the search terms corresponds to relationship between the terms, and wherein a manner of display of the terms corresponds to their relative importance to the subject matter; and (b) a neural network underlying the map, wherein the manner of display and a selection of the search terms is derived from the neural network. The manner of display includes font color, font size, font transparency, distance between search terms and positioning of the search terms within the map. Positioning of a cursor over one of the search terms rearranges the search terms on the map to correspond to an increased relevance of the one of the search terms, while the cursor is over the one of the search terms. Clicking on the one of the search terms corresponds to navigating into a sub-subject matter of the one of the search terms.',\n",
       " 'A Hamming neural network circuit is provided with N binary inputs and M exemplar template outputs, and has a template matching calculation subnet and a winner-take-all subnet. The template matching calculation subnet includes M first neurons in which M exemplar templates are stored respectively. Each first neuron includes N pull-up and pull-down transistor pairs connected in parallel with each other, and connected to and controlled by the N binary inputs, respectively, so that the M first neurons generate M template matching signals depending on the matching degrees between the N binary inputs and the M exemplar templates. The winner-take-all subnet includes M second neurons, each having a template competition node, a load element connected between a power source and the template competition node, and a competition circuit connected between the template competition node and ground. The M template competition nodes are connected to the M template matching signals respectively for generating the M exemplar template outputs. The competition circuit of each second neuron includes M -1 parallel-connected transistors controlled respectively by the template competition nodes of all second neurons except the template competition node of itself so that the template competition node connecting with the largest template matching signal is eventually at a relatively high voltage level, and the other template competition nodes are at a relatively low voltage level, after competition.',\n",
       " 'A method and system for recognizing user input information including cursive handwriting and spoken words. A time-delayed neural network having an improved architecture is trained at the word level with an improved method, which, along with preprocessing improvements, results in a recognizer with greater recognition accuracy. Preprocessing is performed on the input data and, for example, may include resampling the data with sample points based on the second derivative to focus the recognizer on areas of the input data where the slope change per time is greatest. The input data is segmented, featurized and fed to the time-delayed neural network which outputs a matrix of character scores per segment. The neural network architecture outputs a separate score for the start and the continuation of a character. A dynamic time warp (DTW) is run against dictionary words to find the most probable path through the output matrix for that word, and each word is assigned a score based on the least costly path that can be traversed through the output matrix. The word (or words) with the overall lowest score (or scores) are returned. A DTW is similarly used in training, whereby the sample ink only need be labeled at the word level.',\n",
       " 'A system for recognizing handwritten characters, including pre-processing apparatus for generating a set of features for each handwritten character, a neural network disposed for operating on sparse data structures of those features and generating a set of confidence values for each possible character symbol which might correspond to the handwritten character, and post-processing apparatus for adjusting those confidence values and for selecting a character symbol consistent with external knowledge about handwritten characters and the language they are written in. The pre-processing apparatus scales and re-parameterizes the handwritten strokes, encodes the scaled and re-parameterizd strokes into fuzzy membership vectors and binary pointwise data, and combines the vectors and data into a sparse data structure of features. The (nonconvolutional) neural network performs a matrix-vector multiply on the sparse data structure, using only the data for nonzero features collected in that structure, and, for a first layer of that neural network, using only successive chunks of the neural weights. The post-processing apparatus adjusts the confidence values for character symbols using a set of expert rules embodying common-sense knowledge, from which it generates a set of character probabilities for each character position; these character probabilities are combined with a Markov model of character sequence transitions and a dictionary of known words, to produce a final work output for a sequence of handwritten characters.',\n",
       " \"Handwriting recognition techniques employing a personalized handwriting recognition engine. The recognition techniques use examples of an individual's previous writing style to help recognize new pen input from that individual. The techniques also employ a shape trainer to select samples of an individual's handwriting that accurately represent the individual's writing style, for use as prototypes to recognize subsequent handwriting from the individual. The techniques also alternately or additionally employ an intelligent combiner to combine the recognition results from the personalized recognition engine and the conventional recognition engine (or engines). The combiner may use a comparative neural network to combine the recognition results from multiple recognition engines. The combiner alternately may use a rule-based system based on prior knowledge of different recognition engines.\",\n",
       " 'New neural networks for handwriting recognition may be build from existing neural networks. An existing neural network pre-trained for a starting language is chosen based on a desired target language. The neural network is modified so that it may be used to recognize characters of the target language, and the modified neural network is used in a handwriting recognizer for the target language. Modification includes copying one or more of the primary outputs of the existing neural network. An appropriate starting language may be chosen based on the desired target language. In addition, a “super network” may be provided that is a relatively large neural network configured to recognize characters from a number of different languages. One may customize a handwriting recognizer using such a super network by programming a mask to block outputs from the super network that are not necessary for the language desired to be recognized.',\n",
       " 'In a method for training an artificial neural network based algorithm designed to monitor a first device, a processor receives a first data. A processor determines a first service action recommendation for a first device using the received first data and an artificial neural network (ANN) algorithm. A processor causes a second device to provide haptic feedback using the received first data. A processor receives a second service action recommendation for the first device based on the haptic feedback. A processor adjusts at least one parameter of the ANN algorithm such that the ANN algorithm determines a third service action recommendation for the first device using the received first data, wherein the third service action recommendation is equivalent to the second service action recommendation.',\n",
       " 'In a method for training an artificial neural network based algorithm designed to monitor a first device, a processor receives a first data. A processor determines a first service action recommendation for a first device using the received first data and an artificial neural network (ANN) algorithm. A processor causes a second device to provide haptic feedback using the received first data. A processor receives a second service action recommendation for the first device based on the haptic feedback. A processor adjusts at least one parameter of the ANN algorithm such that the ANN algorithm determines a third service action recommendation for the first device using the received first data, wherein the third service action recommendation is equivalent to the second service action recommendation.',\n",
       " 'In a method for training an artificial neural network based algorithm designed to monitor a first device, a processor receives a first data. A processor determines a first service action recommendation for a first device using the received first data and an artificial neural network (ANN) algorithm. A processor causes a second device to provide haptic feedback using the received first data. A processor receives a second service action recommendation for the first device based on the haptic feedback. A processor adjusts at least one parameter of the ANN algorithm such that the ANN algorithm determines a third service action recommendation for the first device using the received first data, wherein the third service action recommendation is equivalent to the second service action recommendation.',\n",
       " 'A method and apparatus for calculating an expected access time associated with one of a plurality of disk drive commands employs one or more neural networks. A plurality of disk drive commands received from an external source are stored in a memory, typically in a queue. Using a neural network, an expected access time associated with each of the queued commands is determined. Determining the expected access time associated with each of the queued commands involves determining a time for performing a seek and settle operation for each of the queued commands and a latency time associated with each of the queued commands. The command indicated by the neural network as having a minimum expected access time relative to access times associated with other ones of the queued commands is identified for execution. A first neural network may be used to determine an expected access time associated with each read command stored in a read command queue and a second neural network may be used to determine an expected access time associated with each write command stored in a write command queue. A pair of read and write neural networks may be associated with each of a number of read/write transducers employed in a disk drive system. The neural network may be trained at the time of manufacture and on a periodic basis during the service life of the disk drive.',\n",
       " 'Embodiments of the invention relate to a neural network system for simulating neurons of a neural model. One embodiment comprises a memory device that maintains neuronal states for multiple neurons, a lookup table that maintains state transition information for multiple neuronal states, and a controller unit that manages the memory device. The controller unit updates a neuronal state for each neuron based on incoming spike events targeting said neuron and state transition information corresponding to said neuronal state.',\n",
       " 'Embodiments of the invention relate to a neural network system for simulating neurons of a neural model. One embodiment comprises a memory device that maintains neuronal states for multiple neurons, a lookup table that maintains state transition information for multiple neuronal states, and a controller unit that manages the memory device. The controller unit updates a neuronal state for each neuron based on incoming spike events targeting said neuron and state transition information corresponding to said neuronal state.',\n",
       " 'This disclosure describes embodiments for a hardware based neural network integrated circuit classifier incorporating natively implemented Radial Basis functions, Restricted Coulomb Energy function, and/or kNN to make it more practical for handling a broader group of parallel algorithms.',\n",
       " 'A nonlinear neuron classifier comprising a neuron array including a plurality of neuron chips each including a plurality of neurons of variable length and variable depth, the chips processing input vectors of variable length and variable depth that are input into the classifier for comparison against vectors stored in the classifier, wherein an NSP flag is set for a plurality of the neurons to indicate that only that plurality of neurons is to participate in the vector calculations. A virtual content addressable memory flag is set for certain of the neuron chips to enable functions including fast readout of data from the chips. Results of vector calculations are aggregated for fast readout for a host computer interfacing with the classifier.',\n",
       " 'This application discloses hardware suitable for use in a neural network system. It makes use of Z-technology modules, each containing densely packaged electronic circuitry. The modules provide access planes which are electrically connected to circuitry located on planar surfaces interfacing with such access planes. One such planar surface comprises a resistive feedback network. By combining two Z-technology modules, whose stacked chips are in planes perpendicular to one another, and using switching networks between the two modules, the system provides bidirectional accessibility of each individual electronic element in the neural network to most or all of the other individual electronic elements in the system.',\n",
       " 'A method includes receiving, at a neural network, a subset of images of a plurality of images of a training image set. The method includes training the neural network by iteratively adjusting parameters of the neural network based on concurrent application of multiple loss functions to the subset of images. The multiple loss functions include a classification loss function and a hashing loss function. The classification loss function is associated with an image classification function that extracts image features from an image. The hashing loss function is associated with a hashing function that generates a hash code for the image.',\n",
       " 'A passive/active infrared imaging system apparatus for mounting on a head/helmet includes a passive infrared camera Head Pack having a removable narrow band filter cover, an objective lens, a beam splitter, an uncooled focal plane array (UFPA) package, an interface board, and a display unit such a liquid crystal display (LCD), with forward/back, up/down, and tilt adjustment functions fitting any mask, mounted in the front of said head/helmet for converting infrared light images into electronic signals. An electronic unit coupled between the UFPA of the infrared camera and the display unit, includes a controller for processing video signals from the infrared camera and supplying them to the display unit. The electronic circuit includes a wireless video & audio transceiver, a piezoelectric microphone, a voice controller, and a neural network pattern recognition chip. The display unit (such as LCD)] is inside the head pack and mounted on the head/helmet for converting electronic signals into visible light images, so that it is in front of eyes of a user, so that the user can directly view an external scene without blocking his normal vision, if the optical axis of the display unit is aligned with the optical axis of the objective lens, the system parallax is eliminated. A Battery Pack having a video controller board and battery is mounted on the rear of the head/helmet so that it gives the video output and power to the infrared system. An eye-safe near infrared laser diode with corresponding optical and electronic attachments mounted on the head/helmet illuminates targets to get images through same passive infrared system.',\n",
       " \"Method and system for the analysis and source localization of the dynamical patterns in medical and health data, and linking such dynamical patterns with the individual's genetic and/or molecular data. The invention makes use of optimally positioned sensors (sensor arrays) providing input data for signal processing, time-series analysis, pattern recognition and mathematical modeling to facilitate dynamical tracking of systemic arterial pressure without a pressure cuff, local vascular activity, electrocardiographic (ECG), respiratory, physical, muscular, gastrointestinal and neural activity, temperature and other physiological/health data. The invention also facilitates separation of local signals (such as local aneurisms or local vascular activity) from non-local, central or systemic patterns (e.g. systemic blood pressure). In addition, the invention improves identification of dynamical patterns associated with a specific genotype/disorder for screening, personalized risk assessment, diagnosis and treatment control. The system can be implemented in a specialized processor, such as an ambulatory blood pressure monitor, Electrocardiograph, Holter monitor located outside subject's body or implanted inside the body, mobile/cell phone or Smart Phone/Personal Digital Assistant, computer or computer network (the Internet), including wireless or mobile network. The system can be also linked to the electronic health/medical records and other databases.\",\n",
       " \"A medical facility after discharge of a cardiovascular patient, can remain in contact with the patient. The patient is provided with a multiple lead EKG terminal spread placed on the body, and the signals therefrom are collected and transmitted. They are transmitted to a remote central location. At the central location, the transmitted EKG data is analyzed. It is compared with normal EKG signals and signals captured in time from the same patient as part of the patient history. The evaluation is done through a neural network which forms an output signal automatically or through intervention of a cardiologist sending an alarm condition signal to the patient instructing the patient to get immediate treatment at the patient's location or to otherwise go to a specific medical facility. Signal preparation includes providing EKG signals through a multiplexer, conversation into a digital data, removal of bias signals, stabilization of this EKG base line, compression and data transmission through a modulator. The receive signal is reconstructed to provide an EKG signal of the patient which is then evaluated in the neural network. As appropriate, transmitter/receiver repeater stations and synchronous satellites are used to convey these signals.\",\n",
       " 'A heart monitoring apparatus and method is disclosed wherein an electrocardiograph signal is obtained from a patient and processed to enhance the salient features and to suppress noise. A plurality n of values representative of the features of the electrocardiograph signal are generated and used in a Kohonen neural network to generate an n dimensional vector. This vector is compared with a stored plurality m of n dimensional reference vectors defining an n dimensional Kohonen feature map to determine the proximity of the vector to the reference vectors. If it is determined by the Kohonen neural network that the vector is within or beyond a threshold range of the reference vectors a signal is output which can be used to initiate an event such as the generation of an alarm or the storage of ECG data.',\n",
       " 'An improved heart rate monitor is provided that can detect and distinguish a heartbeat from an otherwise contaminated system with noise components potentially larger than the signal of interest. Embodiments of the inventive monitor have an amplification system that eliminates large noise components so as not to saturate the system during detection of a desired low amplitude signal. In embodiments the elimination of noise components is accomplished through wavelet decomposition, and the removal of undesired components including interference components during adaptive gain control (AGC), in addition to hunting algorithms which minimize the error with techniques such as neural network least mean squares type back propagation algorithms.',\n",
       " 'A heat dissipation control system comprises a sensing unit, an artificial neural network computing unit, and two heat dissipation units. The artificial neural network computing unit performs computation for controlling based on a plurality of electronic-device temperatures sent out by the sensing unit. The computation for controlling performs a back propagation algorithm on an objective function which is defined a as the square of an error function. Accordingly, cooling effects suitable for the heat dissipation units are generated in order to achieve an optimum heat dissipation effect.',\n",
       " 'An image processing system and/or method obtains source images in which a damaged vehicle is represented, and performs image processing techniques to determine, predict, estimate, and/or detect damage that has occurred at various locations on the vehicle. The image processing techniques may include generating a composite image of the damaged vehicle, aligning and/or isolating the image, applying convolutional neural network techniques to the image to generate damage parameter values, where each value corresponds to damage in a particular location of vehicle, and/or other techniques. Based on the damage values, the image processing system/method generates and displays a heat map for the vehicle, where each color and/or color gradation corresponds to respective damage at a respective location on the vehicle. The heat map may be manipulatable by the user, and may include user controls for displaying additional information corresponding to the damage at a particular location on the vehicle.',\n",
       " 'A heater on-time computing unit, provided in a heater control device, has a first fuzzy neural network for computing a heater on-time in accordance with a surface temperature of a heat fixing roller and a surface temperature change obtained from surface temperatures. A roller surface temperature predicting unit has the second fuzzy neural network for computing a predicted temperature of the heater in accordance with a surface temperature, a surface temperature change obtained from surface temperatures, and a heater on-time computed by the heater on-time computing unit. Thereby only roughly setting of parameters is required because the parameters are adjusted by sequential learning so that the optimal heater on-time is obtained. Therefore, the programming is simplified and it is possible to comply with differences in such as models, individuals, deterioration due to aging, and changes in environments.',\n",
       " 'A heater controlling unit used in a heat fusing device of an image forming apparatus, such as a copying machine, comprises a temperature detecting unit for outputting a detected temperature, a temperature change rate computing unit for computing the surface temperature of a heat fusing roller using the output of the temperature detecting unit, and an on-time computing and controlling unit for computing a heater on-time within a predetermined period by means of a fuzzy neural network using the above temperature and a temperature change rate found by the temperature-change rate computing unit, a heater controlling circuit for controlling the on/off action of the heater, a predictive computing unit for predicting the surface temperature, and a comparing and adjusting unit for comparing the actual temperature with the predicted temperature, and, when the difference is greater than a predetermined value (e.g., .+-.5.degree. C.), for adjusting the weights of the links within the network. Accordingly, the roughly-set parameters can be amended to the ones for an optimal on-time by the sequential learning. As a result, the program can be generated in a simpler manner, and the program can be changed easily for individual units depending on aged distortion and environments thereof.',\n",
       " 'A heuristic control system and method for use with a computer-aided design, capable of learning complicated control and achieving an optimizing task with a fewer number of iteration. The heuristic control system includes: rule-based system for choosing and evaluating a rule among a plurality of given rules; training system for choosing strongly a rule whose evaluation result is favorable based on a predetermined value which evaluates an evaluation result of the rule-based system, and for generating a learning pattern; and neural network for designing an optimized circuit based on a signal fed from the training system and for sending a resultant signal to the rule-based system for another iteration of heuristic control. The learning method includes the steps of: choosing and evaluating a rule among a plurality of given rules; choosing strongly a rule whose evaluation result is favorable based on a predetermined value; generating a learning pattern which brings a desirable result based on the evaluating step; designing an optimized circuit based on the learning pattern generated; and choosing and evaluating iteratively a rule among a plurality of given rules.',\n",
       " 'Plural efferent signal paths paired with plural conventional afferent signal paths respectively are provided between lower order cell-layers and higher order cell-layers of a neural network model. Once an output response has been derived from the higher order cell-layer, an efferent signal is transmitted through the efferent signal path paired with the afferent signal path concerned in the output response. Under the control of which efferent signal, the afferent signal path contributing to the output response of the higher order cell-layer is affected by an excitatory effect, while the afferent signal path not contributing to the same is affected by an inhibitory effect. Hence the information processing consisting of both the associative memory and the pattern recognition provided with the faculty of segmentation can be attained despite deformation and positional error of the input pattern.',\n",
       " 'Highly accurate, reliable optical character recognition is afforded by a layered network having several layers of constrained feature detection wherein each layer of constrained feature detection includes a plurality of constrained feature maps and a corresponding plurality of feature reduction maps. Each feature reduction map is connected to only one constrained feature map in the same layer for undersampling that constrained feature map. Units in each constrained feature map of the first constrained feature detection layer respond as a function of a corresponding kernel and of different portions of the pixel image of the character captured in a receptive field associated with the unit. Units in each feature map of the second constrained feature detection layer respond as a function of a corresponding kernel and of different portions of an individual feature reduction map or a combination of several feature reduction maps in the first constrained feature detection layer as captured in a receptive field of the unit. The feature reduction maps of the second constrained feature detection layer are fully connected to each unit in the final character classification layer. Kernels are automatically learned by constrained back propagation during network initialization or training.',\n",
       " 'A multi-featured control system which improves the manufacturing capability of the thin-film semiconductor growth process. This system improves repeatability and accuracy of the process, reduces the manpower requirements to operate MBE, and improves the MBE environment for scientific investigation. This system has three levels of feedback control. The first level improves the precision and tracking of the process variables, flux, and substrate temperature. The second level comprises an expert system that uses sensors to monitor the status of the product in order to tailor the process plan in real time so that the exact qualities desired are achieved. The third level features a continuously evolving neural network model of the process which is used to recommend the recipe and command inputs to achieve a desired goal. The third level is particularly useful during the development process for new materials. All three levels require models of the process which are updated during automatic process identification experiments.',\n",
       " '\" The present invention relates to a hierarchical artificial neural network (HANN) for automating the recognition and identification of patterns in data matrices. It has particular, although not exclusive, application to the identification of severe storm events (SSEs) from spatial precipitation patterns, derived from conventional volumetric radar imagery. To identify characteristic features a data matrix, the data matrix is processed with a self organizing network to produce a self organizing feature space mapping. The self organizing feature space mapping is processed to produce a density characterization of the feature space mapping. The self organizing network is preferably completely unsupervised. It may, under some circumstances include a supervised layer, but it must include at least an unsupervised component for the purposes of the invention. The \"\"self organizing feature space\"\" is intended to include any map with the self organizing characteristics of the Kohonen Self Organizing Feature Map. The frequency vector of a CAPPI image that has been derived is a data abstraction that can be displayed directly for examination. In preferred embodiments, it is presented to a classification network, e.g. the standard CPN network, for classifying the density vector representation of the three dimensional data and displaying a representation of classified features in the three dimensional data. A novel methodology is preferably used for incorporating vigilance and conscience mechanisms in the forward counterpropagation network during training. \"',\n",
       " '\" The present invention relates to a hierarchical artificial neural network (HANN) for automating the recognition and identification of patterns in data matrices. It has particular, although not exclusive, application to the identification of severe storm events (SSEs) from spatial precipitation patterns, derived from conventional volumetric radar imagery. To identify characteristic features a data matrix, the data matrix is processed with a self organizing network to produce a self organizing feature space mapping. The self organizing feature space mapping is processed to produce a density characterization of the feature space mapping. The self organizing network is preferably completely unsupervised. It may, under some circumstances include a supervised layer, but it must include at least an unsupervised component for the purposes of the invention. The \"\"self organizing feature space\"\" is intended to include any map with the self organizing characteristics of the Kohonen Self Organizing Feature Map. The frequency vector of a CAPPI image that has been derived is a data abstraction that can be displayed directly for examination. In preferred embodiments, it is presented to a classification network, e. g. the standard CPN network, for classifying the density vector representation of the three dimensional data and displaying a representation of classified features in the three dimensional data. A novel methodology is preferably used for incorporating vigilance and conscience mechanisms in the forward counterpropagation network during training. \"',\n",
       " 'A disclosed facial recognition system (and method) includes face parsing. In one approach, the face parsing is based on hierarchical interlinked multiscale convolutional neural network (HIM) to identify locations and/or footprints of components of a face image. The HIM generates multiple levels of image patches from different resolution images of the face image, where image patches for different levels have different resolutions. Moreover, the HIM integrates the image patches for different levels to generate interlinked image patches for different levels, where interlinked image patches for different levels have different resolutions. Furthermore, the HIM combines the interlinked image patches to identify refined locations and/or footprints of components.',\n",
       " 'Hierarchical routing for two-way information flow and structural plasticity in a neural network is provided. In one embodiment the network includes multiple core modules, wherein each core module has a plurality of incoming connections with predetermined addresses. Each core module also has a plurality of outgoing connections such that each outgoing connection targets an incoming connection in a core module among the multiple core modules. The network also has a routing system that selectively routes signals among the core modules based on a reconfigurable hierarchical organization of the core modules. The network approximates a fully connected network such that each outgoing connection on any core module can target and reach any incoming connection on any core module without requiring a fully connected network. The routing system provides two-way information flow between neurons utilizing hierarchical routing.',\n",
       " 'In one embodiment, the present invention provides a neural network circuit comprising multiple symmetric core circuits. Each symmetric core circuit comprises a first core module and a second core module. Each core module comprises a plurality of electronic neurons, a plurality of electronic axons, and an interconnection network comprising multiple electronic synapses interconnecting the axons to the neurons. Each synapse interconnects an axon to a neuron. The first core module and the second core module are logically overlayed on one another such that neurons in the first core module are proximal to axons in the second core module, and axons in the first core module are proximal to neurons in the second core module. Each neuron in each core module receives axonal firing events via interconnected axons and generates a neuronal firing event according to a neuronal activation function.',\n",
       " 'Pattern recognition, for instance optical character recognition, is achieved by training a neural network, scanning an image, segmenting the image to detect a pattern, preprocessing the detected pattern, and applying the preprocessed detected pattern to the trained neural network. The preprocessing includes determining a centroid of the pattern and centrally positioning the centroid in a frame containing the pattern. The training of the neural network includes randomly displacing template patterns within frames before applying the template patterns to the neural network.',\n",
       " 'A physical neural network synapse chip and a method for forming such a synapse chip. The synapse chip can be configured to include an input layer comprising a plurality of input electrodes and an output layer comprising a plurality of output electrodes, such that the output electrodes are located perpendicular to the input electrodes. A gap is generally formed between the input layer and the output layer. A solution can then be provided which is prepared from a plurality of nanoconductors and a dielectric solvent. The solution is located within the gap, such that an electric field is applied across the gap from the input layer to the output layer to form nanoconnections of a physical neural network implemented by the synapse chip. Such a gap can thus be configured as an electrode gap. The input electrodes can be configured as an array of input electrodes, while the output electrodes can be configured as an array of output electrodes.',\n",
       " 'Nodal outputs are discretized to values of S2.sup.n where n is an integer and S is equal to +1 or -1. During forward propagation, this offers the advantage of forming a product of a nodal output and a weight using a simple shift operation rather than a multiply operation. Replacing multiply operations with shift operations through out a neural network improves response times and permits building larger networks that have broader applicability. Training is also improved by increasing the efficiency of backward propagation. The multiplications involved in backward propagation are reduced To shift operations by discretizing the errors associated with each node so that they are represented as 2.sup.n where n is an integer and S is equal to +1 or -1.',\n",
       " 'In order to improve the problematical points concerning the structure and the processing speed of a prior art neural network, the optimum structure of the neural network, in which a synapse structure constructed on the basis of living body physiological knowledge or presumed therefrom is determined to make it possible to realize high level information processing functions such as feature extraction, feature unification, memory, etc. Applications to an image recognition, a movement control, etc. making the most of the robust recognizing power thereof, or application to an optimum problem, a large scale numerical analysis, etc. making the most of the parallel processing power thereof are made possible.',\n",
       " 'A multifrequency detector, such as a DTMF detector, includes a Goertzel module detecting energies of a current frame of an incoming signal at nominal tone frequencies. A number of ratios are computed from the detected energies and supplied as an input to a multidimensional thresholding device such as a neural network. The neural network generates a decision level to be used in a subsequent frame decision. A frequency estimation module also receives the incoming signal and generates a number of frequency estimation indications to be used in the final determination of whether the incoming signal contains a valid multifrequency signal. A low-level decision module returns a frame decision result (D/N) for the current frame based on inputs from the Goertzel module and the decision level. A high-level decision module receives the frame decision result and information based on the frequency estimation indications. A state machine generates a digit start signal when the frame decision result and the frequency estimation information indicate a transition from an out-of-digit state to an in-digit state. The detector outputs a suggested digit provided by the Goertzel module and an affirmative digit detection result when the state machine transitions from out-of-digit to in-digit.',\n",
       " 'Systems and methods are disclosed for speeding up a computer having a graphics processing unit (GPU) and a general purpose processor (GP-GPU) by decoupling a convolution process for a first matrix into a row part and a column part; expanding the row part into a second matrix; performing matrix multiplication using the second matrix and a filter matrix; and performing reduction on an output matrix.',\n",
       " 'The present invention discloses increased bit resolution of a charge coupled device (CCD)/charge injection device (CID) matrix vector multiplication (MVM) processor by storing each bit of each matrix element as a separate CCD charge packet. The bits of each input vector are separately multiplied by each bit of each matrix element in massive parallelism and the resulting products are combined appropriately to synthesize the correct product. In addition, such arrays are employed in a pseudo-spectral method of the invention, in which partial differential equations are solved by expressing each derivative analytically as matrices, and the state function is updated at each computation cycle by multiplying it by the matrices. The matrices are treated as synaptic arrays of a neutral network and the state function vector elements are treated as neurons. Further, moving target detection is performed by driving the soliton equation with a vector of detector outputs. The neural architecture consists of two synaptic arrays corresponding to the two differential terms of the soliton equation and an adder connected to the output thereof and to the output of the detector array to drive the soliton equation.',\n",
       " 'The present invention enhances the bit resolution of a CCD/CID MVM processor by storing each bit of each matrix element as a separate CCD charge packet. The bits of each input vector are separately multiplied by each bit of each matrix element in massive parallelism and the resulting products are combined appropriately to synthesize the correct product. In another aspect of the invention, such arrays are employed in a pseudo-spectral method of the invention, in which partial differential equations are solved by expressing each derivative analytically as matrices, and the state function is updated at each computation cycle by multiplying it by the matrices. The matrices are treated as synaptic arrays of a neural network and the state function vector elements are treated as neurons. In a further aspect of the invention, moving target detection is performed by driving the soliton equation with a vector of detector outputs. The neural architecture consists of two synaptic arrays corresponding to the two differential terms of the soliton-equation and an adder connected to the output thereof and to the output of the detector array to drive the soliton equation.',\n",
       " 'This invention relates to a high speed packet switching controller in a telephone switching system which can suitably be applied to a packet controller having large capacity using a neural network chip and maximize the system performance by the optimized switching operation. The high speed packet switching controller comprises a row address decoder for decoding a weight raw address which is inputted thereto, a column address decoder for decoding a weight column address which is inputted thereto, a matrix array for providing the neural network using address signals provided from the row address decoder and column address decoder and outputing varied voltage in accordance with an external weight value, a neural network for producing a final crossbar switching control signal, an external input/output bus for transmitting an output signal of the neural network, and an internal neural data bus for transmitting the address signal output from the row address decoder and column address decoder to the matrix array.',\n",
       " 'A high speed, feed forward, segmented neural network and fabrication technique are described. The segmented network includes a plurality of network layers stacked in an ascending pyramid fashion. The network layers are structured with a plurality of subnetworks, and within each subnetwork exists a plurality of nodes structured in a fully interconnected and/or partially interconnected layered neural network arrangement. The inputs and outputs of each subnetwork are one bit digital values constrained to `0` or `1`, while any number of nodes with any number of layers may be modeled for each subnetwork. Each subnetwork is independent of all other subnetworks in a given network layer, and thus, each network layer is segmented. In hardware implementation, each subnetwork comprises a simple memory device, such as a RAM or PROM look-up table. The speed of the neural network system is high and largely dictated by the access time of the memory devices used.',\n",
       " 'High-gain MOCVD-grown (metal-organic chemical vapor deposition) AlGaAs/GaAs/AlGaAs n-p-n double heterojunction bipolar transistors (DHBTs) (14) and Darlington phototransistor pairs (14, 16) are provided for use in optical neural networks and other optoelectronic integrated circuit applications. The reduced base (22) doping level used herein results in effective blockage of Zn out-diffusion, enabling a current gain of 500, higher than most previously reported values for Zn-diffused-base DHBTs. Darlington phototransistor pairs of this material can achieve a current gain of over 6,000, which satisfies the gain requirement for optical neural network designs, which advantageously may employ novel neurons (10) comprising the Darlington phototransistor pair in series with a light source (12).',\n",
       " 'An automatic speech recognition system comprising a speech decoder to resolve phone and word level information, a vector generator to generate information vectors on which a confidence measure is based by a neural network classifier (ANN). An error signal is designed which is not subject to false saturation or over specialization. The error signal is integrated into an error function which is back propagated through the ANN.',\n",
       " 'Advantageous neural network realizations are achieved by employing only negative gain amplifiers and a clipped T matrix having conductances T.sub.ij which have only two values. Preferably, one of these values is a preselected value set by the value of a fixed resistor, and the other value is zero, created simply with an open circuit. Values for the T.sub.ij terms of the clipped T matrix are obtained through an iterative process which operates on the clipped and nonclipped matrices and minimizes the error resulting from the use of the clipped T matrix.',\n",
       " 'An on-line training neural network for process control system and method trains by retrieving training sets from the stream of process data. The neural network detects the availability of new training data, and constructs a training set by retrieving the corresponding input data. The neural network is trained using the training set. Over time, many training sets are presented to the neural network. When multiple presentations are needed to effectively train, a buffer of training sets is filled and updated as new training data becomes available. The size of the buffer is selected in accordance with the training needs of the neural network. Once the buffer is full, a new training set bumps the oldest training set off the top of the buffer stack. The training sets in the buffer stack can be presented one or more times each time a new training set is constructed. An historical database of timestamped data can be used to construct training sets when training input data has a time delay from sample time to availability for the neural network. The timestamps of the training input data are used to select the appropriate timestamp at which input data is retrieved for use in the training set. Using the historical database, the neural network can be trained retrospectively by searching the historical database and constructing training sets based on past data.',\n",
       " 'An on-line training neural network for controlling a process for producing a product having at least one product property that trains by retrieving training sets from a stream of process data. The neural network detects the availability of new training data, and constructs a training set by retrieving the corresponding input data. The neural network is trained using the training set. Over time, many training sets are presented to the neural network. When multiple presentations are needed to effectively train, a buffer of training sets is filled and updated as new training data becomes available. The size of the buffer is selected in accordance with the training needs of the neural network. Once the buffer is full, a new training set bumps the oldest training set off the top of the buffer stack. The training sets in the buffer stack can be presented one or more times each time a new training set is constructed. An historical database of timestamped data can be used to construct training sets when training input data has a time delay from sample time to availability for the neural network. The timestamps of the training input data are used to select input data for use in the training set. Using the historical database, the neural network can be trained retrospectively by searching the historical database and constructing training sets based on past data.',\n",
       " 'An on-line training neural network for process control system and method trains by retrieving training sets from the stream of process data. The neural network detects the availability of new training data, and constructs a training set by retrieving the corresponding input data. The neural network is trained using the training set. Over time, many training sets are presented to the neural network. When multiple presentations are needed to effectively train, a buffer of training sets is filled-and updated as new training data becomes available. The size of the buffer is selected in accordance with the training needs of the neural network. Once the buffer is full, a new training set bumps the oldest training set off the top of the buffer stack. The training sets in the buffer stack can be presented one or more times each time a new training set is constructed. An historical database of timestamped data can be used to construct training sets when training input data has a time delay from sample time to availability for the neural network. The timestamps of the training input data are used to select the appropriate timestamp at which input data is retrieved for use in the training set. Using the historical database, the neural network can be trained retrospectively by searching the historical database and constructing training sets based on past data.',\n",
       " 'Many computing scenarios involve the classification of content items within one or more categories. The content item set may be too large for humans to classify, but an automated classifier (e.g., an artificial neural network) may not be able to classify all content items with acceptable accuracy. Instead, the automated classifier may calculate a classification confidence while classifying respective content items. Content items having a low classification confidence may be sent to a human classifier, and may be added, along with the categories identified by the human classifier, to a training set. The automated classifier may then be retrained using the training set, thereby incrementally improving the classification confidence of the automated classifier while conserving the involvement of human classifiers. Additionally, human classifiers may be rewarded for classifying the content items, and the costs of such rewards may be considered while selecting content items for the training set.',\n",
       " 'A controller implemented in a heating, ventilation and air-conditioning (HVAC) distribution system provides improved control by implementing a general regression neural network to generate a control signal based on identified characteristics of components utilized within the HVAC system. The general regression neural network utilizes past characteristics and desired (calculated) characteristics to generate an output control signal. The general regression neural network is implemented in a feedforward process, which is combined with a feedback process to generate an improved control signal to control components within the HVAC distribution system. Implementation of the general regression neural network is simple and accurate, requires no input from an operator supervising the controller, and provides adaptive, real-time control of components within the HVAC distribution system.',\n",
       " 'Random access memory is used to store synaptic information in the form of a matrix of rows and columns of binary digits. N rows read in sequence are processed through switches and resistors, and a summing amplifier to N neural amplifiers in sequence, one row for each amplifier, using a first array of sample-and-hold devices S/H1 for commutation. The outputs of the neural amplifiers are stored in a second array of sample-and-hold devices S/H2 so that after N rows are processed, all of said second array of sample-and-hold devices are updated. A second memory may be added for binary values of 0 and -1, and processed simultaneously with the first to provide for values of 1, 0, and -1, the results of which are combined in a difference amplifier.',\n",
       " 'A self-contained chip set architecture for ANN systems, based on back-propagation model with full-connectivity topology, and on-chip learning and refreshing, based on analog chip set technology providing self-contained synapse and neuron modules with fault tolerant neural computing, capable of growing to any arbitrary size as a result of embedded electronic addressing. Direct analog and digital I/O ports allow real-time computation and interface communication with other systems including digital host of any bus bandwidth. Scalability is provided, allowing accommodation of all input/output data sizes and different host platform.',\n",
       " 'A brain-based device (BBD) for moving in a real-world environment has sensors that provide data about the environment, actuators to move the BBD, and a hybrid controller which includes a neural controller having a simulated nervous system being a model of selected areas of the human brain and a non-neural controller based on a computational algorithmic network. The neural controller and non-neural controller interact with one another to control movement of the BBD.',\n",
       " 'A brain-based device (BBD) for moving in a real-world environment has sensors that provide data about the environment, actuators to move the BBD, and a hybrid controller which includes a neural controller having a simulated nervous system being a model of selected areas of the human brain and a non-neural controller based on a computational algorithmic network. The neural controller and non-neural controller interact with one another to control movement of the BBD.',\n",
       " 'The present invention relates to a system and a method for developing an engine model. The system broadly comprises a module for generating a state variable model of an engine, which module receives a plurality of inputs to an engine representative of a particular flight condition and generates a set of estimated engine parameters representative of the model. The system further comprises a comparator for comparing the set of estimated engine parameters to a set of measured engine parameters for generating a set of residuals and an artificial neural network module to be trained and to be used in an implementation configuration after training has been completed. The artificial neural network receives the set of residuals and the engine inputs during a training phase and generates a set of estimated residuals representative of the engine condition.',\n",
       " 'A hybrid analyzer having a data derived primary analyzer and an error correction analyzer connected in parallel is disclosed. The primary analyzer, preferably a data derived linear model such as a partial least squares model, is trained using training data to generate major predictions of defined output variables. The error correction analyzer, preferably a neural network model is trained to capture the residuals between the primary analyzer outputs and the target process variables. The residuals generated by the error correction analyzer is summed with the output of the primary analyzer to compensate for the error residuals of the primary analyzer to arrive at a more accurate overall model of the target process. Additionally, an adaptive filter can be applied to the output of the primary analyzer to further capture the process dynamics. The data derived hybrid analyzer provides a readily adaptable framework to build the process model without requiring up-front knowledge. Additionally, the primary analyzer, which incorporates the PLS model, is well accepted by process control engineers. Further, the hybrid analyzer also addresses the reliability of the process model output over the operating range since the primary analyzer can extrapolate data in a predictable way beyond the data used to train the model. Together, the primary and the error correction analyzers provide a more accurate hybrid process analyzer which mitigates the disadvantages, and enhances the advantages, of each modeling methodology when used alone.',\n",
       " 'A hybrid analyzer having a data derived primary analyzer and an error correction analyzer connected in parallel is disclosed. The primary analyzer, preferably a data derived linear model such as a partial least squares model, is trained using training data to generate major predictions of defined output variables. The error correction analyzer, preferably a neural network model is trained to capture the residuals between the primary analyzer outputs and the target process variables. The residuals generated by the error correction analyzer is summed with the output of the primary analyzer to compensate for the error residuals of the primary analyzer to arrive at a more accurate overall model of the target process. Additionally, an adaptive filter can be applied to the output of the primary analyzer to further capture the process dynamics. The data derived hybrid analyzer provides a readily adaptable framework to build the process model without requiring up-front knowledge. Additionally, the primary analyzer, which incorporates the PLS model, is well accepted by process control engineers. Further, the hybrid analyzer also addresses the reliability of the process model output over the operating range since the primary analyzer can extrapolate data in a predictable way beyond the data used to train the model. Together, the primary and the error correction analyzers provide a more accurate hybrid process analyzer which mitigates the disadvantages, and enhances the advantages, of each modeling methodology when used alone.',\n",
       " 'A query device scans radio frequencies for visible transmitting devices. The querying device receives at least a signal strength and identifier information associated with each of the transmitting devices. The list of visible devices is used to query a database containing location information for a plurality of visible devices. The list may be sent to a locationing system that may perform a location analysis on the resulting data to return a location to the query device. The weighted average of the locations returned in the database query may be computed to determine the location of the querying device, with the weight for each of the locations being the current signal strength detected by the querying device. Neural network analysis may also be used to determine the location of the querying device. Learning and seeding operations many also be used to populate the database with location information for transmitting devices.',\n",
       " 'A query device scans radio frequencies for visible transmitting devices. The querying device receives at least a signal strength and identifier information associated with each of the transmitting devices. The list of visible devices is used to query a database containing location information for a plurality of visible devices. The list may be sent to a locationing system that may perform a location analysis on the resulting data to return a location to the query device. The weighted average of the locations returned in the database query may be computed to determine the location of the querying device, with the weight for each of the locations being the current signal strength detected by the querying device. Neural network analysis may also be used to determine the location of the querying device. Learning and seeding operations many also be used to populate the database with location information for transmitting devices.',\n",
       " 'Aspects of the invention relate to techniques for classifying memory failure bitmaps using both rule-based classification and artificial neural network-based classification methods. The rule-based classification method employs classification rules comprising those for global failure patterns. The artificial neural network-based classification method classifies local failure patterns. One of the artificial neural network models is the Kohonen self-organizing map model. The input vector for a failure pattern may contain four elements: pattern aspect ratio, failing bit ratio, dominant failing column number and dominant failing row number.',\n",
       " 'A method of determining properties relating to the manufacture of an injection-molded article is described. The method makes use of a hybrid model which includes at least one neural network and at least one rigorous model. In order to forecast (or predict) properties relating to the manufacture of a plastic molded part, a hybrid model is used which includes: one or more neural networks NN1, NN2, NN3, NN4, . . . , NNk; and one or more rigorous models R1, R2, R3, R4, . . . , which are connected to one another. The rigorous models are used to map model elements which can be described in mathematical formulae. The neural model elements are used to map processes whose relationship is present only in the form of data, as it is typically impossible to model such processes rigorously. As a result, a forecast (or prediction) relating to properties including, for example, the mechanical, thermal and rheological processing properties and relating to the cycle time of a plastic molded part can be made.',\n",
       " 'A method of predicting the properties (e.g., mechanical and/or processing properties) of an injection-molded article is disclosed. The method makes use of a hybrid model which includes at least one neural network. In order to forecast (or predict) properties with respect to the manufacture of a plastic molded article, a hybrid model is used in the present invention, which includes: one or more neural networks NN1, NN2, NN3, NN4, . . . , NNk; and optionally one or more rigorous models R1, R2, R3, R4, . . . , which are connected to one another. The rigorous models are used to map model elements which can be described in mathematical formulae. The neural networks are used to map processes whose relationship is present only in the form of data, as it is in effect impossible to model such processes rigorously. As a result, a forecast relating to properties including the mechanical, thermal and rheological processing properties and relating to the process time of a plastic molded article is obtained.',\n",
       " 'The hybrid artificial immune system consists of three main layers, including a solution application layer that interacts with the environment, a solution generation layer that solves combinatorial optimization problems and a modeling layer that analyzes problems and presents solution scenarios. The system solves evolutionary multi-objective optimization problems in network computing, robotics, artificial neural networks, protein network modeling, evolutionary systems and evolutionary hardware.',\n",
       " 'A hybrid network 100 which combines a neural network of the self-organized type 110 with a plurality of neural networks of the supervised learning type 150,160,170 to successfully retrieve building address information from a database using imperfect textual retrieval keys. Generally, the self-organized type is a Kohonen Feature Map network, whereas each supervised learning type is a Back Propagation network. A user query 105 produces an activation response 111,112,113 from the self-organized network 110 and this response, along with a new query 151,161,171 derived from the original query 105, activates a selected one of the learning networks R.sub.1,R.sub.2,R.sub.M to retrieve the requested information.',\n",
       " 'A hybrid navigation system including a neural network is provided. The hybrid navigation system includes a global positioning system (GPS) as a main system using satellites and a radio determination system when there are difficulties in reception of signals from the satellites. The hybrid navigation system comprises a GPS signal processor, a TDOA signal processor and a neural network. The GPS signal processor receives GPS signals from the satellites to determine positions. The TDOA signal processor receives determination signals from mobile communication stations to determine positions. The neural network uses position values inputted from each of the GPS signal processor and the TDOA signal processor to learn and predict the position of the mobile terminal.',\n",
       " 'An apparatus for in-depth three dimensional tumor mapping including (A) a light source; (B) a multi-fiber bundle including at least one illumination fiber and at least two receiving fibers, the at least one illumination fiber being connected to the light source; (C) a spectrometer connected to the at least two receiving fibers; and (D) a hybrid neural network connected to the spectrometer, said hybrid neural network including a principle component analysis processor and a neural network classifier.',\n",
       " 'System and method for optimization of a design associated with a response function, using a hybrid neural net and support vector machine (NN/SVM) analysis to minimize or maximize an objective function, optionally subject to one or more constraints. As a first example, the NN/SVM analysis is applied iteratively to design of an aerodynamic component, such as an airfoil shape, where the objective function measures deviation from a target pressure distribution on the perimeter of the aerodynamic component. As a second example, the NN/SVM analysis is applied to data classification of a sequence of data points in a multidimensional space. The NN/SVM analysis is also applied to data regression.',\n",
       " 'System and method for optimization of a design associated with a response function, using a hybrid neural net and support vector machine (NN/SVM) analysis to minimize or maximize an objective function, optionally subject to one or more constraints. As a first example, the NN/SVM analysis is applied iteratively to design of an aerodynamic component, such as an airfoil shape, where the objective function measures deviation from a target pressure distribution on the perimeter of the aerodynamic component. As a second example, the NN/SVM analysis is applied to data classification of a sequence of data points in a multidimensional space. The NN/SVM analysis is also applied to data regression.',\n",
       " 'A method of and system for parallelizing an program, comprising the steps of inputting an algorithm, operating said algorithm on selected data inputs to generate representative outputs, inputting representative outputs into parallelizing algorithms, and outputting a parallel implementation of said algorithm. In particular, this provides a parallel framework for target classification and pattern recognition procedures.',\n",
       " 'A system and a method for recognizing patterns comprises a first stage for xtracting features from inputted patterns and for providing topological representations of the characteristics of the inputted patterns and a second stage for classifying and recognizing the inputted patterns. The first stage comprises two one-layer neural networks and the second stage comprises a feedforward two-layer neural network. Supplying signals representative of a set of inputted patterns to the input layers of the first and second neural networks, training the first and second neural networks using a competitive learning algorithm, and generating topological representations of the input patterns using the first and second neural networks The method further comprises providing a third neural network for classifying and recognizing the inputted patterns and training the third neural network with a back-propagation algorithm so that the third neural network recognizes at least one interested pattern.',\n",
       " 'A computer-implemented method and system for building a neural network is disclosed. The neural network predicts at least one target based upon predictor variables defined in a state space. First, an input data set is retrieved that includes the predictor variables and at least one target associated with the predictor variables for each observation. In the state space, a number of points is inserted in the state space based upon the values of the predictor variables. The number of points is less than the number of observations. A statistical measure is determined that describes a relationship between the observations and the inserted points. Weights and activation functions of the neural network are determined using the statistical measure.',\n",
       " 'A computer-implemented method and system for building a neural network is disclosed. The neural network predicts at least one target based upon predictor variables defined in a state space. First, an input data set is retrieved that includes the predictor variables and at least one target associated with the predictor variables for each observation. In the state space, a number of points is inserted in the state space based upon the values of the predictor variables. The number of points is less than the number of observations. A statistical measure is determined that describes a relationship between the observations and the inserted points. Weights and activation functions of the neural network are determined using the statistical measure.',\n",
       " 'A computer-implemented method and system for building a neural network is disclosed. The neural network predicts at least one target based upon predictor variables defined in a state space. First, an input data set is retrieved that includes the predictor variables and at least one target associated with the predictor variables for each observation. In the state space, a number of points is inserted in the state space based upon the values of the predictor variables. The number of points is less than the number of observations. A statistical measure is determined that describes a relationship between the observations and the inserted points. Weights and activation functions of the neural network are determined using the statistical measure.',\n",
       " 'A method uses a hybrid neural network including a self organizing mapping neural network (SOM NN) and a, back-propagation neural network (BP NN) for color identification. In the method the red, green and blue (RGB) of color samples are input as features of training samples and are automatically classified by way of SOM NN. Afterwards, the outcomes of SOM NN are respectively delivered to various BP NN for further learning; and the map relationship of the input and the output defines the X,Y, Z corresponding the x, y and z values of a coordinate system of the standard color samples of RGB and IT8. By way of the above learning structure, a non-linear model of color identification can be set up. After color samples are self organized and classified by SOM NN network, data can be categorized in clusters as a result of characteristic difference thereof. Then the data are respectively sent to BP NN for learning whereby-the learning system not only can be quickly converged but also lower error discrepancy in operation effectively.',\n",
       " 'The hybrid handwriting recognition method includes the steps of (a), in response to a handwriting input from a user, providing dynamic, time ordered stroke information; (b) determining a first list comprised of at least one probable character that the dynamic, time ordered stroke information is intended to represent; (c) converting the dynamic, time ordered stroke information to static stroke information; (d) determining a second list comprised of at least one probable character that the static stroke information represents; and (e) merging the first list and the second list to provide a third, unified list comprised of at least one element representing a most probable character that the dynamic, time ordered stroke information is intended to represent. The step of converting includes the steps of generating a static, bit-mapped representation of the dynamic stroke information, and generating one or more first stroke features based on contour directions of the bit-mapped stroke information. The first stroke features are applied as inputs to a plurality of neural network recognizers.',\n",
       " 'The invention concerns a method for compressing a digitally coded video frame sequence. In the method, a given frame is divided into blocks, and the information content of selected blocks is modified, relying on information contained in a neighboring block or blocks (prediction), and the blocks are converted from spatial representation into frequency representation. The information content of the transformed blocks is encoded by arithmetic coding. The efficiency of the coding is improved by various methods, such as dynamically partitioning the blocks into sub-blocks, or performing a compressibility analysis is the blocks before carrying out further transformations. The entropy coding uses a neural network to determine the parameters of the arithmetic coding. The frames are dynamically re-scaled, depending on available bandwidth and quality of the coded image.',\n",
       " 'A method for analyzing a fluid containing one or more analytes of interest includes; measuring a plurality of properties of a sample fluid with unknown concentrations of the one or more analytes of interest; and using the measurements and a model of the relationship between the plurality of properties and concentrations of the one or more analytes to calculate the concentration of at least one of the analytes of interest. The model may be an artificial neural network. The method may be used to monitor the concentration of inhibitors of gas hydrate formation in a fluid. Apparatus for use in the method is also provided.',\n",
       " \"A neural logic unit network acting as an agent to achieve machine or device consciousness and intent is disclosed.More specifically, an agent of consciousness and intent (The Agent) is disclosed consisting of neuronal logic units upon which are mapped and connected to the individual outputs of the host system's entire sensorium and which neuronal logic units are activated by the simultaneous presentation of the results of the host system's recognition, tracking, analyzes and characterization computations similar to those performed by biological unconscious brains.The embodiment of the assembly of neural logic units is referred to as Hyper Aware Logic.\",\n",
       " 'A hyperspectral method for detecting the present condition of an avian egg is disclosed in which a neural network algorithm is used to compare the spectrum of a test egg against a spectral library. The method can detect fertility with greater than 90% reliability on the day of laying and the gender of the chick with greater than 75% reliability on the 12th day after laying.',\n",
       " 'A method of tracking a moving object in an image created by use of a synthetic aperture includes identifying a plurality of receive phase centers for an image collector, obtaining a synthetic aperture image using the plurality of receive phase centers, and reading a signature of the moving object based on the synthetic aperture image, where the reading of the signature includes identifying, in the synthetic aperture image, as a function of image collection time, a presence of the moving object. The reading of the signature may also include identifying a changing position of the moving object, and may include associating a plurality of range difference values with respective ones of the plurality of phase centers. A signature of a scatterer may be formed using only its associated ΔR-versus-time profile. The presence of a mover in the image may be determined by filtering the image to detect all or part of a signature, or by using one or more signatures to train a neural network to observe the mover directly.',\n",
       " 'A multi-criteria fire detection system, comprising a plurality of sensors, wherein each sensor is capable of detecting a signature characteristic of a presence of a fire and providing an output indicating the same. A processor for receiving each output of the plurality of sensors is also employed. The processor includes a probabilistic neural network for processing the sensor outputs. The probabilistic neural network comprises a nonlinear, nor-parametric pattern recognition algorithm that operates by defining a probability density function for a plurality of data sets that are each based on a training set data and an optimized kernel width parameter. The plurality of data sets includes a baseline, non-fire, fist data set; a second, fire data set, and a third, nuisance data set. The algorithm provides a decisional output indicative of the presence of a fire based on recognizing and discrimination between said data sets, and whether the outputs suffice to substantially indicate the presence of a fire, as opposed to a non-fire or nuisance situation.',\n",
       " 'The detection method includes generating a plurality of neural network models. Each model has as a training set a data set from a plurality of samples of a commodity of known origins. Each sample has been analyzed for a plurality of elemental concentrations. Each neural network model is presented for classification a test data set from a plurality of samples of a commodity of unknown origins. As with the training set, the samples have been analyzed for the same plurality of elemental concentrations. Next a bootstrap aggregating strategy is employed to combine the results of the classifications for each sample in the test data set made by each neural network model. Finally, a determination is made from the bootstrap aggregating strategy as to a final classification of each sample in the test data set. This final classification is indicative of the geographical origin of the commodity. The system includes software for generating the neural network models and a software routine for performing the bootstrap aggregating strategy.',\n",
       " 'A system, method, and device for identifying data sources for a neural network are disclosed. The exemplary system may have a module for determining load curves for each selected data set. The system may also have a module for determining a global difference measure and a global similarity measure for each load curve of each selected data set. The system may have a module for determining a set of data sets with lowest value global difference measure. The system may also have a module for determining a set of data sets with largest value global similarity measure. The system may also have a module for determining a union of the sets of lowest value difference measure and the sets of largest value similarity measure. The system may also have a module for determining for each set in the union one of a local similarity measure and a local difference measure and a module for selecting a set of reduced data sets based on one of the local similarity measure and the local difference measure.',\n",
       " 'The state or condition of a data storage drive, or a subsystem within a drive, may be evaluated by comparing a set of selected parameter values, converted into a trial vector, with a number of model or exemplar vectors, each of which was represents a particular state or condition of a sample drive. Examples of such conditions may include “good”, “marginal”, “unacceptable”, “worn”, “defective”, or other general or specific conditions. Sets of parameter values from the drive are converted into input vectors. Unprocessed vectors are then processed against the input vectors in an artificial neural network to generate the exemplar vectors. The exemplar vectors are stored in a memory of an operational drive. During operation of the drive, the trial vector is compared with the exemplar vectors. The exemplar vector which is closest to the trial vector represents a state which most closely represents the current state of the drive. Thus, a high similarity between the trial vector and an exemplar vector which represent a “good” drive is likely to have come from a “good” drive.',\n",
       " 'The state or condition of a system may be evaluated by comparing a set of selected parameter values, converted into a trial vector, with a number of model or exemplar vectors, each of which was represents a particular state or condition of a sample system. Examples of such conditions may include “good”, “marginal”, “unacceptable”, “worn”, “defective”, or other general or specific conditions. Sets of parameter values from the system are converted into input vectors. Unprocessed vectors are then processed against the input vectors in an artificial neural network to generate the exemplar vectors. The exemplar vectors are stored in a memory of an operational system. During operation of the system, the trial vector is compared with the exemplar vectors. The exemplar vector which is closest to the trial vector represents a state which most closely represents the current state of the system. Thus, a high similarity between the trial vector and an exemplar vector which represent a “good” system is likely to have come from a “good” system.',\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on computer storage media, for identifying objects in images. One of the methods includes obtaining a first training image; down-sampling the first training image to generate a low-resolution first training image; processing the low-resolution first training image using a first neural network to generate a plurality of features of the low-resolution first training image and first scores for the low-resolution first training image; processing the first scores and the features of the low-resolution first training image using an initial patch locator neural network to generate an initial location of an initial patch of the first training image; locally perturbing the initial location to select an adjusted location for the initial patch of the first training image; and updating the current values of the parameters of the initial patch locator neural network to generate updated values using the adjusted location.',\n",
       " 'Architecture for comparing images by building an initial map from the average color and an inserted blackened area. Accordingly, a map can be built that is more information-rich and smaller, thereby making the system more efficient. The architecture employs a Kohonen neural network (or self-organizing map (SOM)) by guiding the learning of the SOM using characteristics of the images such as average color and a central area. A strong component of the average color of the image and the central area at the approximate center of the image are added to the uninitialized SOM, which allows related colors to converge toward the central area of the image. When input, the SOM organizes the color content of the image on a map, which can be used to compare the image with other images.',\n",
       " 'A computer-implemented method for predicting answers to questions concerning medical image analytics reports includes splitting a medical image analytics report into a plurality of sentences and generating a plurality of sentence embedding vectors by applying a natural language processing framework to the plurality of sentences. A question related to subject matter included in the medical image analytics report is received and a question embedding vector is generated by applying the natural language processing framework to the question. A subset of the sentence embedding vectors most similar to the question embedding vector is identified by applying a similarity matching process to the sentence embedding vectors and the question embedding vector. A trained recurrent neural network (RNN) is used to determine a predicted answer to the question based on the subset of the sentence embedding vectors.',\n",
       " '\" A hybrid filter architecture and an artificial neural network is proposed for image enhancement and detection of suspicious areas in digital x-ray images that is operator, image, and digital x-ray sensor independent. The hybrid filter architecture includes an Adaptive Multistage Nonlinear Filter (AMNF) cascaded with an M-channel Tree Structured Wavelet Transform (TSWT). The AMNF shares the advantages of an array of linear and nonlinear filters and is adaptively supervised using either an order statistic or linear operator. The filter is used for noise suppression and image enhancement and adapts to the noise characteristics of the sensor. The TSWT is used for multiresolution image decomposition and reconstruction of subimages for further image enhancement of diagnostic features of interest. A Multistage Artificial Neural Network (MANN) is proposed, together with Kalman Filtering for network training, for both improved detection or classification of suspicious areas and computational efficiency to allow the MANN to be applied to full digital images without operator input. The hybrid filter architecture and MANN may be applied to any gray scale image in medical imaging. The specific application of the proposed method includes: (a) improved enhancement or detection of suspicious areas as a \"\"second opinion\"\" strategy using a computer workstation or (b) mass screening of large image databases such as that used for medical screening programs. \"',\n",
       " 'A neural network is trained and used to reduce artifacts in spatial domain representations of images that were compressed by a transform method and then decompressed. For example, the neural network can be trained and used to reduce artifacts such as blocking and ringing artifacts in JPEG images.',\n",
       " 'Deep convolutional neural networks receive local and global representations of images as inputs and learn the best representation for a particular feature through multiple convolutional and fully connected layers. A double-column neural network structure receives each of the local and global representations as two heterogeneous parallel inputs to the two columns. After some layers of transformations, the two columns are merged to form the final classifier. Additionally, features may be learned in one of the fully connected layers. The features of the images may be leveraged to boost classification accuracy of other features by learning a regularized double-column neural network.',\n",
       " '\" An image binarizing apparatus, which comprises an image sensor for inputting a character image or a line image, an A/D converter for digitizing the output of the image sensor, a frame memory for temporary storage of the digital image, a window circuit for generating address information for dividing the stored image into a predetermined number of partial images, a brightness extractor for obtaining the highest brightness, lowest brightness and average brightness for the pixels for each block, a neural network which provides the optimum threshold value based on pre-learned data when receiving the highest brightness, lowest brightness and average brightness, a binarizer for binarizing each pixel of a partial image block from the frame memory based on the optimum threshold value (\"\"white pixel\"\" when the value of the brightness of the pixel is larger than the output value of the neural network, and \"\"black pixel\"\" when the value of the brightness of the pixel is smaller than the output value of the neural network), and another frame memory for storing the binarized image at a predetermined address. \"',\n",
       " 'Image content classification methods, systems and computer programs repeatedly scan an image having an array of image pixels, with at least one random neural network. Each scan corresponds to one of multiple texture patterns. A corresponding texture pattern is compared to each of multiple image portions for each of the multiple scans. A value is assigned to each image portion, corresponding to the texture pattern having the highest coincidence. An array of pixels corresponding to the assigned values for the image portions may then be displayed. Highly accurate results may be obtained, at high speed, without the need for lengthy expert analysis.',\n",
       " 'An image distortion correction method and an image distortion correction device are provided. The image distortion correction method uses a neural network model to perform a correcting operation on an original image so as to obtain a correction image with plural correction points. Firstly, a position coordinate of the correction point is inputted into the neural network model, so that a first direction coordinate correction amount is outputted from the neural network model. Then, the position coordinate of the correction point is inputted into the neural network model, so that a second direction coordinate correction amount is outputted from the neural network model. Afterwards, a pixel value of the original image corresponding to the first direction coordinate correction amount and the second direction coordinate correction amount is used as a pixel value of the correction point.',\n",
       " 'Disclosed are devices and methods for processing an image document in a client-server environment such that privacy of text information contained in the image document is preserved. Specifically, in a client-server environment, an image document can be processed using a local computerized device of a client to create an obfuscated document by identifying word images in the image document and scrambling those word images. The obfuscated document can be received by a server of a service provider over a network (e.g., the Internet) and processed by previously trained software (e.g., a previously trained convolutional neural network (CNN)) to recognize specific words represented by the scrambled images in the obfuscated document without having to reconstruct the image document. Since the image document is neither communicated over the network, nor reconstructed and stored on the server, privacy concerns are minimized.',\n",
       " 'An image forming apparatus, such as a laser printer, ink jet printer, or a thermal transfer, which comprises a neural network. The apparatus improves image quality by reducing a zigzag included, e.g., in input image data, reducing the circuit size by reducing the number of bits having small weights for an input combination, and concurrently correcting the size of center, left and right picture elements in a predetermined window. The neural network outputs correction data for the size and position of the center dot in a window in response to an input of dot image data in a window or subdot pattern exposure data for the center dot. Additionally, the neural network uses any of the three values, +1, -1 and 0, for the coefficient of input combination for a hidden layer neuron, e.g., after a teacher pattern is learned. Further, the neural network outputs correction data for 3.times.N subblocks of picture elements obtained by dividing blocks of picture elements in the center, left and right of a window.',\n",
       " 'A copying machine equipped with a PC counter for counting cumulative rotation time of a photoconductive drum, a development counter for counting cumulative drive time of a developing unit, a sensor for detecting deposition amount of toner onto the photoconductive drum, a sensor for detecting toner concentration in the developer, and a humidity sensor. Based on output values from the counters and sensors, a control section of the copying machine estimates the degree of consumption of a consumable article by using fuzzy inference method or neural network, and thereby decides whether the consumable article have reached an end of life.',\n",
       " 'Methods, systems, and apparatus, including computer programs encoded on computer storage media, for image generation using neural networks. In one of the methods, an initial image is received. Data defining an objective function is received, and the objective function is dependent on processing of a neural network trained to identify features of an image. The initial image is modified to generate a modified image by iteratively performing the following: a current version of the initial image is processed using the neural network to generate a current objective score for the current version of the initial image using the objective function; and the current version of the initial image is modified to increase the current objective score by enhancing a feature detected by the processing.',\n",
       " 'An image interpolation method and an image interpolation device and an image apparatus using the image interpolation method are provided. The image interpolation method uses a probabilistic neural network model to perform an adaptive interpolation on an image. The image interpolation method includes the following steps. Firstly, plural reference points neighboring an interpolation point are selected. Then, an anisotropic Gaussian function value of each reference point of the plural reference points is obtained according to an edge direction angle, a horizontal smoothing parameter, a vertical smoothing parameter and a distance between each reference point and the interpolation point. Afterwards, a statistics method is performed to integrate and compute the anisotropic Gaussian function values of the plural reference points, thereby obtaining an interpolation value of the interpolation point.',\n",
       " 'An image processing apparatus inputs an image signal obtained by scanning a document in which a character region, a photographic region and a dot region are mixed and stores image data in a local block composed of a target picture element and plural picture elements surrounding the target picture element. The image processing apparatus computes first and second feature parameters P.sub.0 and P.sub.1 representing the features of each region based on the image data in the local block, and inputs the resulting first and second feature parameters P.sub.0 and P.sub.1 to an identification circuit adopting a neural network. The identification circuit outputs the region identification information O.sub.0 and O.sub.1 of the target picture element, and the filter processing circuit performs a spatial filtering process according to the region identification information O.sub.0 and O.sub.1. As described, in the image processing apparatus, since a multi-dimensional identification process is performed using the neural circuit which receives inputs of plural feature parameters, an image identification with very high precision is permitted, and an optimum spatial-filtering process can be applied according to the feature of each picture element,',\n",
       " 'An image processing apparatus includes a feature data extracting circuit for detecting feature data indicative of density characteristics of a document based on image signals inputted from an input terminal, a density correction table selecting circuit composed of a neural circuit network which is learned beforehand so as to recognize image characteristics based on the feature data, and a density correcting circuit for selecting a density correction table in accordance with image characteristics based on a selection signal from the density correction table selecting circuit so that the density of image signals is corrected based on the density correction table. As a result, characteristics of the document are extracted, so that the density of the image signals can be corrected based thereon. As a result, the density characteristics of the document are extracted, and a density correction can be performed based on the extracted density characteristics, thereby obtaining a high quality recorded image with respect to documents of various kinds. Furthermore, by adopting the neural circuit network, the density of the image signals can be corrected accurately at high speed.',\n",
       " 'An image processing apparatus and method and a provision medium arranged to perform image learning and image recognition in a short time. An image difference detector computes a differential image between an image stored in a frame buffer and an image stored in another frame buffer, and also computes the centroid of the differential image. A information collector forms RGB histogram data and binary data of a peripheral area about the centroid obtained by the image difference detector. A category former formed by a Kohonen network forms a category based on the RGB histogram data and binary data. A category statistic processor performs statistical processing of the categories output from the category former, and outputs a processing result to a learner formed by a recurrent neural network.',\n",
       " 'An image processing apparatus includes an image input section, a color image/monochrome image converting section for performing image area division, a binarization circuit for binarizing a converted monochrome image, a reducing section for reducing a binary image, a boundary extracting section for extracting the boundaries between the areas of constituent elements constituting an input image, e.g., a binary image and a continuous gradation image, and a kind-of-image determining section for determining the kinds of images in partial areas defined by the extracted boundaries. For example, the image processing apparatus further includes a data compressing section. In the image processing apparatus, pre-processing is performed to efficiently performing pattern determination in consideration of localization of frequencies of occurrence of edges and black pixel patterns of an image, and kind-of-image determination is performed by a neural network on the basis of the data obtained by pre-processing, thus performing suitable processing such as data compression in accordance with the determination result.',\n",
       " 'An image processing apparatus using a neural network having: an image supplying unit for supplying spatiotemporal data of a predetermined region including a target pixel of an image; and a neural network formed by coupling a plurality of artificial neuron models so as to have at least an input layer, a hidden layer, and an output layer, wherein in the output layer, an input/output converting process is executed by a linear function and data corresponding to a target pixel is outputted from the output layer.',\n",
       " 'Disclosed is an image processing apparatus having an input device for inputting binary image data comprising a plurality of pixels which include a pixel of interest that is to be subjected to multivalued conversion, the plurality of pixels being contained in an area that is asymmetrical with respect to the position of the pixel of interest, and an multivalued converting device for executing processing, by a neural network, to restore the input binary image data to multivalued image data for the pixel of interest, whereby multivalued image data is estimated from binarized image data. It is possible to reduce the number of pixels referred to in arithmetic operations performed in the neural network.',\n",
       " 'In order to realize a neural network for image processing by an inexpensive hardware arrangement, a neural network arranged in an image processing apparatus is constituted by an input layer having neurons for receiving information from picture elements in a 7.times.7 area including an interesting picture element in an image, an intermediate layer having one neuron connected to all the 49 neurons in the input layer and five groups of nine neurons, the nine neurons in each group being connected to nine neurons in the input layer, which receive information from picture elements in at least one of five 3.times.3 areas (1a to 1e), and an output layer having one neuron, which is connected to all the neurons in the intermediate layer and outputs information corresponding to the interesting picture element.',\n",
       " 'An information processing apparatus including a switch for manually requesting change of output image quality, detecting unit for detecting a condition of the apparatus, setting unit of setting an image forming condition in accordance with the detected condition and the requested output image quality and control unit for changing the image forming condition by learning the request previously requested by the user. Image forming conditions are adjusted so as to satisfy the user manually based upon the degree of satisfaction determined by the user.',\n",
       " 'The present invention provides an image processing device capable of performing high-resolution conversion, enlargement processing, etc. which, even with images including both text images and photographic images, satisfies both sharpness of text areas and smoothness of photograph areas. The image processing device according to the present invention performs frequency conversion, using a frequency conversion device, of partial images which are the objects of processing, resulting in a matrix of frequency-converted coefficients; divides into a plurality of domains, using a plurality of patterns, the matrix of frequency-converted coefficients; and quantifies each such domain by finding a mean value of the coefficients of that domain as a feature quantity for that domain. The mean coefficient value of each domain is inputted into a conversion filter selecting device, where a hierarchical neural network calculates and outputs the suitability of each conversion filter for the partial image in question, and the conversion filter selecting device selects the conversion filter with the highest suitability. Then an interpolation processing device performs interpolation processing of each partial image using the conversion filter most suited thereto.',\n",
       " 'Arrangement and method for obtaining information about objects in an environment in or around a vehicle includes one or more optical imagers for obtaining images of the environment and a processor coupled to the imager(s) for obtaining information about an object in one or more images obtained by the imager(s). The processor is arranged to process the obtained images to determine edges of objects in the images and input data about the edges into a trained pattern recognition algorithm which has been trained to provide information about the object as output. The pattern recognition algorithm may include a neural network or variation thereof. The information about the object may be used to control a vehicular component such as an airbag or light filter.',\n",
       " 'In coding color still image data into multi-valued image data, the image quality deteriorates when a large compression ratio is used. In the present invention, a transmitted image is classified using a parameter transmitted from the transmitting station, and the deterioration of image quality caused by compression at the transmitting station is estimated from the image classification. In an image reproduction, a quantization table is used in the case of an adaptive discrete cosine transform (ADCT) method to select an optimum neural network suitable for image reproduction and improve the image quality.',\n",
       " 'An image processing apparatus includes an input unit for entering a plurality of color image signals, an image processing unit for subjecting the plurality of entered color image signals to processing based upon an algorithm of a cellular neural network, and a comparison decision unit for deciding output color data based upon results of processing by the image processing unit. Since input multivalued color image data based upon the algorithm of a neural network are converted to output color image data, it is possible to obtain a high-quality output color image that is faithful to the input color image.',\n",
       " 'In an image processing method and apparatus, image data having multi-value levels for one pixel is input, and the input image data is quantized such that an output area of one pixel is adapted to an output device in which an output area of one pixel changes depending on the position of the pixel. A quantizing process executes an arithmetic operation based on an algorithm of a neural network on the basis of a value obtained by multiplying an output value by a weight corresponding to an area of each pixel. Therefore, even if pixels have different maximum luminances, the different numbers of bits, and different color expression capabilities, an optimum half-tone process can be performed by an algorithm based on a cellular neural network, and a high-quality image can be obtained.',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv(\n",
    "    './data/neural_network_patent_query.csv', parse_dates=['patent_date'])\n",
    "\n",
    "# Extract abstracts\n",
    "original_abstracts = list(data['patent_abstract'])\n",
    "original_abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a short sentence with one reference to an image . This next sentence , while non-sensical , does not have an image and has two commas .'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from keras.preprocessing.text import Tokenizer\n",
    "import re\n",
    "\n",
    "\n",
    "example = 'This is a short sentence (1) with one reference to an image. This next sentence, while non-sensical, does not have an image and has two commas.'\n",
    "\n",
    "def format_patent(patent):\n",
    "    \"\"\"Add spaces around punctuation and remove references to images/citations.\"\"\"\n",
    "\n",
    "    # Add spaces around punctuation\n",
    "    patent = re.sub(r'(?<=[^\\s0-9])(?=[.,;?])', r' ', patent)\n",
    "\n",
    "    # Remove references to figures\n",
    "    patent = re.sub(r'\\((\\d+)\\)', r'', patent)\n",
    "\n",
    "    # Remove double spaces\n",
    "    patent = re.sub(r'\\s\\s', ' ', patent)\n",
    "    return patent\n",
    "\n",
    "format_patent(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3522"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted = []\n",
    "\n",
    "# Iterate through all the original abstracts\n",
    "for a in original_abstracts:\n",
    "    formatted.append(format_patent(a))\n",
    "\n",
    "len(formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert sequences into indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[13,\n",
       " 91,\n",
       " 75,\n",
       " 125,\n",
       " 14,\n",
       " 71,\n",
       " 6,\n",
       " 2,\n",
       " 31,\n",
       " 11,\n",
       " 566,\n",
       " 6,\n",
       " 560,\n",
       " 34,\n",
       " 130,\n",
       " 36,\n",
       " 2,\n",
       " 3395,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 300,\n",
       " 2988,\n",
       " 7591,\n",
       " 342,\n",
       " 46,\n",
       " 366,\n",
       " 10183,\n",
       " 1,\n",
       " 1343,\n",
       " 4,\n",
       " 13,\n",
       " 3395,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 25,\n",
       " 10,\n",
       " 345,\n",
       " 3,\n",
       " 4735,\n",
       " 6,\n",
       " 2029,\n",
       " 5,\n",
       " 2987,\n",
       " 1481,\n",
       " 10184,\n",
       " 140,\n",
       " 12,\n",
       " 2,\n",
       " 10185,\n",
       " 511,\n",
       " 67,\n",
       " 7,\n",
       " 22,\n",
       " 1,\n",
       " 282,\n",
       " 178,\n",
       " 11,\n",
       " 1,\n",
       " 282,\n",
       " 92,\n",
       " 4246,\n",
       " 3,\n",
       " 1,\n",
       " 869,\n",
       " 145,\n",
       " 1625,\n",
       " 3,\n",
       " 1,\n",
       " 92,\n",
       " 4,\n",
       " 13,\n",
       " 91,\n",
       " 75,\n",
       " 996,\n",
       " 7591,\n",
       " 34,\n",
       " 59,\n",
       " 156,\n",
       " 6,\n",
       " 81,\n",
       " 47,\n",
       " 29,\n",
       " 342,\n",
       " 46,\n",
       " 5,\n",
       " 25,\n",
       " 10,\n",
       " 1,\n",
       " 1871,\n",
       " 155,\n",
       " 12,\n",
       " 9,\n",
       " 8,\n",
       " 223,\n",
       " 5,\n",
       " 1522,\n",
       " 3175,\n",
       " 9,\n",
       " 83,\n",
       " 6,\n",
       " 3175,\n",
       " 8,\n",
       " 148,\n",
       " 684,\n",
       " 223,\n",
       " 16,\n",
       " 153,\n",
       " 7,\n",
       " 188,\n",
       " 295,\n",
       " 24,\n",
       " 1,\n",
       " 34,\n",
       " 19,\n",
       " 350,\n",
       " 7,\n",
       " 1,\n",
       " 59,\n",
       " 566,\n",
       " 6,\n",
       " 560,\n",
       " 350,\n",
       " 4]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = formatted[100].split(\" \")\n",
    "\n",
    "index_seq = []\n",
    "for word in seq:\n",
    "    if word in word_dict.keys():\n",
    "        index_seq.append(word_dict[word])\n",
    "    else:\n",
    "        index_seq.append(0)\n",
    "\n",
    "print(len(seq), len(index_seq))\n",
    "index_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Compile C program\n",
    "\n",
    "If the program has already been compiled, simply skip this step.\n",
    "\n",
    "The compiled program is in ./sim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Entering directory '/home/jwq/6868esp/C-implementation-of-RNN/python_demo/sim'\n",
      "MAKE: CLEAN /home/jwq/6868esp/C-implementation-of-RNN/python_demo\n",
      "make: Leaving directory '/home/jwq/6868esp/C-implementation-of-RNN/python_demo/sim'\n",
      "make: Entering directory '/home/jwq/6868esp/C-implementation-of-RNN/python_demo/sim'\n",
      "MAKE: CC fc.o\n",
      "MAKE: CC rnn.o\n",
      "MAKE: CC init.o\n",
      "MAKE: CC main.o\n",
      "MAKE: CC utils.o\n",
      "MAKE: CC softmax.o\n",
      "MAKE: CC activation.o\n",
      "MAKE: LINK c-rnn\n",
      "make: Leaving directory '/home/jwq/6868esp/C-implementation-of-RNN/python_demo/sim'\n"
     ]
    }
   ],
   "source": [
    "!make clean -C ./sim\n",
    "!make -C ./sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run C program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEED_LEN = 50\n",
    "# part_seq = index_seq[0:FEED]\n",
    "\n",
    "def write_seq(index_seq, start_idx):\n",
    "    \"\"\"\n",
    "    write the index sequence to txt file\n",
    "    Length: 50\n",
    "    \"\"\"\n",
    "    with open(\"./tmp/seq.txt\", 'w') as f:\n",
    "        for item in index_seq[start_idx: start_idx + FEED_LEN]:\n",
    "            f.write(\"%d \" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict next word by origin sequence\n",
    "\n",
    "Our language model always predict the next word given the 50 ORGINAL words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_topk(arr, k):\n",
    "    return arr.argsort()[-k:][::-1]\n",
    "\n",
    "def list_to_arr(ls):\n",
    "    arr = np.zeros(len(ls))\n",
    "    for i, ele in enumerate(ls):\n",
    "        arr[i] = (np.float64(ele))\n",
    "        \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of sentence: 125\n",
      "[  9 817 234]\n",
      "[511 260 198]\n",
      "[ 67 249 147]\n",
      "[   4   11 6885]\n",
      "[5975  127  109]\n",
      "[ 1  2 14]\n",
      "[22 19 87]\n",
      "[22  7 63]\n",
      "[3 4 7]\n",
      "[ 1 32  2]\n",
      "[38  9 19]\n",
      "[63  9 92]\n",
      "[ 4  5 10]\n",
      "[5 2 4]\n",
      "[ 1  2 14]\n",
      "[19 22 87]\n",
      "[ 3  4 34]\n",
      "[ 2  1 63]\n",
      "[ 4  3 48]\n",
      "[ 1  2 14]\n",
      "[ 9 37 19]\n",
      "^C\n",
      "[]\n",
      "[13 18 64]\n",
      "[ 9 31 20]\n",
      "[  75 3570   63]\n",
      "[ 10  85 125]\n",
      "[7591    2  978]\n",
      "[34 43 15]\n",
      "[15 81 46]\n",
      "[81  5 10]\n",
      "[ 138    4 6929]\n",
      "[  2   1 125]\n",
      "[ 3 15  4]\n",
      "[ 29 240 585]\n",
      "[ 1  2 25]\n",
      "[984  46  15]\n",
      "[  6 217 593]\n",
      "[  6 162   1]\n",
      "[10 16 40]\n",
      "[ 2 54 73]\n",
      "[ 282 1871  178]\n",
      "[ 3 11 28]\n",
      "[17 24 12]\n",
      "[  1   2 122]\n",
      "[ 83   8 501]\n",
      "[5 4 6]\n",
      "[5 6 4]\n",
      "[6 1 7]\n",
      "[3 1 2]\n",
      "[ 21   8 124]\n",
      "[ 83   8 501]\n",
      "[5 4 7]\n",
      "[  1 150  46]\n",
      "[ 8 21  9]\n",
      "[4 5 7]\n",
      "[5 4 7]\n",
      "[5 6 3]\n",
      "[60  7 28]\n",
      "[54 78 73]\n",
      "[ 7 27 36]\n",
      "[ 1  2 14]\n",
      "[ 1  3 43]\n",
      "[ 3  4 11]\n",
      "[ 1  2 14]\n",
      "[ 9 19 34]\n",
      "[  15    4 1022]\n",
      "[30  6 15]\n",
      "[7 6 5]\n",
      "[  1   2 109]\n",
      "[ 9 38 19]\n",
      "[ 4 81  3]\n",
      "[61  6  5]\n",
      "[   1    2 2402]\n",
      "[  1   2 788]\n"
     ]
    }
   ],
   "source": [
    "print(\"length of sentence: {}\".format(len(index_seq)))\n",
    "\n",
    "for i in range(len(index_seq) - FEED_LEN - 1):\n",
    "    write_seq(index_seq, i)\n",
    "    prob_str = !./sim/c-rnn\n",
    "    prob_arr = list_to_arr(prob_str)\n",
    "    topk = arg_topk(prob_arr, 3)\n",
    "    print(topk)\n",
    "#     predict_idx = int(temp[0])\n",
    "#     print(\"predicted result: {}\\tactual result: {}\".format(predict_idx, index_seq[FEED_LEN + i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict next word given a seed sequence\n",
    "\n",
    "Given 50 start words, the language model will generate sequences without refering to the original sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## greedy\n",
    "if we use greedy (always choose the word of highest probability), we may get a loop of repeated words..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "def print_seq(seq, index_dict):\n",
    "    \"\"\"\n",
    "    given an index sequence, print it's corresponding words\n",
    "    \"\"\"\n",
    "    print(colored(\"blue: \", 'blue'), end=\"\")\n",
    "    print(\"start sequence\")\n",
    "    print(\"black: sequence generated by our language model\")\n",
    "    print(colored(\"red: \", 'red'), end=\"\")\n",
    "    print(\"current prediction\\n\\n\")\n",
    "\n",
    "    for i, word_idx in enumerate(seq):\n",
    "        if i < FEED_LEN:\n",
    "            print(colored(index_dict[word_idx], 'blue'), end=\" \")\n",
    "        elif i == len(seq) - 1:    \n",
    "            print(colored(index_dict[word_idx], 'red'), end=\" \")\n",
    "        else:\n",
    "            print(index_dict[word_idx], end=\" \")     \n",
    "            \n",
    "    print(\"\\n\\nnew word: \")\n",
    "    print(colored(index_dict[seq[-1]], 'red'))\n",
    "    \n",
    "def random_choose(idx_arr):\n",
    "    return idx_arr[np.random.randint(0, high=len(idx_arr))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some randomness\n",
    "choose, e.g. top 3 most likely words and randomly pick one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### randomly pick top 3 most likely word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mblue: \u001b[0mstart sequence\n",
      "black: sequence generated by our language model\n",
      "\u001b[31mred: \u001b[0mcurrent prediction\n",
      "\n",
      "\n",
      "\u001b[34mThe\u001b[0m \u001b[34mpresent\u001b[0m \u001b[34minvention\u001b[0m \u001b[34mprovides\u001b[0m \u001b[34man\u001b[0m \u001b[34mapparatus\u001b[0m \u001b[34mand\u001b[0m \u001b[34ma\u001b[0m \u001b[34mmethod\u001b[0m \u001b[34mfor\u001b[0m \u001b[34mclassifying\u001b[0m \u001b[34mand\u001b[0m \u001b[34mrecognizing\u001b[0m \u001b[34mimage\u001b[0m \u001b[34mpatterns\u001b[0m \u001b[34musing\u001b[0m \u001b[34ma\u001b[0m \u001b[34msecond-order\u001b[0m \u001b[34mneural\u001b[0m \u001b[34mnetwork\u001b[0m \u001b[34m,\u001b[0m \u001b[34mthereby\u001b[0m \u001b[34machieving\u001b[0m \u001b[34mhigh-rate\u001b[0m \u001b[34mparallel\u001b[0m \u001b[34mprocessing\u001b[0m \u001b[34mwhile\u001b[0m \u001b[34mlowering\u001b[0m \u001b[34mthe\u001b[0m \u001b[34mcomplexity\u001b[0m \u001b[34m.\u001b[0m \u001b[34mThe\u001b[0m \u001b[34msecond-order\u001b[0m \u001b[34mneural\u001b[0m \u001b[34mnetwork\u001b[0m \u001b[34m,\u001b[0m \u001b[34mwhich\u001b[0m \u001b[34mis\u001b[0m \u001b[34mmade\u001b[0m \u001b[34mof\u001b[0m \u001b[34madders\u001b[0m \u001b[34mand\u001b[0m \u001b[34mmultipliers\u001b[0m \u001b[34m,\u001b[0m \u001b[34mcorrects\u001b[0m \u001b[34mpositional\u001b[0m \u001b[34mtranslations\u001b[0m \u001b[34mgenerated\u001b[0m \u001b[34min\u001b[0m \u001b[34ma\u001b[0m variety of real time , to obtain the output y(t) the post output layer of each of the input image . A neural system further comprises the neural net layer is connected together to the first and second layer of a neuron in a first set and second input signals . A second neural networks is used to generate the image data . A method is also provided to a user to the user . A plurality rality attention function , the second neural networks are used in the neural networks , or a neural net layer , the \u001b[31mfirst\u001b[0m \n",
      "\n",
      "new word: \n",
      "\u001b[31mfirst\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "output_len = 100\n",
    "\n",
    "my_seq = index_seq[:FEED_LEN]\n",
    "      \n",
    "for i in range(output_len):\n",
    "    # generate a sequence that has equal length as original sequence\n",
    "    write_seq(my_seq, i)\n",
    "    prob_str = !./sim/c-rnn\n",
    "    prob_arr = list_to_arr(prob_str)\n",
    "    topk = arg_topk(prob_arr, 3)\n",
    "#     print(topk)\n",
    "    predict_idx = random_choose(topk)\n",
    "    my_seq.append(predict_idx)\n",
    "    clear_output()\n",
    "    print_seq(my_seq, index_dict)\n",
    "#     print(\"\\n\\nnew word: {}\".format(index_dict[my_seq[-1]]))\n",
    "#     print(\"predicted result: {}\\tactual result: {}\".format(predict_idx, index_seq[FEED_LEN + i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### randomly pick top 2 most likely word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mblue: \u001b[0mstart sequence\n",
      "black: sequence generated by our language model\n",
      "\u001b[31mred: \u001b[0mcurrent prediction\n",
      "\n",
      "\n",
      "\u001b[34mThe\u001b[0m \u001b[34mpresent\u001b[0m \u001b[34minvention\u001b[0m \u001b[34mprovides\u001b[0m \u001b[34man\u001b[0m \u001b[34mapparatus\u001b[0m \u001b[34mand\u001b[0m \u001b[34ma\u001b[0m \u001b[34mmethod\u001b[0m \u001b[34mfor\u001b[0m \u001b[34mclassifying\u001b[0m \u001b[34mand\u001b[0m \u001b[34mrecognizing\u001b[0m \u001b[34mimage\u001b[0m \u001b[34mpatterns\u001b[0m \u001b[34musing\u001b[0m \u001b[34ma\u001b[0m \u001b[34msecond-order\u001b[0m \u001b[34mneural\u001b[0m \u001b[34mnetwork\u001b[0m \u001b[34m,\u001b[0m \u001b[34mthereby\u001b[0m \u001b[34machieving\u001b[0m \u001b[34mhigh-rate\u001b[0m \u001b[34mparallel\u001b[0m \u001b[34mprocessing\u001b[0m \u001b[34mwhile\u001b[0m \u001b[34mlowering\u001b[0m \u001b[34mthe\u001b[0m \u001b[34mcomplexity\u001b[0m \u001b[34m.\u001b[0m \u001b[34mThe\u001b[0m \u001b[34msecond-order\u001b[0m \u001b[34mneural\u001b[0m \u001b[34mnetwork\u001b[0m \u001b[34m,\u001b[0m \u001b[34mwhich\u001b[0m \u001b[34mis\u001b[0m \u001b[34mmade\u001b[0m \u001b[34mof\u001b[0m \u001b[34madders\u001b[0m \u001b[34mand\u001b[0m \u001b[34mmultipliers\u001b[0m \u001b[34m,\u001b[0m \u001b[34mcorrects\u001b[0m \u001b[34mpositional\u001b[0m \u001b[34mtranslations\u001b[0m \u001b[34mgenerated\u001b[0m \u001b[34min\u001b[0m \u001b[34ma\u001b[0m neural net which has a function of the neural networks to generate an output signal . The output of the neural networks are used to determine the output of a plurality rality rates are used in a neural neural network . A neural network-based combination neural network can be used in the form of a neural net which is a result of a neural network , the neural network is used to train the neural network to produce an output signal to a neural network . A neural network-based combination of the neural networks are used to determine the predicted output . A method of a genetic algorithm to determine whether the distance , and a neural network-based adaptive neural system may be used in the form of a neural network . A neural network is trained to identify the probability density of each other than a plurality of neurons . The neural networks are used as a neural system . A neural network-based adaptive neural networks are trained using the training data . A neural network-based combination neural network is trained using a plurality of output signals to a neural system . The neural networks are used as \u001b[31ma\u001b[0m \n",
      "\n",
      "new word: \n",
      "\u001b[31ma\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "output_len = 200\n",
    "\n",
    "my_seq = index_seq[:FEED_LEN]\n",
    "      \n",
    "for i in range(output_len):\n",
    "    # generate a sequence that has equal length as original sequence\n",
    "    write_seq(my_seq, i)\n",
    "    prob_str = !./sim/c-rnn\n",
    "    prob_arr = list_to_arr(prob_str)\n",
    "    topk = arg_topk(prob_arr, 2)\n",
    "#     print(topk)\n",
    "    predict_idx = random_choose(topk)\n",
    "    my_seq.append(predict_idx)\n",
    "    clear_output()\n",
    "    print_seq(my_seq, index_dict)\n",
    "#     print(\"\\n\\nnew word: {}\".format(index_dict[my_seq[-1]]))\n",
    "#     print(\"predicted result: {}\\tactual result: {}\".format(predict_idx, index_seq[FEED_LEN + i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
